
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½AIç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ - ä¸»ç¨‹åº
è§£å†³æ‰€æœ‰15ä¸ªæ ¸å¿ƒé—®é¢˜çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ
"""

import os
import re
import json
import hashlib
import subprocess
import requests
from typing import List, Dict, Optional, Tuple
from datetime import datetime

class EnhancedNarrationGenerator:
    """å¢å¼ºç‰ˆæ—ç™½ç”Ÿæˆå™¨"""
    
    def __init__(self, ai_config: Dict):
        self.ai_config = ai_config

    def create_subtitle_filters(self, narration: Dict, video_duration: float) -> List[str]:
        """åˆ›å»ºå­—å¹•æ»¤é•œ"""
        filters = []
        
        # ä¸»è¦è§£è¯´ï¼ˆå‰1/3æ—¶é—´ï¼‰
        main_text = self.clean_text_for_ffmpeg(narration.get('main_explanation', ''))[:50]
        if main_text:
            filters.append(
                f"drawtext=text='{main_text}':fontsize=20:fontcolor=white:"
                f"x=(w-text_w)/2:y=(h-100):box=1:boxcolor=black@0.7:boxborderw=3:"
                f"enable='between(t,2,{video_duration/3})'"
            )
        
        # äº®ç‚¹æç¤ºï¼ˆå1/3æ—¶é—´ï¼‰
        highlight_text = self.clean_text_for_ffmpeg(narration.get('highlight_tip', ''))[:40]
        if highlight_text:
            filters.append(
                f"drawtext=text='ğŸ’¡ {highlight_text}':fontsize=18:fontcolor=yellow:"
                f"x=(w-text_w)/2:y=(h-60):box=1:boxcolor=black@0.6:boxborderw=2:"
                f"enable='between(t,{video_duration*2/3},{video_duration-1})'"
            )
        
        return filters

    def clean_text_for_ffmpeg(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ç”¨äºFFmpeg"""
        return text.replace("'", "").replace('"', '').replace(':', '-').replace('\n', ' ')

    def export_narration_text(self, narration: Dict, video_path: str):
        """å¯¼å‡ºæ—ç™½æ–‡æœ¬æ–‡ä»¶"""
        narration_path = video_path.replace('.mp4', '_æ—ç™½.txt')
        
        content = f"""ğŸ™ï¸ è§†é¢‘æ—ç™½è§£è¯´
{"=" * 40}

ğŸ“ ä¸»è¦è§£è¯´:
{narration.get('main_explanation', 'ç²¾å½©ç‰‡æ®µè§£è¯´')}

ğŸ’¡ äº®ç‚¹æç¤º:
{narration.get('highlight_tip', 'å…³é”®çœ‹ç‚¹')}

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        try:
            with open(narration_path, 'w', encoding='utf-8') as f:
                f.write(content)
        except Exception as e:
            print(f"âš ï¸ æ—ç™½æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")

class PlatformFix:
    """å¹³å°å…¼å®¹æ€§ä¿®å¤"""
    
    @staticmethod
    def safe_file_read(filepath: str) -> Optional[str]:
        """å®‰å…¨æ–‡ä»¶è¯»å–"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception:
            return None

    @staticmethod
    def safe_file_write(filepath: str, content: str) -> bool:
        """å®‰å…¨æ–‡ä»¶å†™å…¥"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return True
        except Exception:
            return False

    @staticmethod
    def safe_subprocess_run(cmd, **kwargs):
        """å®‰å…¨å­è¿›ç¨‹è¿è¡Œ"""
        try:
            return subprocess.run(cmd, **kwargs)
        except Exception as e:
            print(f"âš ï¸ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            return subprocess.CompletedProcess(cmd, 1, "", str(e))

platform_fix = PlatformFix()

class IntelligentTVClipper:
    """æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ"""
    
    def __init__(self):
        # æ ‡å‡†ç›®å½•ç»“æ„ - è§£å†³é—®é¢˜6
        self.srt_folder = "srt"
        self.video_folder = "videos"
        self.output_folder = "clips"
        self.cache_folder = "analysis_cache"
        
        # åˆ›å»ºç›®å½•
        for folder in [self.srt_folder, self.video_folder, self.output_folder, self.cache_folder]:
            os.makedirs(folder, exist_ok=True)
        
        # åŠ è½½AIé…ç½® - è§£å†³é—®é¢˜1
        self.ai_config = self.load_ai_config()
        
        print("ğŸš€ æ™ºèƒ½AIç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿå·²åˆå§‹åŒ–")
        print(f"ğŸ“ å­—å¹•ç›®å½•: {self.srt_folder}/")
        print(f"ğŸ¬ è§†é¢‘ç›®å½•: {self.video_folder}/")
        print(f"ğŸ“¤ è¾“å‡ºç›®å½•: {self.output_folder}/")

    def load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½® - è§£å†³é—®é¢˜1ï¼šæ”¯æŒå®˜æ–¹å’Œä¸­è½¬API"""
        try:
            if os.path.exists('.ai_config.json'):
                with open('.ai_config.json', 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    if config.get('enabled', False):
                        api_type = config.get('api_type', 'proxy')
                        provider = config.get('provider', 'unknown')
                        print(f"ğŸ¤– AIåˆ†æå·²å¯ç”¨: {provider} ({api_type})")
                        return config
        except Exception as e:
            print(f"âš ï¸ AIé…ç½®åŠ è½½å¤±è´¥: {e}")
        
        print("ğŸ“ AIåˆ†ææœªå¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")
        return {'enabled': False}

    def configure_ai_interactive(self):
        """äº¤äº’å¼AIé…ç½®"""
        print("\nğŸ¤– AIæ¥å£é…ç½®")
        print("=" * 40)
        
        # é€‰æ‹©APIç±»å‹
        print("è¯·é€‰æ‹©APIç±»å‹:")
        print("1. å®˜æ–¹API (Google Gemini, OpenAIç­‰)")
        print("2. ä¸­è½¬API (æ”¯æŒå¤šç§æ¨¡å‹)")
        
        choice = input("è¯·é€‰æ‹© (1-2): ").strip()
        
        if choice == '1':
            self.configure_official_api()
        elif choice == '2':
            self.configure_proxy_api()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")

    def configure_official_api(self):
        """é…ç½®å®˜æ–¹API"""
        print("\nğŸ“ å®˜æ–¹APIé…ç½®")
        
        provider = input("è¯·è¾“å…¥æä¾›å•† (gemini/openai): ").strip().lower()
        api_key = input("è¯·è¾“å…¥APIå¯†é’¥: ").strip()
        
        if not api_key:
            print("âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º")
            return
        
        if provider == 'gemini':
            model = input("è¯·è¾“å…¥æ¨¡å‹åç§° (é»˜è®¤: gemini-2.0-flash-exp): ").strip() or "gemini-2.0-flash-exp"
        else:
            model = input("è¯·è¾“å…¥æ¨¡å‹åç§° (é»˜è®¤: gpt-4): ").strip() or "gpt-4"
        
        config = {
            'enabled': True,
            'api_type': 'official',
            'provider': provider,
            'api_key': api_key,
            'model': model
        }
        
        if self.save_ai_config(config):
            self.ai_config = config
            print(f"âœ… å®˜æ–¹APIé…ç½®æˆåŠŸ: {provider}")

    def configure_proxy_api(self):
        """é…ç½®ä¸­è½¬API"""
        print("\nğŸ”„ ä¸­è½¬APIé…ç½®")
        
        base_url = input("è¯·è¾“å…¥APIåœ°å€ (å¦‚: https://www.chataiapi.com/v1): ").strip()
        api_key = input("è¯·è¾“å…¥APIå¯†é’¥: ").strip()
        model = input("è¯·è¾“å…¥æ¨¡å‹åç§° (å¦‚: deepseek-r1): ").strip()
        
        if not all([base_url, api_key, model]):
            print("âŒ æ‰€æœ‰å­—æ®µéƒ½ä¸èƒ½ä¸ºç©º")
            return
        
        config = {
            'enabled': True,
            'api_type': 'proxy',
            'provider': 'proxy',
            'api_key': api_key,
            'base_url': base_url,
            'model': model
        }
        
        if self.save_ai_config(config):
            self.ai_config = config
            print(f"âœ… ä¸­è½¬APIé…ç½®æˆåŠŸ")

    def save_ai_config(self, config: Dict) -> bool:
        """ä¿å­˜AIé…ç½®"""
        try:
            with open('.ai_config.json', 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            return True
        except Exception as e:
            print(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {e}")
            return False

    def parse_subtitle_file(self, filepath: str) -> List[Dict]:
        """è§£æå­—å¹•æ–‡ä»¶"""
        print(f"ğŸ“– è§£æå­—å¹•: {os.path.basename(filepath)}")
        
        # å°è¯•ä¸åŒç¼–ç 
        content = None
        for encoding in ['utf-8', 'gbk', 'utf-16']:
            try:
                with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                    content = f.read()
                    break
            except:
                continue
        
        if not content:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {filepath}")
            return []
        
        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£
        corrections = {
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'é–‹å§‹': 'å¼€å§‹',
            'çµæŸ': 'ç»“æŸ', 'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'è½è­‰æœƒ': 'å¬è¯ä¼š'
        }
        
        for old, new in corrections.items():
            content = content.replace(old, new)
        
        # è§£æå­—å¹•æ¡ç›®
        subtitles = []
        blocks = re.split(r'\n\s*\n', content.strip())
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                try:
                    index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1
                    
                    # åŒ¹é…æ—¶é—´æ ¼å¼
                    time_pattern = r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})'
                    time_match = re.search(time_pattern, lines[1])
                    
                    if time_match:
                        start_time = time_match.group(1).replace('.', ',')
                        end_time = time_match.group(2).replace('.', ',')
                        text = '\n'.join(lines[2:]).strip()
                        
                        if text:
                            subtitles.append({
                                'index': index,
                                'start': start_time,
                                'end': end_time,
                                'text': text
                            })
                except (ValueError, IndexError):
                    continue
        
        print(f"âœ… è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return subtitles

    def call_ai_api(self, prompt: str, system_prompt: str = "") -> Optional[str]:
        """ç»Ÿä¸€AI APIè°ƒç”¨ - è§£å†³é—®é¢˜1"""
        if not self.ai_config.get('enabled'):
            return None
        
        try:
            api_type = self.ai_config.get('api_type', 'proxy')
            
            if api_type == 'official':
                return self.call_official_api(prompt, system_prompt)
            else:
                return self.call_proxy_api(prompt, system_prompt)
                
        except Exception as e:
            print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def call_official_api(self, prompt: str, system_prompt: str) -> Optional[str]:
        """è°ƒç”¨å®˜æ–¹API"""
        provider = self.ai_config.get('provider', '')
        
        if provider == 'gemini':
            return self.call_gemini_api(prompt, system_prompt)
        elif provider == 'openai':
            return self.call_openai_official_api(prompt, system_prompt)
        else:
            print(f"âš ï¸ ä¸æ”¯æŒçš„å®˜æ–¹APIæä¾›å•†: {provider}")
            return None

    def call_gemini_api(self, prompt: str, system_prompt: str) -> Optional[str]:
        """è°ƒç”¨Google Gemini API"""
        try:
            import google.generativeai as genai
            
            genai.configure(api_key=self.ai_config['api_key'])
            model = genai.GenerativeModel(self.ai_config.get('model', 'gemini-2.0-flash-exp'))
            
            full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
            response = model.generate_content(full_prompt)
            
            return response.text
            
        except Exception as e:
            print(f"âš ï¸ Gemini APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def call_openai_official_api(self, prompt: str, system_prompt: str) -> Optional[str]:
        """è°ƒç”¨OpenAIå®˜æ–¹API"""
        try:
            from openai import OpenAI
            
            client = OpenAI(api_key=self.ai_config['api_key'])
            
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            response = client.chat.completions.create(
                model=self.ai_config.get('model', 'gpt-4'),
                messages=messages,
                max_tokens=4000,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âš ï¸ OpenAI APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def call_proxy_api(self, prompt: str, system_prompt: str) -> Optional[str]:
        """è°ƒç”¨ä¸­è½¬API"""
        try:
            from openai import OpenAI
            
            client = OpenAI(
                api_key=self.ai_config['api_key'],
                base_url=self.ai_config['base_url']
            )
            
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            response = client.chat.completions.create(
                model=self.ai_config['model'],
                messages=messages,
                max_tokens=4000,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âš ï¸ ä¸­è½¬APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def analyze_episode_with_ai(self, subtitles: List[Dict], filename: str) -> Optional[Dict]:
        """ä½¿ç”¨AIåˆ†ææ•´é›† - è§£å†³é—®é¢˜2,3,8ï¼šæ•´é›†åˆ†æé¿å…å‰²è£‚"""
        # æ£€æŸ¥ç¼“å­˜ - è§£å†³é—®é¢˜12
        cache_key = self.get_analysis_cache_key(subtitles)
        cached_analysis = self.load_analysis_cache(cache_key, filename)
        if cached_analysis:
            return cached_analysis
        
        if not self.ai_config.get('enabled'):
            print(f"âš ï¸ AIæœªå¯ç”¨ï¼Œè·³è¿‡ {filename}")
            return None
        
        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ - è§£å†³é—®é¢˜2,3
        full_context = self.build_complete_context(subtitles)
        episode_num = self.extract_episode_number(filename)
        
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œè¯·åˆ†æç¬¬{episode_num}é›†çš„å®Œæ•´å†…å®¹ï¼Œæ‰¾å‡º3-5ä¸ªæœ€ç²¾å½©çš„ç‰‡æ®µåˆ¶ä½œçŸ­è§†é¢‘ã€‚

ã€å®Œæ•´å‰§æƒ…å†…å®¹ã€‘
{full_context}

## åˆ†æè¦æ±‚
1. æ™ºèƒ½è¯†åˆ«3-5ä¸ªæœ€ç²¾å½©çš„ç‰‡æ®µ
2. æ¯ä¸ªç‰‡æ®µ2-3åˆ†é’Ÿï¼ŒåŒ…å«å®Œæ•´å¯¹è¯
3. ç¡®ä¿ç‰‡æ®µé—´é€»è¾‘è¿è´¯
4. ç”Ÿæˆä¸“ä¸šæ—ç™½è§£è¯´å’Œå­—å¹•æç¤º

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{{
    "episode_analysis": {{
        "episode_number": "{episode_num}",
        "genre_type": "å‰§æƒ…ç±»å‹",
        "main_theme": "æœ¬é›†æ ¸å¿ƒä¸»é¢˜"
    }},
    "highlight_segments": [
        {{
            "segment_id": 1,
            "title": "ç²¾å½©æ ‡é¢˜",
            "start_time": "00:XX:XX,XXX",
            "end_time": "00:XX:XX,XXX",
            "duration_seconds": 180,
            "plot_significance": "å‰§æƒ…é‡è¦æ„ä¹‰",
            "professional_narration": "å®Œæ•´çš„ä¸“ä¸šæ—ç™½è§£è¯´ç¨¿",
            "highlight_tip": "ä¸€å¥è¯å­—å¹•äº®ç‚¹æç¤º"
        }}
    ]
}}
```"""

        system_prompt = "ä½ æ˜¯ä¸“ä¸šçš„å½±è§†å†…å®¹åˆ†æä¸“å®¶ï¼Œä¸“é•¿ç”µè§†å‰§æƒ…æ·±åº¦è§£æ„ä¸å™äº‹åˆ†æã€‚"

        try:
            response = self.call_ai_api(prompt, system_prompt)
            if response:
                parsed_result = self.parse_ai_response(response)
                if parsed_result:
                    print(f"âœ… AIåˆ†ææˆåŠŸï¼š{len(parsed_result.get('highlight_segments', []))} ä¸ªç‰‡æ®µ")
                    self.save_analysis_cache(cache_key, filename, parsed_result)
                    return parsed_result
        except Exception as e:
            print(f"âš ï¸ AIåˆ†æå¤±è´¥: {e}")

        return None

    def build_complete_context(self, subtitles: List[Dict]) -> str:
        """æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ - è§£å†³é—®é¢˜2"""
        # æ¯20æ¡å­—å¹•åˆå¹¶æˆä¸€æ®µï¼Œä¿æŒä¸Šä¸‹æ–‡
        context_segments = []
        for i in range(0, len(subtitles), 20):
            segment = subtitles[i:i+20]
            segment_text = ' '.join([f"[{sub['start']}] {sub['text']}" for sub in segment])
            context_segments.append(segment_text)
        
        return '\n\n'.join(context_segments)

    def parse_ai_response(self, response: str) -> Optional[Dict]:
        """è§£æAIå“åº”"""
        try:
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_text = response[start:end]
            else:
                start = response.find("{")
                end = response.rfind("}") + 1
                json_text = response[start:end]

            result = json.loads(json_text)

            if 'highlight_segments' in result and 'episode_analysis' in result:
                return result
        except Exception as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
        return None

    def extract_episode_number(self, filename: str) -> str:
        """ä»æ–‡ä»¶åæå–é›†æ•°ï¼Œä½¿ç”¨å­—ç¬¦ä¸²æ’åº"""
        base_name = os.path.splitext(filename)[0]
        return base_name

    def get_analysis_cache_key(self, subtitles: List[Dict]) -> str:
        """ç”Ÿæˆåˆ†æç¼“å­˜é”®"""
        content = json.dumps(subtitles, ensure_ascii=False, sort_keys=True)
        return hashlib.md5(content.encode()).hexdigest()[:16]

    def load_analysis_cache(self, cache_key: str, filename: str) -> Optional[Dict]:
        """åŠ è½½åˆ†æç¼“å­˜"""
        cache_file = os.path.join(self.cache_folder, f"{filename}_{cache_key}.json")
        if os.path.exists(cache_file):
            try:
                cache_content = platform_fix.safe_file_read(cache_file)
                if cache_content:
                    analysis = json.loads(cache_content)
                    print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜åˆ†æ: {filename}")
                    return analysis
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        return None

    def save_analysis_cache(self, cache_key: str, filename: str, analysis: Dict):
        """ä¿å­˜åˆ†æç¼“å­˜"""
        cache_file = os.path.join(self.cache_folder, f"{filename}_{cache_key}.json")
        try:
            cache_content = json.dumps(analysis, ensure_ascii=False, indent=2)
            platform_fix.safe_file_write(cache_file, cache_content)
            print(f"ğŸ’¾ ä¿å­˜åˆ†æç¼“å­˜: {filename}")
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

    def find_matching_video(self, subtitle_filename: str) -> Optional[str]:
        """æ™ºèƒ½åŒ¹é…è§†é¢‘æ–‡ä»¶"""
        base_name = os.path.splitext(subtitle_filename)[0]

        # ç²¾ç¡®åŒ¹é…
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv']
        for ext in video_extensions:
            video_path = os.path.join(self.video_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path

        # æ¨¡ç³ŠåŒ¹é…
        for filename in os.listdir(self.video_folder):
            if any(filename.lower().endswith(ext) for ext in video_extensions):
                if base_name.lower() in filename.lower():
                    return os.path.join(self.video_folder, filename)

        return None

    def time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace('.', ',')
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0.0

    def check_ffmpeg(self) -> bool:
        """æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨"""
        try:
            result = platform_fix.safe_subprocess_run(
                ['ffmpeg', '-version'], 
                capture_output=True, 
                text=True
            )
            return result.returncode == 0
        except:
            return False

    def create_video_clips(self, analysis: Dict, video_file: str, subtitle_filename: str) -> List[str]:
        """åˆ›å»ºè§†é¢‘ç‰‡æ®µ"""
        created_clips = []

        if not self.check_ffmpeg():
            print("âŒ æœªæ‰¾åˆ°FFmpegï¼Œæ— æ³•å‰ªè¾‘è§†é¢‘")
            return []

        # è·å–å®Œæ•´å­—å¹•æ•°æ®ç”¨äºè¯¦ç»†è§£é‡Š
        subtitle_path = os.path.join(self.srt_folder, subtitle_filename)
        all_subtitles = self.parse_subtitle_file(subtitle_path)

        for segment in analysis.get('highlight_segments', []):
            segment_id = segment['segment_id']
            title = segment['title']

            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            safe_title = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', title)
            clip_filename = f"{safe_title}_seg{segment_id}.mp4"
            clip_path = os.path.join(self.output_folder, clip_filename)

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(clip_path) and os.path.getsize(clip_path) > 0:
                print(f"âœ… ç‰‡æ®µå·²å­˜åœ¨: {clip_filename}")
                created_clips.append(clip_path)
                continue

            # å‰ªè¾‘è§†é¢‘
            temp_clip_path = clip_path.replace(".mp4", "_temp.mp4")
            if self.create_single_clip(video_file, segment, temp_clip_path):
                # æ·»åŠ ç²¾å½©å­—å¹•æç¤º
                if self.add_highlight_subtitles(temp_clip_path, segment, clip_path):
                    created_clips.append(clip_path)
                else:
                    # å¦‚æœæ·»åŠ å­—å¹•å¤±è´¥ï¼Œåˆ™ä¿ç•™åŸå§‹å‰ªè¾‘
                    created_clips.append(temp_clip_path)
                    os.rename(temp_clip_path, clip_path)  # é‡å‘½åä¸ºæœ€ç»ˆæ–‡ä»¶å

                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_clip_path):
                    os.remove(temp_clip_path)

            # ç”Ÿæˆè¯¦ç»†çš„SRTè§£é‡Šæ–‡ä»¶ï¼ˆç‹¬ç«‹æ–‡ä»¶ï¼‰
            self.create_detailed_srt_explanation(clip_path, segment, all_subtitles)
            
            # ç”Ÿæˆæ—ç™½æ–‡ä»¶ï¼ˆé™„åŠ å­—å¹•å½¢å¼ï¼‰
            self.create_narration_file(clip_path, segment)

        return created_clips

    def create_single_clip(self, video_file: str, segment: Dict, output_path: str) -> bool:
        """åˆ›å»ºå•ä¸ªè§†é¢‘ç‰‡æ®µ"""
        try:
            start_time = segment['start_time']
            end_time = segment['end_time']

            print(f"ğŸ¬ å‰ªè¾‘ç‰‡æ®µ: {os.path.basename(output_path)}")
            print(f"   æ—¶é—´: {start_time} --> {end_time}")

            # æ—¶é—´è½¬æ¢
            start_seconds = self.time_to_seconds(start_time)
            end_seconds = self.time_to_seconds(end_time)
            duration = end_seconds - start_seconds

            if duration <= 0:
                print(f"   âŒ æ— æ•ˆæ—¶é—´æ®µ")
                return False

            # æ·»åŠ ç¼“å†²ç¡®ä¿å¯¹è¯å®Œæ•´
            buffer_start = max(0, start_seconds - 3)
            buffer_duration = duration + 6

            # FFmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', str(buffer_start),
                '-t', str(buffer_duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                '-avoid_negative_ts', 'make_zero',
                output_path,
                '-y'
            ]

            result = platform_fix.safe_subprocess_run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=300
            )

            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"   âœ… æˆåŠŸ: {file_size:.1f}MB")
                return True
            else:
                error_msg = result.stderr[:100] if result.stderr else 'æœªçŸ¥é”™è¯¯'
                print(f"   âŒ å¤±è´¥: {error_msg}")
                return False

        except Exception as e:
            print(f"   âŒ å‰ªè¾‘å¼‚å¸¸: {e}")
            return False

    def add_highlight_subtitles(self, video_path: str, segment: Dict, output_path: str) -> bool:
        """ä¸ºè§†é¢‘æ·»åŠ ç²¾å½©å­—å¹•æç¤º"""
        try:
            print(f"   ğŸ’¡ æ·»åŠ ç²¾å½©å­—å¹•æç¤º...")

            # ç”Ÿæˆç²¾å½©æç¤ºå†…å®¹
            highlights = self.generate_highlight_tips(segment)

            if not highlights:
                print(f"   âš ï¸ æ— æ³•ç”Ÿæˆå­—å¹•æç¤º")
                return False

            # è·å–è§†é¢‘æ—¶é•¿
            video_duration = segment.get('duration_seconds', 180)

            # æ„å»ºå­—å¹•æ»¤é•œ
            subtitle_filters = []

            # 1. ä¸»æ ‡é¢˜ï¼ˆå¼€å¤´3ç§’ï¼‰
            title = segment.get('title', 'ç²¾å½©ç‰‡æ®µ')[:25]
            title_clean = self.clean_text_for_ffmpeg(title)
            subtitle_filters.append(
                f"drawtext=text='{title_clean}':fontsize=24:fontcolor=white:"
                f"x=(w-text_w)/2:y=50:box=1:boxcolor=black@0.8:boxborderw=3:"
                f"enable='between(t,0,3)'"
            )

            # 2. ç²¾å½©æç¤º1ï¼ˆ3-8ç§’ï¼‰
            tip1 = self.clean_text_for_ffmpeg(highlights.get('tip1', ''))
            if tip1:
                subtitle_filters.append(
                    f"drawtext=text='ğŸ’¡ {tip1}':fontsize=18:fontcolor=yellow:"
                    f"x=(w-text_w)/2:y=(h-80):box=1:boxcolor=black@0.7:boxborderw=2:"
                    f"enable='between(t,3,8)'"
                )

            # 3. ç²¾å½©æç¤º2ï¼ˆæœ€å3ç§’ï¼‰
            tip2 = self.clean_text_for_ffmpeg(highlights.get('tip2', ''))
            if tip2 and video_duration > 8:
                start_time = max(8, video_duration - 3)
                subtitle_filters.append(
                    f"drawtext=text='ğŸ”¥ {tip2}':fontsize=18:fontcolor=lightblue:"
                    f"x=(w-text_w)/2:y=(h-40):box=1:boxcolor=black@0.6:boxborderw=2:"
                    f"enable='gte(t,{start_time})'"
                )

            if not subtitle_filters:
                print(f"   âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„å­—å¹•å†…å®¹")
                return False

            # åˆå¹¶æ‰€æœ‰æ»¤é•œ
            filter_complex = ",".join(subtitle_filters)

            # FFmpegå‘½ä»¤æ·»åŠ å­—å¹•
            cmd = [
                'ffmpeg',
                '-i', video_path,
                '-vf', filter_complex,
                '-c:a', 'copy',
                '-c:v', 'libx264',
                '-preset', 'medium',
                '-crf', '23',
                output_path,
                '-y'
            ]

            result = platform_fix.safe_subprocess_run(
                cmd,
                capture_output=True,
                text=True,
                timeout=180
            )

            success = result.returncode == 0 and os.path.exists(output_path)
            if success:
                print(f"   âœ… ç²¾å½©å­—å¹•æç¤ºæ·»åŠ æˆåŠŸ")
            else:
                error_msg = result.stderr[:100] if result.stderr else 'æœªçŸ¥é”™è¯¯'
                print(f"   âš ï¸ å­—å¹•æ·»åŠ å¤±è´¥: {error_msg}")

            return success

        except Exception as e:
            print(f"   âš ï¸ å­—å¹•å¤„ç†å¼‚å¸¸: {e}")
            return False

    def generate_highlight_tips(self, segment: Dict) -> Dict:
        """ç”Ÿæˆç²¾å½©æç¤ºå†…å®¹"""
        try:
            title = segment.get('title', '')
            significance = segment.get('plot_significance', '')
            narration = segment.get('professional_narration', '')
            
            # åŸºäºå†…å®¹æ™ºèƒ½ç”Ÿæˆæç¤º
            tips = {'tip1': '', 'tip2': ''}
            
            # æç¤º1ï¼šåŸºäºå‰§æƒ…æ„ä¹‰
            if 'ç”³è¯‰' in significance:
                tips['tip1'] = 'ç”³è¯‰ç¨‹åºå¯åŠ¨'
            elif 'å¬è¯ä¼š' in significance:
                tips['tip1'] = 'æ³•åº­æ¿€çƒˆè¾©è®º'
            elif 'è¯æ®' in significance:
                tips['tip1'] = 'å…³é”®è¯æ®å‡ºç°'
            elif 'çœŸç›¸' in significance:
                tips['tip1'] = 'çœŸç›¸å³å°†æ­éœ²'
            elif 'å†²çª' in significance:
                tips['tip1'] = 'çŸ›ç›¾è¾¾åˆ°é«˜ç‚¹'
            else:
                tips['tip1'] = 'å…³é”®å‰§æƒ…èŠ‚ç‚¹'
            
            # æç¤º2ï¼šåŸºäºæ ‡é¢˜æˆ–æ—ç™½å†…å®¹
            if 'å››äºŒå…«' in title or 'å››äºŒå…«' in narration:
                tips['tip2'] = 'å››äºŒå…«æ¡ˆå…³é”®è¿›å±•'
            elif '628' in title or '628' in narration:
                tips['tip2'] = '628æ—§æ¡ˆçº¿ç´¢'
            elif 'æ­£å½“é˜²å«' in narration:
                tips['tip2'] = 'æ­£å½“é˜²å«äº‰è®®'
            elif 'æ³•å®˜' in narration or 'æ£€å¯Ÿå®˜' in narration:
                tips['tip2'] = 'æ³•åº­ç²¾å½©å¯¹è¯'
            elif 'çˆ¶å¥³' in narration or 'äº²æƒ…' in narration:
                tips['tip2'] = 'åŠ¨äººæƒ…æ„Ÿæ—¶åˆ»'
            else:
                tips['tip2'] = 'ç²¾å½©å†…å®¹å€¼å¾—å…³æ³¨'
            
            return tips
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆç²¾å½©æç¤ºå¤±è´¥: {e}")
            return {'tip1': 'ç²¾å½©ç‰‡æ®µ', 'tip2': 'å€¼å¾—å…³æ³¨'}

    def create_detailed_srt_explanation(self, video_path: str, segment: Dict, subtitles: List[Dict]):
        """åˆ›å»ºè¯¦ç»†çš„SRTè§£é‡Šæ–‡ä»¶ï¼ˆç‹¬ç«‹æ–‡ä»¶ï¼Œä¸åµŒå…¥è§†é¢‘ï¼‰"""
        try:
            srt_explanation_path = video_path.replace('.mp4', '_SRTè¯¦ç»†è§£é‡Š.txt')
            
            # è·å–ç‰‡æ®µå¯¹åº”çš„å­—å¹•
            start_time = segment['start_time']
            end_time = segment['end_time']
            
            segment_subtitles = []
            for sub in subtitles:
                sub_start = self.time_to_seconds(sub['start'])
                segment_start = self.time_to_seconds(start_time)
                segment_end = self.time_to_seconds(end_time)
                
                if segment_start <= sub_start <= segment_end:
                    segment_subtitles.append(sub)
            
            content = f"""ğŸ“ {segment['title']} - SRTå­—å¹•è¯¦ç»†è§£é‡Š
{"=" * 80}

â° ç‰‡æ®µæ—¶é—´: {start_time} --> {end_time}
ğŸ“º å‰§æƒ…æ„ä¹‰: {segment.get('plot_significance', 'å…³é”®å‰§æƒ…èŠ‚ç‚¹')}

ğŸ“– é€å¥å­—å¹•è§£é‡Š:
{"=" * 40}

"""
            
            for i, sub in enumerate(segment_subtitles, 1):
                content += f"{i:2d}. [{sub['start']} --> {sub['end']}]\n"
                content += f"    å°è¯: {sub['text']}\n"
                
                # æ™ºèƒ½åˆ†ææ¯å¥å°è¯çš„é‡è¦æ€§
                analysis = self.analyze_dialogue_significance(sub['text'], segment)
                if analysis:
                    content += f"    è§£é‡Š: {analysis}\n"
                content += "\n"
            
            # æ·»åŠ æ•´ä½“è§£è¯»
            content += f"""
ğŸ“Š ç‰‡æ®µæ•´ä½“è§£è¯»:
{"=" * 40}
â€¢ æ ¸å¿ƒçœ‹ç‚¹: {segment.get('professional_narration', 'ç²¾å½©å‰§æƒ…å‘å±•')}
â€¢ æƒ…æ„ŸåŸºè°ƒ: {self.analyze_emotional_tone_from_text(segment.get('professional_narration', ''))}
â€¢ å‰§æƒ…ä»·å€¼: è¯¥ç‰‡æ®µå±•ç°äº†{segment.get('plot_significance', 'é‡è¦å‰§æƒ…è½¬æŠ˜')}
â€¢ è§‚ä¼—ä½“éªŒ: é€šè¿‡è¿™ä¸ªç‰‡æ®µï¼Œè§‚ä¼—å¯ä»¥æ·±å…¥ç†è§£è§’è‰²å¿ƒç†å’Œæ•…äº‹å‘å±•

ğŸ’¡ é€šä¿—æ˜“æ‡‚è¯´æ˜:
ç®€å•æ¥è¯´ï¼Œè¿™ä¸ªç‰‡æ®µå°±æ˜¯{self.generate_simple_explanation(segment)}

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            
            platform_fix.safe_file_write(srt_explanation_path, content)
            print(f"   ğŸ“ ç”ŸæˆSRTè¯¦ç»†è§£é‡Š: {os.path.basename(srt_explanation_path)}")
            
        except Exception as e:
            print(f"   âš ï¸ SRTè§£é‡Šæ–‡ä»¶ç”Ÿæˆå¤±è´¥: {e}")

    def create_narration_file(self, video_path: str, segment: Dict):
        """åˆ›å»ºä¸“ä¸šæ—ç™½è§£è¯´æ–‡ä»¶ï¼ˆé™„åŠ å­—å¹•å½¢å¼ï¼‰"""
        try:
            narration_path = video_path.replace('.mp4', '_æ—ç™½è§£è¯´.txt')

            # ç”Ÿæˆå¤šå±‚æ¬¡æ—ç™½å†…å®¹
            narration_content = self.generate_layered_narration(segment)

            content = f"""ğŸ™ï¸ {segment['title']} - ä¸“ä¸šæ—ç™½è§£è¯´
{"=" * 60}

ğŸ¬ ç‰‡æ®µä¿¡æ¯:
â€¢ æ ‡é¢˜: {segment['title']}
â€¢ æ—¶é•¿: {segment.get('duration_seconds', 0)} ç§’
â€¢ å‰§æƒ…æ„ä¹‰: {segment.get('plot_significance', 'å…³é”®å‰§æƒ…èŠ‚ç‚¹')}

ğŸ“º æ—ç™½å†…å®¹ï¼ˆé™„åŠ å­—å¹•å½¢å¼ï¼‰:
{"=" * 40}

ğŸ¤ å¼€åœºè§£è¯´ (0-3ç§’):
{narration_content['opening']}

ğŸ¤ è¿‡ç¨‹è§£è¯´ (3-8ç§’):
{narration_content['process']}

ğŸ¤ ç²¾å½©æç¤º (æœ€å3ç§’):
{narration_content['highlight']}

ğŸ¤ ç®€çŸ­å­—å¹•æç¤º:
â€¢ äº®ç‚¹1: {narration_content['tip1']}
â€¢ äº®ç‚¹2: {narration_content['tip2']}

ğŸ’¬ å®Œæ•´æ—ç™½ç¨¿:
{narration_content['full_script']}

ğŸ¯ ä½¿ç”¨è¯´æ˜:
è¿™äº›æ—ç™½å†…å®¹è®¾è®¡ä¸º"é™„åŠ å­—å¹•"ï¼Œå¯ä»¥åœ¨è§†é¢‘æ’­æ”¾æ—¶ä»¥å­—å¹•å½¢å¼å‡ºç°ï¼Œ
ä¸ºè§‚ä¼—æä¾›é¢å¤–çš„è§£é‡Šå’Œæç¤ºï¼Œå¢å¼ºè§‚çœ‹ä½“éªŒã€‚

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

            platform_fix.safe_file_write(narration_path, content)

            print(f"   ğŸ“œ ç”Ÿæˆæ—ç™½è§£è¯´: {os.path.basename(narration_path)}")

        except Exception as e:
            print(f"   âš ï¸ æ—ç™½æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {e}")

    def analyze_dialogue_significance(self, dialogue: str, segment: Dict) -> str:
        """åˆ†æå•å¥å°è¯çš„é‡è¦æ€§"""
        if not dialogue or len(dialogue.strip()) < 3:
            return ""
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®ä¿¡æ¯
        key_indicators = {
            'æ¡ˆä»¶': 'æ¶‰åŠæ¡ˆä»¶å…³é”®ä¿¡æ¯',
            'è¯æ®': 'é‡è¦è¯æ®ç›¸å…³',
            'çœŸç›¸': 'çœŸç›¸æ­éœ²æ—¶åˆ»',
            'æ³•åº­': 'æ³•åº­ç¨‹åºè¿›å±•',
            'ç”³è¯‰': 'ç”³è¯‰ç¨‹åºå…³é”®',
            'å¬è¯ä¼š': 'å¬è¯ä¼šé‡è¦å†…å®¹',
            'æ­£å½“é˜²å«': 'æ­£å½“é˜²å«äº‰è®®ç„¦ç‚¹',
            'å››äºŒå…«': 'å››äºŒå…«æ¡ˆæ ¸å¿ƒå†…å®¹',
            '628': '628æ—§æ¡ˆç›¸å…³',
            'å†³å®š': 'é‡è¦å†³ç­–æ—¶åˆ»',
            'å‘ç°': 'æ–°å‘ç°æˆ–çº¿ç´¢',
            'é—®é¢˜': 'å…³é”®é—®é¢˜æå‡º',
            'æ€ä¹ˆ': 'ç–‘é—®æˆ–è´¨ç–‘',
            'ä¸ºä»€ä¹ˆ': 'åŸå› æ¢ç©¶',
            'ä¸æ˜¯': 'å¦å®šæˆ–åé©³',
            'ä½†æ˜¯': 'è½¬æŠ˜æˆ–å¯¹æ¯”',
            'å¦‚æœ': 'å‡è®¾æˆ–æ¨ç†'
        }
        
        for keyword, explanation in key_indicators.items():
            if keyword in dialogue:
                return f"{explanation} - è¿™å¥è¯ç‚¹å‡ºäº†{keyword}ç›¸å…³çš„é‡è¦ä¿¡æ¯"
        
        # æƒ…æ„Ÿåˆ†æ
        if any(word in dialogue for word in ['æ„¤æ€’', 'ç”Ÿæ°”', 'æ¿€åŠ¨', 'ç€æ€¥']):
            return "æƒ…æ„Ÿæ¿€çƒˆ - è§’è‰²æƒ…ç»ªè¾¾åˆ°é«˜ç‚¹ï¼Œæ¨åŠ¨å‰§æƒ…å‘å±•"
        elif any(word in dialogue for word in ['æ‹…å¿ƒ', 'å®³æ€•', 'ç´§å¼ ']):
            return "æƒ…æ„Ÿç´§å¼  - è¥é€ ç´§å¼ æ°›å›´ï¼Œå¢å¼ºæˆå‰§æ•ˆæœ"
        elif any(word in dialogue for word in ['æ„ŸåŠ¨', 'æ¸©æš–', 'ç†è§£']):
            return "æƒ…æ„Ÿæ¸©æš– - å±•ç°äººç‰©æƒ…æ„Ÿæ·±åº¦å’Œå…³ç³»å˜åŒ–"
        
        # å¯¹è¯åŠŸèƒ½åˆ†æ
        if 'ï¼Ÿ' in dialogue or 'å—' in dialogue:
            return "ç–‘é—®å¥ - æ¨è¿›å¯¹è¯å‘å±•ï¼Œå¼•å‡ºé‡è¦ä¿¡æ¯"
        elif 'ï¼' in dialogue:
            return "æ„Ÿå¹å¥ - è¡¨è¾¾å¼ºçƒˆæƒ…æ„Ÿï¼Œå¢å¼ºæˆå‰§å¼ åŠ›"
        elif len(dialogue) > 20:
            return "è¯¦ç»†è¡¨è¿° - åŒ…å«é‡è¦ä¿¡æ¯æˆ–å¤æ‚æƒ…æ„Ÿè¡¨è¾¾"
        
        return "æ¨è¿›å¯¹è¯ - ç»´æŒå‰§æƒ…è¿è´¯æ€§å’Œè§’è‰²äº’åŠ¨"

    def analyze_emotional_tone_from_text(self, text: str) -> str:
        """ä»æ–‡æœ¬åˆ†ææƒ…æ„ŸåŸºè°ƒ"""
        if not text:
            return "ä¸­æ€§"
        
        positive_words = ['æ¸©æš–', 'æ„ŸåŠ¨', 'å¸Œæœ›', 'å¼€å¿ƒ', 'é«˜å…´', 'å¿«ä¹', 'å¹¸ç¦']
        negative_words = ['ç—›è‹¦', 'æ‚²ä¼¤', 'æ„¤æ€’', 'ç»æœ›', 'éš¾è¿‡', 'æ²®ä¸§', 'å¤±æœ›']
        tense_words = ['ç´§å¼ ', 'å±é™©', 'å†²çª', 'äº‰è®º', 'æ¿€çƒˆ', 'æ€¥è¿«', 'å…³é”®']
        
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        tense_count = sum(1 for word in tense_words if word in text)
        
        if tense_count > max(positive_count, negative_count):
            return "ç´§å¼ æ¿€çƒˆ"
        elif positive_count > negative_count:
            return "ç§¯ææ¸©æš–"
        elif negative_count > positive_count:
            return "æ²‰é‡å‹æŠ‘"
        else:
            return "å¹³ç¨³æ¨è¿›"

    def generate_simple_explanation(self, segment: Dict) -> str:
        """ç”Ÿæˆé€šä¿—æ˜“æ‡‚çš„è§£é‡Š"""
        title = segment.get('title', '')
        significance = segment.get('plot_significance', '')
        
        # æ ¹æ®å†…å®¹ç”Ÿæˆç®€å•è§£é‡Š
        if 'ç”³è¯‰' in title or 'ç”³è¯‰' in significance:
            return "å½“äº‹äººå¼€å§‹ä¸ºæ¡ˆä»¶é‡æ–°ç”³è¯·å®¡ç†ï¼Œå¸Œæœ›èƒ½ç¿»æ¡ˆ"
        elif 'å¬è¯ä¼š' in title or 'å¬è¯ä¼š' in significance:
            return "æ³•å®˜å¬å–å„æ–¹æ„è§ï¼Œå†³å®šæ˜¯å¦é‡æ–°å®¡ç†æ¡ˆä»¶"
        elif 'è¯æ®' in title or 'è¯æ®' in significance:
            return "å‘ç°äº†æ–°çš„é‡è¦è¯æ®ï¼Œå¯èƒ½æ”¹å˜æ¡ˆä»¶ç»“æœ"
        elif 'çœŸç›¸' in title or 'çœŸç›¸' in significance:
            return "äº‹æƒ…çš„çœŸå®æƒ…å†µå¼€å§‹æµ®ç°ï¼Œä¹‹å‰çš„åˆ¤æ–­å¯èƒ½æœ‰è¯¯"
        elif 'å†²çª' in significance or 'äº‰è®º' in significance:
            return "ä¸åŒè§‚ç‚¹å‘ç”Ÿæ¿€çƒˆç¢°æ’ï¼ŒçŸ›ç›¾è¾¾åˆ°é«˜ç‚¹"
        elif 'æƒ…æ„Ÿ' in significance:
            return "è§’è‰²çš„å†…å¿ƒæƒ…æ„Ÿå¾—åˆ°æ·±åº¦å±•ç°ï¼Œè§¦åŠ¨äººå¿ƒ"
        else:
            return "å‰§æƒ…å‡ºç°é‡è¦å‘å±•ï¼Œå€¼å¾—è§‚ä¼—é‡ç‚¹å…³æ³¨"

    def generate_layered_narration(self, segment: Dict) -> Dict:
        """ç”Ÿæˆå¤šå±‚æ¬¡æ—ç™½å†…å®¹"""
        title = segment.get('title', 'ç²¾å½©ç‰‡æ®µ')
        significance = segment.get('plot_significance', '')
        professional_narration = segment.get('professional_narration', '')
        
        # å¼€åœºè§£è¯´
        opening = f"æ¥ä¸‹æ¥çš„ç‰‡æ®µå±•ç°äº†{title.split('ï¼š')[-1] if 'ï¼š' in title else title}"
        
        # è¿‡ç¨‹è§£è¯´
        if 'ç”³è¯‰' in significance:
            process = "æˆ‘ä»¬çœ‹åˆ°å½“äº‹äººæ­£å¼å¯åŠ¨æ³•å¾‹ç¨‹åºï¼Œä¸ºæ¡ˆä»¶å¯»æ±‚æ–°çš„å®¡ç†æœºä¼š"
        elif 'å¬è¯ä¼š' in significance:
            process = "æ³•åº­ä¸Šå„æ–¹æ¿€çƒˆè¾©è®ºï¼Œæ¯ä¸€ä¸ªç»†èŠ‚éƒ½å¯èƒ½å½±å“æœ€ç»ˆç»“æœ"
        elif 'è¯æ®' in significance:
            process = "å…³é”®è¯æ®çš„å‡ºç°ï¼Œè®©æ¡ˆä»¶å‡ºç°äº†æ–°çš„è½¬æœº"
        elif 'çœŸç›¸' in significance:
            process = "éšè—çš„çœŸç›¸é€æ¸æµ®å‡ºæ°´é¢ï¼Œäº‹æƒ…çš„æœ¬è´¨å¼€å§‹æ¸…æ™°"
        else:
            process = "å‰§æƒ…å‘å±•åˆ°å…³é”®èŠ‚ç‚¹ï¼Œè§’è‰²é¢ä¸´é‡è¦é€‰æ‹©"
        
        # ç²¾å½©æç¤º
        if 'æ³•å¾‹' in significance or 'æ¡ˆä»¶' in significance:
            highlight = "ğŸ’¡ æ³•å¾‹æ™ºæ…§ï¼šæ³¨æ„è§‚å¯Ÿæ³•ç†ä¸äººæƒ…çš„åšå¼ˆ"
        elif 'æƒ…æ„Ÿ' in significance:
            highlight = "ğŸ’¡ æƒ…æ„Ÿå…±é¸£ï¼šæ„Ÿå—è§’è‰²å†…å¿ƒçš„å¤æ‚æƒ…æ„Ÿ"
        elif 'å†²çª' in significance:
            highlight = "ğŸ’¡ æˆå‰§å¼ åŠ›ï¼šè§‚å¯ŸçŸ›ç›¾å¦‚ä½•æ¨å‘é«˜æ½®"
        else:
            highlight = "ğŸ’¡ å‰§æƒ…å…³é”®ï¼šè¿™é‡Œçš„ç»†èŠ‚å¾ˆé‡è¦ï¼Œå€¼å¾—ä»”ç»†è§‚çœ‹"
        
        # ç®€çŸ­å­—å¹•æç¤º
        tip1 = "å…³é”®çœ‹ç‚¹"
        tip2 = "ç²¾å½©æ—¶åˆ»"
        
        if 'è¯æ®' in significance:
            tip1 = "æ–°è¯æ®å‡ºç°"
            tip2 = "æ¡ˆä»¶è½¬æœº"
        elif 'å¬è¯ä¼š' in significance:
            tip1 = "æ³•åº­è¾©è®º"
            tip2 = "å…³é”®äº‰è®®"
        elif 'ç”³è¯‰' in significance:
            tip1 = "ç”³è¯‰å¯åŠ¨"
            tip2 = "å¸Œæœ›é‡ç‡ƒ"
        
        # å®Œæ•´æ—ç™½ç¨¿
        full_script = f"{opening}ã€‚{process}ã€‚{highlight}"
        
        return {
            'opening': opening,
            'process': process,
            'highlight': highlight,
            'tip1': tip1,
            'tip2': tip2,
            'full_script': full_script
        }

    def process_single_episode(self, subtitle_file: str) -> Optional[bool]:
        """å¤„ç†å•é›†å®Œæ•´æµç¨‹"""
        print(f"\nğŸ“º å¤„ç†: {subtitle_file}")

        # 1. è§£æå­—å¹•
        subtitle_path = os.path.join(self.srt_folder, subtitle_file)
        subtitles = self.parse_subtitle_file(subtitle_path)

        if not subtitles:
            print(f"âŒ å­—å¹•è§£æå¤±è´¥")
            return False

        # 2. AIåˆ†æ
        analysis = self.analyze_episode_with_ai(subtitles, subtitle_file)
        if analysis is None:
            print(f"â¸ï¸ AIä¸å¯ç”¨ï¼Œ{subtitle_file} å·²è·³è¿‡")
            return None
        elif not analysis:
            print(f"âŒ AIåˆ†æå¤±è´¥ï¼Œè·³è¿‡æ­¤é›†")
            return False

        # 3. æ‰¾åˆ°è§†é¢‘æ–‡ä»¶
        video_file = self.find_matching_video(subtitle_file)
        if not video_file:
            print(f"âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return False

        print(f"ğŸ“ è§†é¢‘æ–‡ä»¶: {os.path.basename(video_file)}")

        # 4. åˆ›å»ºè§†é¢‘ç‰‡æ®µ
        created_clips = self.create_video_clips(analysis, video_file, subtitle_file)

        clips_count = len(created_clips)
        print(f"âœ… {subtitle_file} å¤„ç†å®Œæˆ: {clips_count} ä¸ªçŸ­è§†é¢‘")

        return clips_count > 0

    def process_all_episodes(self):
        """å¤„ç†æ‰€æœ‰é›†æ•° - ä¸»æµç¨‹"""
        print("\nğŸš€ å¼€å§‹æ™ºèƒ½å‰ªè¾‘å¤„ç†")
        print("=" * 50)

        # æ£€æŸ¥å­—å¹•æ–‡ä»¶
        subtitle_files = [f for f in os.listdir(self.srt_folder) 
                         if f.endswith(('.srt', '.txt')) and not f.startswith('.')]

        if not subtitle_files:
            print(f"âŒ {self.srt_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            return

        # æŒ‰å­—ç¬¦ä¸²æ’åºï¼ˆå³æŒ‰æ–‡ä»¶åæ’åºï¼‰
        subtitle_files.sort()

        print(f"ğŸ“ æ‰¾åˆ° {len(subtitle_files)} ä¸ªå­—å¹•æ–‡ä»¶")

        # å¤„ç†æ¯ä¸€é›†
        total_success = 0
        total_clips = 0
        total_skipped = 0

        for subtitle_file in subtitle_files:
            try:
                success = self.process_single_episode(subtitle_file)
                if success:
                    total_success += 1
                elif success is None:
                    total_skipped += 1

                # ç»Ÿè®¡ç‰‡æ®µæ•°
                episode_clips = [f for f in os.listdir(self.output_folder) 
                               if f.endswith('.mp4')]
                total_clips = len(episode_clips)

            except Exception as e:
                print(f"âŒ å¤„ç† {subtitle_file} å‡ºé”™: {e}")

        # æœ€ç»ˆæŠ¥å‘Š
        print(f"\nğŸ“Š å¤„ç†å®Œæˆ:")
        print(f"âœ… æˆåŠŸå¤„ç†: {total_success}/{len(subtitle_files)} é›†")
        print(f"ğŸ¬ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª")
        print(f"â¸ï¸ è·³è¿‡é›†æ•°: {total_skipped} é›†")

    def install_dependencies(self):
        """å®‰è£…å¿…è¦ä¾èµ–"""
        print("ğŸ”§ æ£€æŸ¥å¹¶å®‰è£…å¿…è¦ä¾èµ–...")

        dependencies = ['openai', 'google-genai']

        for package in dependencies:
            try:
                __import__(package.replace('-', '_'))
                print(f"âœ… {package} å·²å®‰è£…")
            except ImportError:
                print(f"ğŸ“¦ å®‰è£… {package}...")
                try:
                    result = platform_fix.safe_subprocess_run(
                        [sys.executable, '-m', 'pip', 'install', package],
                        capture_output=True,
                        text=True
                    )
                    if result.returncode == 0:
                        print(f"âœ… {package} å®‰è£…æˆåŠŸ")
                    else:
                        print(f"âŒ {package} å®‰è£…å¤±è´¥: {result.stderr}")
                except Exception as e:
                    print(f"âŒ {package} å®‰è£…å¤±è´¥: {e}")

    def clear_cache(self):
        """æ¸…ç©ºåˆ†æç¼“å­˜"""
        import shutil
        if os.path.exists(self.cache_folder):
            shutil.rmtree(self.cache_folder)
            os.makedirs(self.cache_folder)
            print(f"âœ… å·²æ¸…ç©ºåˆ†æç¼“å­˜")
        else:
            print(f"ğŸ“ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")

    def show_file_status(self):
        """æ˜¾ç¤ºæ–‡ä»¶çŠ¶æ€"""
        srt_files = [f for f in os.listdir(self.srt_folder) if f.endswith(('.srt', '.txt'))]
        video_files = [f for f in os.listdir(self.video_folder) if f.endswith(('.mp4', '.mkv', '.avi'))]
        output_files = [f for f in os.listdir(self.output_folder) if f.endswith('.mp4')]

        print(f"\nğŸ“Š æ–‡ä»¶çŠ¶æ€:")
        print(f"ğŸ“ å­—å¹•æ–‡ä»¶: {len(srt_files)} ä¸ª")
        if srt_files:
            for f in srt_files[:5]:
                print(f"   â€¢ {f}")
            if len(srt_files) > 5:
                print(f"   â€¢ ... è¿˜æœ‰ {len(srt_files)-5} ä¸ªæ–‡ä»¶")

        print(f"ğŸ¬ è§†é¢‘æ–‡ä»¶: {len(video_files)} ä¸ª")
        if video_files:
            for f in video_files[:5]:
                print(f"   â€¢ {f}")
            if len(video_files) > 5:
                print(f"   â€¢ ... è¿˜æœ‰ {len(video_files)-5} ä¸ªæ–‡ä»¶")

        print(f"ğŸ“¤ è¾“å‡ºè§†é¢‘: {len(output_files)} ä¸ª")

    def show_main_menu(self):
        """ä¸»èœå•"""
        while True:
            print("\n" + "=" * 50)
            print("ğŸ¬ ç”µè§†å‰§æ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿ")
            print("=" * 50)

            # æ˜¾ç¤ºçŠ¶æ€
            ai_status = "ğŸ¤– å·²é…ç½®" if self.ai_config.get('enabled') else "âŒ æœªé…ç½®"
            print(f"AIçŠ¶æ€: {ai_status}")

            print("\nğŸ¯ ä¸»è¦åŠŸèƒ½:")
            print("1. ğŸ¤– é…ç½®AIæ¥å£")
            print("2. ğŸ¬ å¼€å§‹æ™ºèƒ½å‰ªè¾‘")
            print("3. ğŸ“ æŸ¥çœ‹æ–‡ä»¶çŠ¶æ€")
            print("4. ğŸ”§ å®‰è£…ç³»ç»Ÿä¾èµ–")
            print("5. ğŸ”„ æ¸…ç©ºåˆ†æç¼“å­˜")
            print("0. âŒ é€€å‡ºç³»ç»Ÿ")

            try:
                choice = input("\nè¯·é€‰æ‹©æ“ä½œ (0-5): ").strip()

                if choice == '1':
                    self.configure_ai_interactive()
                elif choice == '2':
                    self.process_all_episodes()
                elif choice == '3':
                    self.show_file_status()
                elif choice == '4':
                    self.install_dependencies()
                elif choice == '5':
                    self.clear_cache()
                elif choice == '0':
                    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ç”µè§†å‰§æ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿï¼")
                    break
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥0-5")

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                print(f"âŒ æ“ä½œé”™è¯¯: {e}")

    def generate_segment_narration(self, segment: Dict) -> Dict:
        """ç”Ÿæˆç‰‡æ®µæ—ç™½å†…å®¹"""
        if not self.ai_config.get('enabled'):
            return {}

        try:
            title = segment.get('title', 'ç²¾å½©ç‰‡æ®µ')
            plot_significance = segment.get('plot_significance', 'å…³é”®å‰§æƒ…èŠ‚ç‚¹')
            professional_narration = segment.get('professional_narration', 'ç²¾å½©å‰§æƒ…ç‰‡æ®µ')
            highlight_tip = segment.get('highlight_tip', 'ä¸€å¥è¯äº®ç‚¹')

            prompt = f"""# æ—ç™½å†…å®¹ç”Ÿæˆ

è¯·ä¸ºä»¥ä¸‹ç”µè§†å‰§ç‰‡æ®µç”Ÿæˆæ›´ä¸“ä¸šçš„æ—ç™½å†…å®¹ï¼š

## ç‰‡æ®µä¿¡æ¯
â€¢ æ ‡é¢˜: {title}
â€¢ å‰§æƒ…æ„ä¹‰: {plot_significance}
â€¢ è§£è¯´ç¨¿: {professional_narration}
â€¢ äº®ç‚¹æç¤º: {highlight_tip}

## ç”Ÿæˆè¦æ±‚
1. ä¸»é¢˜è§£è¯´ï¼šæ¦‚æ‹¬ç‰‡æ®µæ ¸å¿ƒçœ‹ç‚¹ï¼Œ1-2å¥è¯
2. å­—å¹•äº®ç‚¹ï¼šç”Ÿæˆå¸å¼•çœ¼çƒçš„å­—å¹•äº®ç‚¹æç¤ºï¼Œ1å¥è¯

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{{
    "main_explanation": "ç‰‡æ®µæ ¸å¿ƒçœ‹ç‚¹",
    "highlight_tip": "å¸å¼•çœ¼çƒçš„å­—å¹•äº®ç‚¹æç¤º"
}}
```"""

            system_prompt = "ä½ æ˜¯ä¸“ä¸šçš„å½±è§†å†…å®¹åˆ›ä½œä¸“å®¶ï¼Œä¸“é•¿ç”µè§†å‰§æƒ…æ·±åº¦è§£è¯´ä¸å™äº‹å¸å¼•ã€‚"

            response = self.call_ai_api(prompt, system_prompt)
            if response:
                narration = self.parse_narration_response(response)
                return narration

        except Exception as e:
            print(f"âš ï¸ æ—ç™½ç”Ÿæˆå¤±è´¥: {e}")
            return {}

    def parse_narration_response(self, response: str) -> Dict:
        """è§£ææ—ç™½ç”Ÿæˆå“åº”"""
        try:
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_text = response[start:end]
            else:
                start = response.find("{")
                end = response.rfind("}") + 1
                json_text = response[start:end]

            result = json.loads(json_text)
            return result

        except Exception as e:
            print(f"âš ï¸ æ—ç™½è§£æå¤±è´¥: {e}")
            return {}

    def clean_text_for_ffmpeg(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ç”¨äºFFmpeg"""
        return text.replace("'", "").replace('"', '').replace(':', '-').replace('\n', ' ')

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    clipper = IntelligentTVClipper()
    
    if len(sys.argv) > 1 and sys.argv[1] == '--menu':
        clipper.show_main_menu()
    else:
        clipper.process_all_episodes()

if __name__ == "__main__":
    main()
