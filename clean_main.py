#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œæ•´æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ - æœ€ç»ˆç¨³å®šç‰ˆ
è§£å†³æ‰€æœ‰16ä¸ªæ ¸å¿ƒé—®é¢˜çš„å®Œæ•´æ–¹æ¡ˆ
"""

import os
import re
import json
import subprocess
import hashlib
import time
from typing import List, Dict, Optional, Tuple
from datetime import datetime
import time
import requests
from movie_ai_clipper import MovieAIClipper

class CompleteIntelligentTVClipper:
    """å®Œæ•´æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ - ç¨³å®šç‰ˆ"""

    def __init__(self):
        # ç›®å½•ç»“æ„
        self.srt_folder = "srt"
        self.videos_folder = "videos"
        self.clips_folder = "clips"
        self.cache_folder = "cache"
        self.reports_folder = "reports"
        self.analysis_cache_folder = "analysis_cache"
        self.clip_status_folder = "clip_status"

        # åˆ›å»ºå¿…è¦ç›®å½•
        for folder in [self.srt_folder, self.videos_folder, self.clips_folder, 
                      self.cache_folder, self.reports_folder, self.analysis_cache_folder, self.clip_status_folder]:
            os.makedirs(folder, exist_ok=True)

        # å‰§æƒ…ç‚¹åˆ†ç±»é…ç½®
        self.plot_point_types = {
            'å…³é”®å†²çª': {
                'keywords': ['å†²çª', 'äº‰æ‰§', 'å¯¹æŠ—', 'è´¨ç–‘', 'åé©³', 'äº‰è®®', 'æ¿€çƒˆ', 'æ„¤æ€’', 'ä¸åŒæ„', 'çŸ›ç›¾', 'äº‰è®º', 'è¾©è®º', 'åå¯¹', 'æŠ—è®®'],
                'weight': 10,
                'ideal_duration': 180,
                'min_score': 15
            },
            'äººç‰©è½¬æŠ˜': {
                'keywords': ['å†³å®š', 'æ”¹å˜', 'é€‰æ‹©', 'è½¬å˜', 'è§‰æ‚Ÿ', 'æ˜ç™½', 'æ„è¯†åˆ°', 'å‘ç°è‡ªå·±', 'æˆé•¿', 'çªç ´', 'èœ•å˜', 'é†’æ‚Ÿ', 'é¢†æ‚Ÿ'],
                'weight': 9,
                'ideal_duration': 150,
                'min_score': 12
            },
            'çº¿ç´¢æ­éœ²': {
                'keywords': ['å‘ç°', 'æ­éœ²', 'çœŸç›¸', 'è¯æ®', 'çº¿ç´¢', 'ç§˜å¯†', 'æš´éœ²', 'è¯æ˜', 'æ‰¾åˆ°', 'æ›å…‰', 'æŠ«éœ²', 'æ­ç¤º', 'æ˜¾éœ²'],
                'weight': 8,
                'ideal_duration': 160,
                'min_score': 10
            },
            'æƒ…æ„Ÿçˆ†å‘': {
                'keywords': ['å“­', 'ç—›è‹¦', 'ç»æœ›', 'æ„¤æ€’', 'æ¿€åŠ¨', 'å´©æºƒ', 'å¿ƒç—›', 'æ„ŸåŠ¨', 'éœ‡æ’¼', 'æ³ªæ°´', 'æ‚²ä¼¤', 'çœ¼æ³ª', 'å“½å’½'],
                'weight': 7,
                'ideal_duration': 140,
                'min_score': 8
            },
            'é‡è¦å¯¹è¯': {
                'keywords': ['å‘Šè¯‰', 'æ‰¿è®¤', 'å¦ç™½', 'è§£é‡Š', 'æ¾„æ¸…', 'è¯´æ˜', 'è¡¨æ€', 'ä¿è¯', 'æ‰¿è¯º', 'å®£å¸ƒ', 'å£°æ˜', 'äº¤ä»£'],
                'weight': 6,
                'ideal_duration': 170,
                'min_score': 6
            },
            'ä¸»é¢˜å‡å': {
                'keywords': ['æ­£ä¹‰', 'çœŸç†', 'ä¿¡å¿µ', 'åšæŒ', 'å¸Œæœ›', 'ä¿¡ä»»', 'è´£ä»»', 'ä½¿å‘½', 'ä»·å€¼', 'æ„ä¹‰', 'ç²¾ç¥', 'ç†æƒ³'],
                'weight': 8,
                'ideal_duration': 160,
                'min_score': 8
            }
        }

        # é”™åˆ«å­—ä¿®æ­£åº“
        self.corrections = {
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'å¯©åˆ¤': 'å®¡åˆ¤', 'è¾¯è­·': 'è¾©æŠ¤', 'èµ·è¨´': 'èµ·è¯‰', 'èª¿æŸ¥': 'è°ƒæŸ¥',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'è½è­‰æœƒ': 'å¬è¯ä¼š',
            'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'é–‹å§‹': 'å¼€å§‹', 'çµæŸ': 'ç»“æŸ',
            'è¨¼äºº': 'è¯äºº', 'è¨¼è¨€': 'è¯è¨€', 'å®Ÿç¾': 'å®ç°', 'å¯¾è©±': 'å¯¹è¯',
            'é–¢ä¿‚': 'å…³ç³»', 'å®Ÿé™…': 'å®é™…', 'å¯¾äº': 'å¯¹äº', 'å¤‰åŒ–': 'å˜åŒ–',
            'ç„¡ç½ª': 'æ— ç½ª', 'æœ‰ç½ª': 'æœ‰ç½ª', 'æ¤œå¯Ÿ': 'æ£€å¯Ÿ', 'å¼è­·': 'è¾©æŠ¤'
        }

        # å…¨å‰§ä¸Šä¸‹æ–‡ç®¡ç†
        self.series_context = {
            'previous_episodes': [],
            'main_storylines': [],
            'character_arcs': {},
            'ongoing_conflicts': [],
            'genre_detected': None,
            'main_themes': []
        }

        # åŠ è½½AIé…ç½®
        self.ai_config = self._load_ai_config()

        print("ğŸ¤– AIä¸“ç”¨æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿå·²å¯åŠ¨")
        print(f"ğŸ“ å­—å¹•ç›®å½•: {self.srt_folder}/")
        print(f"ğŸ¬ è§†é¢‘ç›®å½•: {self.videos_folder}/")
        print(f"ğŸ“¤ è¾“å‡ºç›®å½•: {self.clips_folder}/")
        print(f"ğŸ’¾ ç¼“å­˜ç³»ç»Ÿ: å¯ç”¨")
        print("âš ï¸ æ³¨æ„ï¼šæœ¬ç³»ç»Ÿåªä½¿ç”¨AIåˆ†æï¼Œéœ€è¦é…ç½®AIæ¥å£")

    def _load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            if os.path.exists('.ai_config.json'):
                with open('.ai_config.json', 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    if config.get('enabled', False):
                        api_type = config.get('api_type', 'proxy')
                        provider = config.get('provider', 'unknown')
                        print(f"ğŸ¤– AIåˆ†æå·²å¯ç”¨: {api_type} - {provider}")
                        return config
        except Exception as e:
            print(f"âš ï¸ AIé…ç½®åŠ è½½å¤±è´¥: {e}")

        print("âŒ AIåˆ†ææœªå¯ç”¨ï¼Œç³»ç»Ÿæ— æ³•å·¥ä½œ")
        print("ğŸ’¡ è¯·é…ç½®AIæ¥å£åé‡æ–°å¯åŠ¨")
        return {'enabled': False}

    def _save_ai_config(self, config: Dict) -> bool:
        """ä¿å­˜AIé…ç½®"""
        try:
            with open('.ai_config.json', 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            return True
        except Exception as e:
            print(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {e}")
            return False

    def configure_ai_interactive(self):
        """æ™ºèƒ½AIé…ç½®æ£€æŸ¥"""
        print("\nğŸ¤– AIé…ç½®æ£€æŸ¥")
        print("=" * 50)

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æœ‰æ•ˆé…ç½®
        if self.ai_config.get('enabled') and self.ai_config.get('api_key'):
            print("âœ… å‘ç°å·²æœ‰AIé…ç½®:")
            print(f"   æœåŠ¡å•†: {self.ai_config.get('provider', 'æœªçŸ¥')}")
            print(f"   æ¨¡å‹: {self.ai_config.get('model', 'æœªçŸ¥')}")
            if self.ai_config.get('base_url'):
                print(f"   åœ°å€: {self.ai_config['base_url']}")
            print(f"   å¯†é’¥: {self.ai_config.get('api_key', '')[:10]}...")
            
            # æµ‹è¯•è¿æ¥
            print("\nğŸ” æµ‹è¯•è¿æ¥...")
            if self._test_existing_config():
                print("âœ… AIé…ç½®æ­£å¸¸ï¼Œç›´æ¥ä½¿ç”¨")
                return
            else:
                print("âš ï¸ è¿æ¥æµ‹è¯•å¤±è´¥")
        
        # å¦‚æœæ²¡æœ‰é…ç½®æˆ–é…ç½®æ— æ•ˆï¼Œæ‰è¿›è¡Œäº¤äº’å¼é…ç½®
        print("\néœ€è¦é…ç½®AIæ¥å£:")
        print("1. ğŸ”’ å®˜æ–¹API (Google Geminiç­‰)")
        print("2. ğŸŒ ä¸­è½¬API (ChatAI, OpenRouterç­‰)")
        print("3. ğŸš« è·³è¿‡é…ç½®")

        choice = input("è¯·é€‰æ‹© (1-3): ").strip()

        if choice == '1':
            self._configure_official_api()
        elif choice == '2':
            self._configure_proxy_api()
        else:
            print("âœ… ä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†ææ¨¡å¼")

    def _configure_official_api(self):
        """é…ç½®å®˜æ–¹API"""
        print("\nğŸ”’ å®˜æ–¹APIé…ç½®")
        print("ç›®å‰æ”¯æŒ: Google Gemini")

        provider = input("é€‰æ‹©æä¾›å•† (gemini): ").strip().lower() or 'gemini'
        api_key = input("è¯·è¾“å…¥APIå¯†é’¥: ").strip()

        if not api_key:
            print("âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º")
            return

        model = input("æ¨¡å‹åç§° (é»˜è®¤: gemini-2.5-flash): ").strip() or 'gemini-2.5-flash'

        config = {
            'enabled': True,
            'api_type': 'official',
            'provider': provider,
            'api_key': api_key,
            'model': model
        }

        # æµ‹è¯•è¿æ¥
        print("ğŸ” æµ‹è¯•è¿æ¥...")
        if self._test_official_api(config):
            self._save_ai_config(config)
            self.ai_config = config
            print("âœ… AIé…ç½®æˆåŠŸï¼")
        else:
            print("âŒ è¿æ¥æµ‹è¯•å¤±è´¥")

    def _configure_proxy_api(self):
        """é…ç½®ä¸­è½¬API"""
        print("\nğŸŒ ä¸­è½¬APIé…ç½®")

        base_url = input("APIåœ°å€ (å¦‚: https://www.chataiapi.com/v1): ").strip()
        api_key = input("APIå¯†é’¥: ").strip()
        model = input("æ¨¡å‹åç§° (å¦‚: deepseek-r1): ").strip()

        if not all([base_url, api_key, model]):
            print("âŒ é…ç½®ä¿¡æ¯ä¸å®Œæ•´")
            return

        config = {
            'enabled': True,
            'api_type': 'proxy',
            'provider': 'proxy',
            'base_url': base_url,
            'api_key': api_key,
            'model': model
        }

        # æµ‹è¯•è¿æ¥
        print("ğŸ” æµ‹è¯•è¿æ¥...")
        if self._test_proxy_api(config):
            self._save_ai_config(config)
            self.ai_config = config
            print("âœ… AIé…ç½®æˆåŠŸï¼")
        else:
            print("âŒ è¿æ¥æµ‹è¯•å¤±è´¥")

    def _test_official_api(self, config: Dict) -> bool:
        """æµ‹è¯•å®˜æ–¹APIè¿æ¥"""
        try:
            if config['provider'] == 'gemini':
                from google import genai
                client = genai.Client(api_key=config['api_key'])
                response = client.models.generate_content(
                    model=config['model'],
                    contents="æµ‹è¯•è¿æ¥"
                )
                return bool(response.text)
        except ImportError:
            print("âŒ éœ€è¦å®‰è£…: pip install google-genai")
            return False
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            return False

    def _test_proxy_api(self, config: Dict) -> bool:
        """æµ‹è¯•ä¸­è½¬APIè¿æ¥"""
        try:
            from openai import OpenAI
            client = OpenAI(
                api_key=config['api_key'],
                base_url=config['base_url']
            )
            completion = client.chat.completions.create(
                model=config['model'],
                messages=[{'role': 'user', 'content': 'æµ‹è¯•è¿æ¥'}],
                max_tokens=10
            )
            return bool(completion.choices[0].message.content)
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            return False

    def _test_existing_config(self) -> bool:
        """æµ‹è¯•å·²æœ‰é…ç½®çš„è¿æ¥"""
        try:
            api_type = self.ai_config.get('api_type')
            if api_type == 'official':
                return self._test_official_api(self.ai_config)
            else:
                return self._test_proxy_api(self.ai_config)
        except Exception as e:
            print(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_current_connection(self):
        """æµ‹è¯•å½“å‰AIè¿æ¥"""
        print("\nğŸ” AIè¿æ¥æµ‹è¯•")
        print("=" * 40)

        if not self.ai_config.get('enabled'):
            print("âŒ æœªæ‰¾åˆ°AIé…ç½®")
            print("ğŸ’¡ è¯·å…ˆé…ç½®AIæ¥å£")
            input("\næŒ‰å›è½¦é”®è¿”å›...")
            return

        print("ğŸ“‹ å½“å‰é…ç½®ä¿¡æ¯:")
        print(f"   ç±»å‹: {self.ai_config.get('api_type', 'æœªçŸ¥')}")
        print(f"   æœåŠ¡å•†: {self.ai_config.get('provider', 'æœªçŸ¥')}")
        print(f"   æ¨¡å‹: {self.ai_config.get('model', 'æœªçŸ¥')}")
        if self.ai_config.get('base_url'):
            print(f"   åœ°å€: {self.ai_config['base_url']}")
        print(f"   å¯†é’¥: {self.ai_config.get('api_key', '')[:10]}...")
        print()

        # æ‰§è¡Œæµ‹è¯•
        api_type = self.ai_config.get('api_type')
        if api_type == 'official':
            success = self._test_official_api(self.ai_config)
        else:
            success = self._test_proxy_api(self.ai_config)

        if success:
            print("\nâœ… è¿æ¥æµ‹è¯•æˆåŠŸï¼AIæ¥å£å·¥ä½œæ­£å¸¸")
        else:
            print("\nâŒ è¿æ¥æµ‹è¯•å¤±è´¥")
            print("ğŸ”§ å»ºè®®è§£å†³æ–¹æ¡ˆ:")
            print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print("2. éªŒè¯APIå¯†é’¥")
            print("3. ç¡®è®¤æœåŠ¡å•†çŠ¶æ€")
            print("4. é‡æ–°é…ç½®API")

        input("\næŒ‰å›è½¦é”®è¿”å›...")

    def get_file_hash(self, filepath: str) -> str:
        """è·å–æ–‡ä»¶å†…å®¹çš„MD5å“ˆå¸Œå€¼ - ç¡®ä¿ä¸€è‡´æ€§"""
        try:
            with open(filepath, 'rb') as f:
                content = f.read()
                return hashlib.md5(content).hexdigest()[:16]
        except:
            return hashlib.md5(filepath.encode()).hexdigest()[:16]

    def _extract_episode_number(self, filename: str) -> str:
        """ä»SRTæ–‡ä»¶åæå–é›†æ•°"""
        patterns = [
            r'[Ee](\d+)',
            r'EP(\d+)',
            r'ç¬¬(\d+)é›†',
            r'S\d+E(\d+)',
            r'(\d+)',
        ]

        for pattern in patterns:
            match = re.search(pattern, filename, re.I)
            if match:
                return match.group(1).zfill(2)

        base_name = os.path.splitext(filename)[0]
        return base_name

    def parse_srt_file(self, filepath: str) -> List[Dict]:
        """è§£æSRTå­—å¹•æ–‡ä»¶"""
        print(f"ğŸ“– è§£æå­—å¹•: {os.path.basename(filepath)}")

        # å°è¯•å¤šç§ç¼–ç è¯»å–æ–‡ä»¶ï¼Œå¢å¼ºé”™è¯¯å¤„ç†
        content = None
        used_encoding = None
        
        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'gb18030', 'utf-16', 'utf-16le', 'utf-16be', 'big5', 'cp936']
        
        for encoding in encodings:
            try:
                with open(filepath, 'r', encoding=encoding, errors='replace') as f:
                    content = f.read()
                    if content.strip():  # ç¡®ä¿è¯»å–åˆ°æœ‰æ•ˆå†…å®¹
                        used_encoding = encoding
                        print(f"âœ… ä½¿ç”¨ç¼–ç : {encoding}")
                        break
            except Exception as e:
                continue

        if not content or not content.strip():
            # æœ€åå°è¯•äºŒè¿›åˆ¶è¯»å–
            try:
                with open(filepath, 'rb') as f:
                    raw_data = f.read()
                    # å°è¯•è‡ªåŠ¨æ£€æµ‹ç¼–ç 
                    try:
                        import chardet
                        detected = chardet.detect(raw_data)
                        if detected['encoding']:
                            content = raw_data.decode(detected['encoding'], errors='replace')
                            print(f"âœ… è‡ªåŠ¨æ£€æµ‹ç¼–ç : {detected['encoding']}")
                    except ImportError:
                        # å¦‚æœæ²¡æœ‰chardetï¼Œä½¿ç”¨æœ€å¸¸è§çš„ç¼–ç 
                        for encoding in ['utf-8', 'gbk', 'gb18030']:
                            try:
                                content = raw_data.decode(encoding, errors='replace')
                                if content.strip():
                                    print(f"âœ… å¼ºåˆ¶ä½¿ç”¨ç¼–ç : {encoding}")
                                    break
                            except:
                                continue
            except Exception as e:
                print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {filepath}, é”™è¯¯: {e}")
                return []

        if not content or not content.strip():
            print(f"âŒ æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è§£æ: {filepath}")
            return []

        # é”™åˆ«å­—ä¿®æ­£
        original_content = content
        for old, new in self.corrections.items():
            content = content.replace(old, new)

        # è®°å½•ä¿®æ­£çš„é”™åˆ«å­—
        corrected_errors = []
        for old, new in self.corrections.items():
            if old in original_content:
                corrected_errors.append(f"'{old}' â†’ '{new}'")

        # è§£æå­—å¹•æ¡ç›®
        subtitles = []

        if '-->' in content:
            blocks = re.split(r'\n\s*\n', content.strip())

            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    try:
                        index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1

                        time_pattern = r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})'
                        time_match = re.search(time_pattern, lines[1])

                        if time_match:
                            start_time = time_match.group(1).replace('.', ',')
                            end_time = time_match.group(2).replace('.', ',')
                            text = '\n'.join(lines[2:]).strip()

                            if text:
                                subtitles.append({
                                    'index': index,
                                    'start': start_time,
                                    'end': end_time,
                                    'text': text,
                                    'start_seconds': self._time_to_seconds(start_time),
                                    'end_seconds': self._time_to_seconds(end_time)
                                })
                    except (ValueError, IndexError):
                        continue
        else:
            # å¤„ç†å…¶ä»–æ ¼å¼
            lines = content.split('\n')
            current_text = []
            for line in lines:
                line = line.strip()
                if line and not line.isdigit():
                    current_text.append(line)

            # ç®€å•å¤„ç†ï¼šæ¯è¡Œä½œä¸ºä¸€ä¸ªå­—å¹•æ¡ç›®
            for i, text in enumerate(current_text):
                if text:
                    subtitles.append({
                        'index': i + 1,
                        'start': f"00:{i*2:02d}:00,000",
                        'end': f"00:{i*2+2:02d}:00,000",
                        'text': text,
                        'start_seconds': i * 2,
                        'end_seconds': (i + 1) * 2
                    })

        if corrected_errors:
            print(f"âœ… ä¿®æ­£é”™åˆ«å­—: {', '.join(corrected_errors[:3])}{'...' if len(corrected_errors) > 3 else ''}")

        print(f"âœ… è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return subtitles

    def _time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace('.', ',')
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0.0

    def _seconds_to_time(self, seconds: float) -> str:
        """ç§’è½¬æ¢ä¸ºæ—¶é—´å­—ç¬¦ä¸²"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        ms = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}"

    def detect_genre_and_themes_ai(self, subtitles: List[Dict]) -> Tuple[str, List[str]]:
        """ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«å‰§æƒ…ç±»å‹å’Œä¸»é¢˜"""
        if not self.ai_config.get('enabled'):
            print("âŒ AIæœªå¯ç”¨ï¼Œæ— æ³•è¿›è¡Œç±»å‹è¯†åˆ«")
            return None, None

        # é€‰æ‹©ä»£è¡¨æ€§å­—å¹•ç”¨äºç±»å‹è¯†åˆ«
        representative_text = self._select_representative_subtitles(subtitles)
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”µè§†å‰§å†…å®¹ï¼Œè¯†åˆ«å‰§æƒ…ç±»å‹å’Œä¸»è¦ä¸»é¢˜ã€‚

ã€å­—å¹•å†…å®¹æ ·æœ¬ã€‘
{representative_text}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{{
    "genre": "å…·ä½“çš„å‰§æƒ…ç±»å‹ï¼ˆå¦‚ï¼šæ³•å¾‹å‰§ã€çˆ±æƒ…å‰§ã€æ‚¬ç–‘å‰§ã€å®¶åº­å‰§ã€èŒåœºå‰§ã€å¤è£…å‰§ã€ç°ä»£éƒ½å¸‚å‰§ç­‰ï¼‰",
    "subgenre": "å­ç±»å‹æè¿°",
    "themes": ["ä¸»é¢˜1", "ä¸»é¢˜2", "ä¸»é¢˜3"],
    "confidence": 0.9,
    "reasoning": "åˆ¤æ–­ä¾æ®"
}}

åˆ†æè¦ç‚¹ï¼š
1. åŸºäºå®é™…å†…å®¹åˆ¤æ–­ï¼Œä¸è¦é¢„è®¾ç±»å‹
2. ä¸»é¢˜è¦å…·ä½“ä¸”ç›¸å…³
3. ç»™å‡ºåˆ¤æ–­çš„ç½®ä¿¡åº¦"""

        try:
            response = self.call_ai_api(prompt, "ä½ æ˜¯ä¸“ä¸šçš„å½±è§†å†…å®¹åˆ†æå¸ˆï¼Œæ“…é•¿è¯†åˆ«å‰§æƒ…ç±»å‹å’Œä¸»é¢˜ã€‚")
            if response:
                # è§£æAIå“åº”
                if "```json" in response:
                    start = response.find("```json") + 7
                    end = response.find("```", start)
                    json_text = response[start:end]
                else:
                    start = response.find("{")
                    end = response.rfind("}") + 1
                    json_text = response[start:end]
                
                result = json.loads(json_text)
                genre = result.get('genre', 'é€šç”¨å‰§')
                themes = result.get('themes', ['å‰§æƒ…å‘å±•'])
                
                print(f"ğŸ­ AIè¯†åˆ«å‰§æƒ…ç±»å‹: {genre}")
                print(f"ğŸ¯ AIè¯†åˆ«ä¸»é¢˜: {', '.join(themes)}")
                
                self.series_context['genre_detected'] = genre
                self.series_context['main_themes'] = themes
                
                return genre, themes
                
        except Exception as e:
            print(f"âš ï¸ AIç±»å‹è¯†åˆ«å¤±è´¥: {e}")
        
        # AIå¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
        return 'é€šç”¨å‰§', ['å‰§æƒ…å‘å±•']

    def build_series_context(self, episode_num: str) -> str:
        """æ„å»ºå…¨å‰§ä¸Šä¸‹æ–‡ä¿¡æ¯ - é—®é¢˜4,8ï¼šè·¨é›†è¿è´¯æ€§"""
        context_parts = []

        if self.series_context['previous_episodes']:
            context_parts.append("ã€å‰æƒ…å›é¡¾ã€‘")
            for prev_ep in self.series_context['previous_episodes'][-3:]:
                context_parts.append(f"ç¬¬{prev_ep['episode']}é›†: {prev_ep['summary']}")
            context_parts.append("")

        if self.series_context['genre_detected']:
            context_parts.append(f"ã€å‰§æƒ…ç±»å‹ã€‘{self.series_context['genre_detected']}")
            context_parts.append("")

        if self.series_context['main_themes']:
            context_parts.append(f"ã€ä¸»è¦ä¸»é¢˜ã€‘{', '.join(self.series_context['main_themes'])}")
            context_parts.append("")

        if self.series_context['main_storylines']:
            context_parts.append("ã€ä¸»è¦æ•…äº‹çº¿ã€‘")
            for storyline in self.series_context['main_storylines'][-5:]:
                context_parts.append(f"â€¢ {storyline}")
            context_parts.append("")

        if self.series_context['ongoing_conflicts']:
            context_parts.append("ã€æŒç»­å†²çªã€‘")
            for conflict in self.series_context['ongoing_conflicts'][-3:]:
                context_parts.append(f"â€¢ {conflict}")
            context_parts.append("")

        return '\n'.join(context_parts) if context_parts else f"æ­£åœ¨åˆ†æç¬¬{episode_num}é›†çš„å‰§æƒ…å†…å®¹"

    def get_analysis_cache_path(self, srt_file: str) -> str:
        """è·å–åˆ†æç»“æœç¼“å­˜è·¯å¾„ - é—®é¢˜11"""
        file_hash = self.get_file_hash(os.path.join(self.srt_folder, srt_file))
        episode_num = self._extract_episode_number(srt_file)
        return os.path.join(self.analysis_cache_folder, f"analysis_E{episode_num}_{file_hash}.json")

    def save_analysis_cache(self, srt_file: str, analysis_result: Dict):
        """ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜ - é—®é¢˜11"""
        cache_path = self.get_analysis_cache_path(srt_file)
        try:
            analysis_result['cache_timestamp'] = datetime.now().isoformat()
            analysis_result['source_file'] = srt_file
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ åˆ†æç»“æœå·²ç¼“å­˜: {os.path.basename(cache_path)}")
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

    def load_analysis_cache(self, srt_file: str) -> Optional[Dict]:
        """ä»ç¼“å­˜åŠ è½½åˆ†æç»“æœ - é—®é¢˜11"""
        cache_path = self.get_analysis_cache_path(srt_file)
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    result = json.load(f)
                print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜çš„åˆ†æç»“æœ: {os.path.basename(cache_path)}")
                return result
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        return None

    def call_ai_api(self, prompt: str, system_prompt: str = "") -> Optional[str]:
        """ç»Ÿä¸€AI APIè°ƒç”¨ - é—®é¢˜11ï¼šå¤„ç†APIä¸ç¨³å®š"""
        if not self.ai_config.get('enabled'):
            return None

        max_retries = 3
        for attempt in range(max_retries):
            try:
                api_type = self.ai_config.get('api_type')

                if api_type == 'official':
                    return self._call_official_api(prompt, system_prompt)
                else:
                    return self._call_proxy_api(prompt, system_prompt)

            except Exception as e:
                print(f"âš ï¸ AIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)

        return None

    def _call_official_api(self, prompt: str, system_prompt: str) -> Optional[str]:
        """è°ƒç”¨å®˜æ–¹API"""
        try:
            if self.ai_config['provider'] == 'gemini':
                from google import genai
                client = genai.Client(api_key=self.ai_config['api_key'])
                full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
                response = client.models.generate_content(
                    model=self.ai_config['model'],
                    contents=full_prompt
                )
                return response.text
        except Exception as e:
            print(f"âš ï¸ å®˜æ–¹APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _call_proxy_api(self, prompt: str, system_prompt: str) -> Optional[str]:
        """è°ƒç”¨ä¸­è½¬API"""
        try:
            from openai import OpenAI
            client = OpenAI(
                api_key=self.ai_config['api_key'],
                base_url=self.ai_config['base_url']
            )
            messages = []
            if system_prompt:
                messages.append({'role': 'system', 'content': system_prompt})
            messages.append({'role': 'user', 'content': prompt})

            completion = client.chat.completions.create(
                model=self.ai_config['model'],
                messages=messages,
                max_tokens=3000,
                temperature=0.7
            )
            return completion.choices[0].message.content
        except Exception as e:
            print(f"âš ï¸ ä¸­è½¬APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def ai_analyze_episode_complete(self, subtitles: List[Dict], episode_num: str, genre: str, themes: List[str], series_context: str) -> Optional[Dict]:
        """ä½¿ç”¨AIåˆ†æå®Œæ•´é›†æ•° - æ”¯æŒå„ç§å‰§æƒ…ç±»å‹"""
        if not self.ai_config.get('enabled'):
            return None

        # æ„å»ºå®Œæ•´çš„å‰§æƒ…æ–‡æœ¬
        full_subtitle_text = "\n".join([f"[{sub['start']} --> {sub['end']}] {sub['text']}" for sub in subtitles])

        # æ ¹æ®å‰§æƒ…ç±»å‹è°ƒæ•´æç¤ºè¯
        genre_specific_guidance = self._get_genre_specific_guidance(genre)

        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰§æƒ…åˆ†æå¸ˆï¼Œç°åœ¨è¦åˆ†æç¬¬{episode_num}é›†çš„å†…å®¹ï¼Œè¯†åˆ«æœ€ç²¾å½©çš„å‰§æƒ…ç‚¹ã€‚

ã€å‰§é›†åŸºæœ¬ä¿¡æ¯ã€‘
- é›†æ•°ï¼šç¬¬{episode_num}é›†
- å‰§æƒ…ç±»å‹ï¼š{genre}
- ä¸»è¦ä¸»é¢˜ï¼š{', '.join(themes)}
- æ€»æ—¶é•¿ï¼š{len(subtitles)}æ¡å­—å¹•

ã€å…¨å‰§ä¸Šä¸‹æ–‡ã€‘
{series_context}

ã€ç±»å‹ç‰¹å®šæŒ‡å¯¼ã€‘
{genre_specific_guidance}

ã€å®Œæ•´å­—å¹•å†…å®¹ã€‘
{full_subtitle_text}

è¯·æ·±åº¦åˆ†æè¿™ä¸€é›†ï¼Œè¯†åˆ«3-4ä¸ªæœ€ç²¾å½©çš„å‰§æƒ…ç‚¹ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µ2-3åˆ†é’Ÿã€‚

è¦æ±‚ï¼š
1. ç‰‡æ®µå¿…é¡»åŒ…å«å®Œæ•´çš„å¯¹è¯åœºæ™¯ï¼Œç¡®ä¿å¥å­å®Œæ•´
2. æ¯ä¸ªç‰‡æ®µè¦æœ‰æ˜ç¡®çš„å‰§æƒ…ä»·å€¼ï¼ˆå†²çªã€è½¬æŠ˜ã€æ­éœ²ã€æƒ…æ„Ÿçˆ†å‘ç­‰ï¼‰
3. æ—¶é—´ç‚¹å¿…é¡»ç²¾ç¡®ï¼Œåœ¨å­—å¹•èŒƒå›´å†…
4. æ”¯æŒéè¿ç»­æ—¶é—´æ®µçš„åˆç†ç»„åˆ
5. ç”Ÿæˆç¬¬ä¸‰äººç§°æ—ç™½ï¼Œé€‚åˆçŸ­è§†é¢‘è§£è¯´

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

{{
    "episode_analysis": {{
        "episode_number": "{episode_num}",
        "genre": "{genre}",
        "main_theme": "æœ¬é›†æ ¸å¿ƒä¸»é¢˜",
        "story_progression": "åœ¨æ•´ä¸ªå‰§æƒ…ä¸­çš„ä½œç”¨",
        "emotional_arc": "æƒ…æ„Ÿå‘å±•çº¿",
        "key_characters": ["ä¸»è¦è§’è‰²1", "ä¸»è¦è§’è‰²2"],
        "main_conflicts": ["æ ¸å¿ƒå†²çª1", "æ ¸å¿ƒå†²çª2"]
    }},
    "plot_points": [
        {{
            "type": "å‰§æƒ…ç‚¹ç±»å‹ï¼ˆå…³é”®å†²çª/äººç‰©è½¬æŠ˜/çº¿ç´¢æ­éœ²/æƒ…æ„Ÿçˆ†å‘/é‡è¦å¯¹è¯/ä¸»é¢˜å‡åï¼‰",
            "title": "ç²¾å½©ç‰‡æ®µæ ‡é¢˜",
            "time_segments": [
                {{
                    "start_time": "å¼€å§‹æ—¶é—´ï¼ˆHH:MM:SS,mmmï¼‰",
                    "end_time": "ç»“æŸæ—¶é—´ï¼ˆHH:MM:SS,mmmï¼‰",
                    "reason": "é€‰æ‹©è¿™ä¸ªæ—¶é—´æ®µçš„åŸå› "
                }}
            ],
            "total_duration": ç‰‡æ®µæ€»æ—¶é•¿ç§’æ•°,
            "plot_significance": "åœ¨å‰§æƒ…ä¸­çš„é‡è¦æ„ä¹‰",
            "content_summary": "ç‰‡æ®µå†…å®¹è¯¦ç»†æ¦‚è¿°",
            "key_dialogues": ["å…³é”®å°è¯1", "å…³é”®å°è¯2"],
            "third_person_narration": "ç¬¬ä¸‰äººç§°æ—ç™½è§£è¯´æ–‡æœ¬",
            "content_highlights": ["è§‚ä¼—å…³æ³¨ç‚¹1", "è§‚ä¼—å…³æ³¨ç‚¹2"],
            "emotional_impact": "æƒ…æ„Ÿå†²å‡»æè¿°",
            "connection_setup": "ä¸ºåç»­å‰§æƒ…çš„é“ºå«"
        }}
    ],
    "episode_summary": {{
        "core_storyline": "æœ¬é›†æ ¸å¿ƒæ•…äº‹çº¿",
        "character_development": "è§’è‰²å‘å±•å˜åŒ–",
        "plot_advancement": "å‰§æƒ…æ¨è¿›è¦ç‚¹",
        "cliffhanger_or_resolution": "æ‚¬å¿µè®¾ç½®æˆ–è§£å†³",
        "next_episode_connection": "ä¸ä¸‹ä¸€é›†çš„è¡”æ¥ç‚¹è¯´æ˜"
    }}
}}

æ³¨æ„ï¼š
- æ—¶é—´å¿…é¡»åœ¨å­—å¹•èŒƒå›´å†…ï¼š{subtitles[0]['start']} åˆ° {subtitles[-1]['end']}
- ç¡®ä¿æ¯ä¸ªç‰‡æ®µæœ‰å®Œæ•´çš„æˆå‰§ä»·å€¼
- ç¬¬ä¸‰äººç§°æ—ç™½è¦ä¸“ä¸šä¸”å¸å¼•äºº
- è€ƒè™‘è·¨é›†è¿è´¯æ€§"""

        system_prompt = f"""ä½ æ˜¯èµ„æ·±çš„{genre}åˆ†æä¸“å®¶ï¼Œå…·æœ‰ä¸°å¯Œçš„ç”µè§†å‰§å‰ªè¾‘ç»éªŒã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. æ·±åº¦ç†è§£{genre}çš„ç‰¹ç‚¹å’Œè§‚ä¼—æœŸå¾…
2. å‡†ç¡®è¯†åˆ«è¯¥ç±»å‹å‰§é›†çš„ç²¾å½©æ—¶åˆ»
3. ç¡®ä¿æ—¶é—´æ®µçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
4. ç”Ÿæˆä¸“ä¸šçš„å‰§æƒ…åˆ†æå’Œæ—ç™½
5. ä¿è¯è·¨é›†å‰§æƒ…è¿è´¯æ€§

è¯·ç¡®ä¿åˆ†æç»“æœå…·æœ‰è¯¥é›†çš„ç‹¬ç‰¹æ€§ï¼Œä½“ç°{genre}çš„ç‰¹è‰²ã€‚"""

        try:
            print(f"ğŸ¤– AIæ·±åº¦åˆ†æç¬¬{episode_num}é›†ä¸­...")
            response = self.call_ai_api(prompt, system_prompt)

            if response:
                # æå–JSON
                try:
                    if "```json" in response:
                        start = response.find("```json") + 7
                        end = response.find("```", start)
                        json_text = response[start:end]
                    elif "```" in response:
                        start = response.find("```") + 3
                        end = response.rfind("```")
                        json_text = response[start:end]
                    else:
                        start = response.find("{")
                        end = response.rfind("}") + 1
                        json_text = response[start:end]

                    result = json.loads(json_text)

                    # éªŒè¯å’Œä¿®æ­£æ—¶é—´èŒƒå›´
                    if self._validate_and_fix_time_ranges(result.get('plot_points', []), subtitles):
                        print(f"âœ… AIåˆ†ææˆåŠŸ: {len(result.get('plot_points', []))} ä¸ªå‰§æƒ…ç‚¹")
                        return result
                    else:
                        print(f"âš ï¸ AIè¿”å›çš„æ—¶é—´èŒƒå›´æ— æ•ˆ")
                        return None

                except json.JSONDecodeError as e:
                    print(f"âš ï¸ AIå“åº”JSONè§£æå¤±è´¥: {e}")
                    print(f"åŸå§‹å“åº”å‰300å­—ç¬¦: {response[:300]}")
                except Exception as e:
                    print(f"âš ï¸ AIå“åº”å¤„ç†å¤±è´¥: {e}")

            return None

        except Exception as e:
            print(f"âš ï¸ AIåˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
            return None

    def _select_representative_subtitles(self, subtitles: List[Dict]) -> str:
        """é€‰æ‹©ä»£è¡¨æ€§å­—å¹•ç”¨äºAIåˆ†æï¼Œé¿å…tokenè¶…é™"""
        if not subtitles:
            return ""
        
        total_length = len(subtitles)
        
        # é€‰æ‹©ç­–ç•¥ï¼šå¼€å¤´ã€ä¸­é—´ã€ç»“å°¾å„é€‰ä¸€äº›
        segments = []
        
        # å¼€å¤´15%
        start_end = max(1, int(total_length * 0.15))
        segments.extend(subtitles[:start_end])
        
        # ä¸­é—´20%
        mid_start = int(total_length * 0.4)
        mid_end = int(total_length * 0.6)
        segments.extend(subtitles[mid_start:mid_end])
        
        # ç»“å°¾15%
        end_start = int(total_length * 0.85)
        segments.extend(subtitles[end_start:])
        
        # åˆå¹¶æ–‡æœ¬ï¼Œé™åˆ¶æ€»é•¿åº¦
        representative_parts = []
        total_chars = 0
        max_chars = 8000  # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        
        for subtitle in segments:
            text = subtitle['text']
            if total_chars + len(text) > max_chars:
                break
            representative_parts.append(f"[{subtitle['start']}] {text}")
            total_chars += len(text)
        
        return '\n'.join(representative_parts)

    def _get_genre_specific_guidance(self, genre: str) -> str:
        """æ ¹æ®å‰§æƒ…ç±»å‹æä¾›ç‰¹å®šæŒ‡å¯¼"""
        guidance = {
            'æ³•å¾‹å‰§': """
é‡ç‚¹å…³æ³¨ï¼š
- æ³•åº­è¾©è®ºçš„ç²¾å½©å¯¹æŠ—
- è¯æ®æ­éœ²çš„å…³é”®æ—¶åˆ»
- æ­£ä¹‰ä¸æ³•ç†çš„å†²çª
- è§’è‰²ä¿¡å¿µçš„åšæŒä¸å¦¥å
- æ¡ˆä»¶çœŸç›¸çš„é€æ­¥æ­ç¤º""",

            'çˆ±æƒ…å‰§': """
é‡ç‚¹å…³æ³¨ï¼š
- æƒ…æ„Ÿè¡¨ç™½æˆ–å†²çªçš„é«˜æ½®æ—¶åˆ»
- è§’è‰²å…³ç³»çš„è½¬æŠ˜ç‚¹
- è¯¯ä¼šäº§ç”Ÿæˆ–è§£é™¤çš„å…³é”®åœºæ™¯
- æµªæ¼«æˆ–å¿ƒåŠ¨çš„ç»å…¸æ—¶åˆ»
- æƒ…æ„Ÿçº è‘›çš„å¤æ‚è¡¨ç°""",

            'æ‚¬ç–‘å‰§': """
é‡ç‚¹å…³æ³¨ï¼š
- çº¿ç´¢æ­éœ²çš„å…³é”®æ—¶åˆ»
- çœŸç›¸å¤§ç™½çš„éœ‡æ’¼åœºæ™¯
- æ¨ç†è¿‡ç¨‹çš„ç²¾å½©å±•ç¤º
- åè½¬æƒ…èŠ‚çš„å·§å¦™è®¾è®¡
- ç´§å¼ æ°›å›´çš„è¥é€ """,

            'å®¶åº­å‰§': """
é‡ç‚¹å…³æ³¨ï¼š
- å®¶åº­æˆå‘˜é—´çš„æƒ…æ„Ÿå†²çª
- äº²æƒ…è¡¨è¾¾çš„æ¸©é¦¨æ—¶åˆ»
- å®¶åº­çŸ›ç›¾çš„çˆ†å‘ä¸å’Œè§£
- ä»£é™…è§‚å¿µçš„ç¢°æ’
- å®¶åº­è´£ä»»çš„æ‰¿æ‹…""",

            'èŒåœºå‰§': """
é‡ç‚¹å…³æ³¨ï¼š
- èŒåœºç«äº‰çš„æ¿€çƒˆæ—¶åˆ»
- äº‹ä¸šè½¬æŠ˜çš„å…³é”®å†³å®š
- åŒäº‹å…³ç³»çš„å¤æ‚å˜åŒ–
- èŒä¸šç†æƒ³ä¸ç°å®çš„å†²çª
- å›¢é˜Ÿåˆä½œæˆ–èƒŒå›çš„æƒ…èŠ‚""",

            'å¤è£…å‰§': """
é‡ç‚¹å…³æ³¨ï¼š
- æƒåŠ›æ–—äº‰çš„ç²¾å½©åšå¼ˆ
- æ±Ÿæ¹–æƒ…ä»‡çš„æ©æ€¨çº è‘›
- å¿ è¯šä¸èƒŒå›çš„é“å¾·è€ƒéªŒ
- æ­¦åŠŸå¯¹å†³çš„ç²¾å½©åœºé¢
- å®¶å›½æƒ…æ€€çš„æ·±åˆ»è¡¨è¾¾"""
        }

        return guidance.get(genre, """
é‡ç‚¹å…³æ³¨ï¼š
- å‰§æƒ…å‘å±•çš„å…³é”®è½¬æŠ˜ç‚¹
- è§’è‰²æƒ…æ„Ÿçš„æ·±åº¦è¡¨è¾¾
- çŸ›ç›¾å†²çªçš„æ¿€çƒˆæ—¶åˆ»
- ä¸»é¢˜æ€æƒ³çš„æ·±åˆ»ä½“ç°
- è§‚ä¼—æƒ…æ„Ÿçš„å…±é¸£ç‚¹""")

    def _validate_and_fix_time_ranges(self, plot_points: List[Dict], subtitles: List[Dict]) -> bool:
        """éªŒè¯å’Œä¿®æ­£AIè¿”å›çš„æ—¶é—´èŒƒå›´ - é—®é¢˜10ï¼šä¿è¯å¥å­å®Œæ•´"""
        if not plot_points or not subtitles:
            return False

        first_subtitle_time = subtitles[0]['start']
        last_subtitle_time = subtitles[-1]['end']

        first_seconds = self._time_to_seconds(first_subtitle_time)
        last_seconds = self._time_to_seconds(last_subtitle_time)

        for point in plot_points:
            time_segments = point.get('time_segments', [])
            if not time_segments:
                print(f"âš ï¸ ç¼ºå°‘æ—¶é—´æ®µä¿¡æ¯: {point.get('title', 'æœªçŸ¥ç‰‡æ®µ')}")
                return False

            total_duration = 0
            valid_segments = []

            for segment in time_segments:
                start_time = segment.get('start_time', '')
                end_time = segment.get('end_time', '')

                if not start_time or not end_time:
                    continue

                start_seconds = self._time_to_seconds(start_time)
                end_seconds = self._time_to_seconds(end_time)

                # æ£€æŸ¥æ—¶é—´æ˜¯å¦åœ¨å­—å¹•èŒƒå›´å†…
                if start_seconds < first_seconds or end_seconds > last_seconds:
                    # å°è¯•ä¿®æ­£åˆ°æœ€æ¥è¿‘çš„å­—å¹•æ—¶é—´
                    closest_start = min(subtitles, key=lambda s: abs(s['start_seconds'] - start_seconds))
                    closest_end = min(subtitles, key=lambda s: abs(s['end_seconds'] - end_seconds))

                    segment['start_time'] = closest_start['start']
                    segment['end_time'] = closest_end['end']

                    start_seconds = closest_start['start_seconds']
                    end_seconds = closest_end['end_seconds']
                    print(f"âš™ï¸ æ—¶é—´å·²ä¿®æ­£: {segment['start_time']} - {segment['end_time']}")

                # æ£€æŸ¥æ—¶é—´æ®µæ˜¯å¦æœ‰æ•ˆ
                if start_seconds >= end_seconds:
                    print(f"âš ï¸ æ— æ•ˆæ—¶é—´æ®µ: {start_time}-{end_time}")
                    continue

                segment_duration = end_seconds - start_seconds
                total_duration += segment_duration
                valid_segments.append(segment)

            if not valid_segments:
                print(f"âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´æ®µ: {point.get('title', 'æœªçŸ¥ç‰‡æ®µ')}")
                return False

            # æ›´æ–°æ—¶é—´æ®µå’Œæ€»æ—¶é•¿
            point['time_segments'] = valid_segments
            point['total_duration'] = total_duration

            # æ£€æŸ¥æ€»æ—¶é•¿æ˜¯å¦åˆç†ï¼ˆ60-300ç§’ï¼‰
            if total_duration < 60:
                print(f"âš ï¸ æ—¶é•¿è¿‡çŸ­: {total_duration:.1f}ç§’ - {point.get('title', 'æœªçŸ¥ç‰‡æ®µ')}")
            elif total_duration > 300:
                print(f"âš ï¸ æ—¶é•¿è¿‡é•¿: {total_duration:.1f}ç§’ - {point.get('title', 'æœªçŸ¥ç‰‡æ®µ')}")

        return True

    # åŸºç¡€åˆ†æåŠŸèƒ½å·²ç§»é™¤ - æœ¬ç³»ç»Ÿåªä½¿ç”¨AIåˆ†æ

    # åŸºç¡€åˆ†æç›¸å…³æ–¹æ³•å·²ç§»é™¤ - æœ¬ç³»ç»Ÿä¸“æ³¨äºAIåˆ†æ

    def _find_sentence_start_advanced(self, subtitles: List[Dict], start_idx: int) -> int:
        """å¯»æ‰¾å®Œæ•´å¥å­çš„å¼€å§‹ç‚¹ - é«˜çº§ç‰ˆ"""
        sentence_starters = [
            'é‚£ä¹ˆ', 'ç°åœ¨', 'è¿™æ—¶', 'çªç„¶', 'æ¥ä¸‹æ¥', 'é¦–å…ˆ', 'ç„¶å', 'äºæ˜¯', 'éšç€', 
            'åˆšæ‰', 'ä½†æ˜¯', 'ä¸è¿‡', 'å› ä¸º', 'æ‰€ä»¥', 'æ—¢ç„¶', 'è™½ç„¶', 'å°½ç®¡', 'ç„¶è€Œ',
            'å¦å¤–', 'æ­¤å¤–', 'è€Œä¸”', 'åŒæ—¶', 'æ¥ç€', 'ç´§æ¥ç€', 'éšå', 'åæ¥'
        ]

        for i in range(start_idx, max(0, start_idx - 15), -1):
            if i < len(subtitles):
                text = subtitles[i]['text']

                # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªç„¶çš„å¼€å§‹
                if any(starter in text[:15] for starter in sentence_starters):
                    return i

                # æ£€æŸ¥å‰ä¸€å¥æ˜¯å¦ç»“æŸ
                if i > 0:
                    prev_text = subtitles[i-1]['text']
                    if any(prev_text.endswith(end) for end in ['ã€‚', 'ï¼', 'ï¼Ÿ', '...', 'â€”â€”']):
                        return i

                # æ£€æŸ¥æ˜¯å¦æ˜¯å¯¹è¯å¼€å§‹
                if text.startswith('"') or text.startswith('"') or 'ï¼š' in text[:10]:
                    return i

        return start_idx

    def _find_sentence_end_advanced(self, subtitles: List[Dict], end_idx: int) -> int:
        """å¯»æ‰¾å®Œæ•´å¥å­çš„ç»“æŸç‚¹ - é«˜çº§ç‰ˆ"""
        sentence_enders = ['ã€‚', 'ï¼', 'ï¼Ÿ', '...', 'â€”â€”', '"', '"', 'ã€‘', 'ï¼‰']

        for i in range(end_idx, min(len(subtitles), end_idx + 15)):
            if i < len(subtitles):
                text = subtitles[i]['text']

                # æ‰¾åˆ°è‡ªç„¶ç»“æŸç‚¹
                if any(text.endswith(ender) for ender in sentence_enders):
                    return i

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ®µè½ç»“æŸ
                if len(text) < 10 and any(ender in text for ender in sentence_enders):
                    return i

        return min(end_idx, len(subtitles) - 1)

    def _calculate_duration(self, subtitles: List[Dict], start_idx: int, end_idx: int) -> float:
        """è®¡ç®—å­—å¹•ç‰‡æ®µçš„æ—¶é•¿"""
        if start_idx >= len(subtitles) or end_idx >= len(subtitles):
            return 0

        start_seconds = subtitles[start_idx]['start_seconds']
        end_seconds = subtitles[end_idx]['end_seconds']
        return end_seconds - start_seconds

    def _generate_segment_title(self, subtitles: List[Dict], start_idx: int, end_idx: int, plot_type: str, genre: str) -> str:
        """ç”Ÿæˆç‰‡æ®µæ ‡é¢˜"""
        content = ' '.join([subtitles[i]['text'] for i in range(start_idx, min(end_idx + 1, start_idx + 5))])

        # æ ¹æ®ç±»å‹å’Œå†…å®¹ç”Ÿæˆæ ‡é¢˜
        if plot_type == 'å…³é”®å†²çª':
            if 'æ³•åº­' in content or 'å®¡åˆ¤' in content:
                return "æ³•åº­æ¿€è¾©ï¼Œé’ˆé”‹ç›¸å¯¹"
            elif 'äº‰è®º' in content or 'è´¨ç–‘' in content:
                return "æ¿€çƒˆäº‰è®ºï¼Œè§‚ç‚¹äº¤é”‹"
            else:
                return "å…³é”®å†²çªçˆ†å‘"
        elif plot_type == 'çº¿ç´¢æ­éœ²':
            if ('è¯æ®' in content or 'å‘ç°' in content):
                return "å…³é”®è¯æ®æµ®å‡ºæ°´é¢"
            elif 'çœŸç›¸' in content:
                return "çœŸç›¸å¤§ç™½æ—¶åˆ»"
            else:
                return "é‡è¦çº¿ç´¢æ­éœ²"
        elif plot_type == 'æƒ…æ„Ÿçˆ†å‘':
            if 'å“­' in content or 'æ³ª' in content:
                return "æƒ…æ„Ÿå†³å ¤ï¼Œæ³ªå¦‚é›¨ä¸‹"
            elif 'æ„¤æ€’' in content or 'æ¿€åŠ¨' in content:
                return "æƒ…æ„Ÿçˆ†å‘ï¼Œéœ‡æ’¼äººå¿ƒ"
            else:
                return "æ·±åº¦æƒ…æ„Ÿè¡¨è¾¾"
        elif plot_type == 'äººç‰©è½¬æŠ˜':
            return "å…³é”®æŠ‰æ‹©ï¼Œäººç”Ÿè½¬æŠ˜"
        elif plot_type == 'é‡è¦å¯¹è¯':
            return "æ·±åº¦å¯¹è¯ï¼Œæ­ç¤ºå†…å¿ƒ"
        else:
            return "ç²¾å½©å‰§æƒ…ç‰‡æ®µ"

    def _generate_plot_significance(self, plot_type: str, genre: str) -> str:
        """ç”Ÿæˆå‰§æƒ…æ„ä¹‰"""
        significance_map = {
            'å…³é”®å†²çª': f"åœ¨{genre}ä¸­ï¼Œæ­¤å†²çªä»£è¡¨æ ¸å¿ƒçŸ›ç›¾çš„æ¿€åŒ–ï¼Œæ¨åŠ¨å‰§æƒ…èµ°å‘é«˜æ½®",
            'çº¿ç´¢æ­éœ²': f"å…³é”®ä¿¡æ¯çš„æŠ«éœ²ï¼Œä¸º{genre}çš„ä¸»è¦æ‚¬å¿µæä¾›é‡è¦çº¿ç´¢",
            'æƒ…æ„Ÿçˆ†å‘': f"è§’è‰²å†…å¿ƒæƒ…æ„Ÿçš„é›†ä¸­è¡¨è¾¾ï¼Œä½“ç°{genre}çš„äººç‰©æ·±åº¦",
            'äººç‰©è½¬æŠ˜': f"è§’è‰²æˆé•¿å’Œæ”¹å˜çš„å…³é”®èŠ‚ç‚¹ï¼Œæ¨åŠ¨{genre}çš„è§’è‰²å¼§çº¿å‘å±•",
            'é‡è¦å¯¹è¯': f"æ‰¿è½½é‡è¦ä¿¡æ¯å’Œæƒ…æ„Ÿçš„å¯¹è¯ï¼Œä½“ç°{genre}çš„å™äº‹æ·±åº¦",
            'ä¸»é¢˜å‡å': f"ä½“ç°{genre}æ ¸å¿ƒä»·å€¼è§‚å’Œæ·±å±‚ä¸»é¢˜çš„é‡è¦æ—¶åˆ»"
        }

        return significance_map.get(plot_type, "æ¨åŠ¨å‰§æƒ…å‘å±•çš„é‡è¦ç‰‡æ®µ")

    def _generate_content_summary_advanced(self, subtitles: List[Dict], start_idx: int, end_idx: int, plot_type: str) -> str:
        """ç”Ÿæˆé«˜çº§å†…å®¹æ‘˜è¦"""
        content = ' '.join([subtitles[i]['text'] for i in range(start_idx, min(end_idx + 1, start_idx + 20))])

        summary_template = {
            'å…³é”®å†²çª': f"åœ¨è¿™ä¸ª{plot_type}ç‰‡æ®µä¸­ï¼ŒåŒæ–¹å±•å¼€æ¿€çƒˆå¯¹æŠ—ã€‚{content[:80]}...çŸ›ç›¾è¾¾åˆ°ç™½çƒ­åŒ–ç¨‹åº¦ã€‚",
            'çº¿ç´¢æ­éœ²': f"é‡è¦{plot_type}æ—¶åˆ»ï¼Œå…³é”®ä¿¡æ¯å¾—ä»¥æŠ«éœ²ã€‚{content[:80]}...ä¸ºçœŸç›¸å¤§ç™½å¥ å®šåŸºç¡€ã€‚",
            'æƒ…æ„Ÿçˆ†å‘': f"è§’è‰²æƒ…æ„Ÿåœ¨æ­¤åˆ»å¾—åˆ°å……åˆ†é‡Šæ”¾ã€‚{content[:80]}...æ·±æ·±è§¦åŠ¨è§‚ä¼—å†…å¿ƒã€‚",
            'äººç‰©è½¬æŠ˜': f"è§’è‰²é¢ä¸´é‡è¦æŠ‰æ‹©æ—¶åˆ»ã€‚{content[:80]}...äººç”Ÿè½¨è¿¹å› æ­¤æ”¹å˜ã€‚",
            'é‡è¦å¯¹è¯': f"æ‰¿è½½é‡è¦ä¿¡æ¯çš„æ·±åº¦å¯¹è¯ã€‚{content[:80]}...æ­ç¤ºè§’è‰²å†…å¿ƒä¸–ç•Œã€‚",
            'ä¸»é¢˜å‡å': f"ä½“ç°æ·±å±‚ä¸»é¢˜çš„é‡è¦æ—¶åˆ»ã€‚{content[:80]}...å¼•å‘æ·±åº¦æ€è€ƒã€‚"
        }

        return summary_template.get(plot_type, f"ç²¾å½©çš„{plot_type}ç‰‡æ®µã€‚{content[:80]}...å±•ç°å‰§æƒ…é­…åŠ›ã€‚")

    def _extract_key_dialogues_advanced(self, subtitles: List[Dict], start_idx: int, end_idx: int) -> List[str]:
        """æå–å…³é”®å°è¯ - é«˜çº§ç‰ˆ"""
        key_dialogues = []

        # å…³é”®è¯å’Œæƒ…æ„Ÿå¼ºåº¦è¯„åˆ†
        priority_keywords = [
            'çœŸç›¸', 'è¯æ®', 'æ­£ä¹‰', 'åšæŒ', 'ç›¸ä¿¡', 'å¸Œæœ›', 'è´£ä»»', 'é€‰æ‹©', 'å†³å®š',
            'å¯¹ä¸èµ·', 'è°¢è°¢', 'çˆ±', 'æ¨', 'ç—›è‹¦', 'å¿«ä¹', 'æˆåŠŸ', 'å¤±è´¥', 'æ¢¦æƒ³'
        ]

        for i in range(start_idx, min(end_idx + 1, start_idx + 25)):
            subtitle = subtitles[i]
            text = subtitle['text']

            # è¯„åˆ†ç³»ç»Ÿ
            score = 0

            # å…³é”®è¯è¯„åˆ†
            for keyword in priority_keywords:
                if keyword in text:
                    score += 3

            # æƒ…æ„Ÿå¼ºåº¦è¯„åˆ†
            score += text.count('ï¼') * 2
            score += text.count('ï¼Ÿ') * 1.5
            score += text.count('...') * 1

            # é•¿åº¦è¯„åˆ†ï¼ˆ10-50å­—æœ€ä½³ï¼‰
            if 10 <= len(text) <= 50:
                score += 2

            # å¯¹è¯æ ‡è¯†è¯„åˆ†
            if 'ï¼š' in text or '"' in text:
                score += 1

            if score >= 4 and len(text) >= 8:
                key_dialogues.append(f"[{subtitle['start']}] {text}")

        # æ’åºå¹¶é€‰æ‹©æœ€ä½³çš„6ä¸ª
        return key_dialogues[:6]

    def _generate_third_person_narration_advanced(self, subtitles: List[Dict], start_idx: int, end_idx: int, plot_type: str, genre: str) -> str:
        """ç”Ÿæˆé«˜çº§ç¬¬ä¸‰äººç§°æ—ç™½ - é—®é¢˜3ï¼šæ—è§‚è€…å™è¿°"""
        content = ' '.join([subtitles[i]['text'] for i in range(start_idx, min(end_idx + 1, start_idx + 10))])

        # æ ¹æ®å‰§æƒ…ç±»å‹å’Œç‰‡æ®µç±»å‹ç”Ÿæˆä¸“ä¸šæ—ç™½
        narration_templates = {
            ('æ³•å¾‹å‰§', 'å…³é”®å†²çª'): "æ³•åº­ä¹‹ä¸Šï¼ŒåŒæ–¹å¾‹å¸ˆå”‡æªèˆŒå‰‘ï¼Œé’ˆé”‹ç›¸å¯¹ã€‚æ¯ä¸€ä¸ªè®ºç‚¹éƒ½å…³ä¹æ­£ä¹‰çš„å¤©å¹³ï¼Œæ¯ä¸€å¥åé©³éƒ½å¯èƒ½æ”¹å˜æ¡ˆä»¶èµ°å‘ã€‚åœ¨è¿™åœºæ²¡æœ‰ç¡çƒŸçš„æˆ˜äº‰ä¸­ï¼ŒçœŸç†ä¸å…¬æ­£æˆä¸ºæœ€ç»ˆçš„è£åˆ¤ã€‚",

            ('æ³•å¾‹å‰§', 'çº¿ç´¢æ­éœ²'): "å…³é”®æ—¶åˆ»ï¼Œéšè—å·²ä¹…çš„è¯æ®ç»ˆäºæµ®å‡ºæ°´é¢ã€‚è¿™ä¸ªå‘ç°å¦‚åŒé»‘æš—ä¸­çš„ä¸€æŸå…‰ï¼Œç…§äº®äº†æ¡ˆä»¶çš„çœŸç›¸ã€‚æ¯ä¸ªç»†èŠ‚éƒ½è¢«é‡æ–°å®¡è§†ï¼Œæ¯ä¸ªç–‘ç‚¹éƒ½å¾—åˆ°è§£ç­”ã€‚",

            ('çˆ±æƒ…å‰§', 'æƒ…æ„Ÿçˆ†å‘'): "æƒ…æ„Ÿåœ¨è¿™ä¸€åˆ»å†³å ¤è€Œå‡ºï¼Œå†ä¹Ÿæ— æ³•æ©é¥°å†…å¿ƒçš„æ³¢æ¾œã€‚çœ¼æ³ªæ¨¡ç³Šäº†è§†çº¿ï¼Œå´è®©å¿ƒçµæ›´åŠ æ¸…æ™°ã€‚è¿™ç§çœŸå®çš„æƒ…æ„Ÿè¡¨è¾¾ï¼Œè§¦åŠ¨ç€æ¯ä¸€ä¸ªè§‚ä¼—çš„å¿ƒå¼¦ã€‚",

            ('æ‚¬ç–‘å‰§', 'çº¿ç´¢æ­éœ²'): "è¿·é›¾å³å°†æ•£å»ï¼ŒçœŸç›¸çš„è½®å»“å¼€å§‹æ˜¾ç°ã€‚æ¯ä¸€ä¸ªçœ‹ä¼¼å¾®ä¸è¶³é“çš„ç»†èŠ‚ï¼Œéƒ½æ˜¯æ‹¼å›¾ä¸­ä¸å¯ç¼ºå°‘çš„ä¸€ç‰‡ã€‚æ¨ç†çš„é“¾æ¡ç¯ç¯ç›¸æ‰£ï¼ŒæŒ‡å‘é‚£ä¸ªéœ‡æ’¼çš„ç­”æ¡ˆã€‚",

            ('å®¶åº­å‰§', 'äººç‰©è½¬æŠ˜'): "åœ¨äººç”Ÿçš„åå­—è·¯å£ï¼Œé€‰æ‹©æ¯”åŠªåŠ›æ›´é‡è¦ã€‚è¿™ä¸ªå†³å®šå°†æ”¹å†™äººç‰©çš„å‘½è¿è½¨è¿¹ï¼Œä¹Ÿå°†é‡æ–°å®šä¹‰å®¶åº­çš„æœªæ¥ã€‚æˆé•¿ï¼Œæœ‰æ—¶å°±æ˜¯åœ¨è¿™æ ·çš„å…³é”®æ—¶åˆ»å®Œæˆã€‚"
        }

        # é€šç”¨æ¨¡æ¿
        generic_templates = {
            'å…³é”®å†²çª': "çŸ›ç›¾åœ¨æ­¤åˆ»ç™½çƒ­åŒ–ï¼Œå„æ–¹ç«‹åœºé²œæ˜ï¼Œå¯¸æ­¥ä¸è®©ã€‚è¿™åœºå†²çªä¸ä»…æ˜¯è§‚ç‚¹çš„äº¤é”‹ï¼Œæ›´æ˜¯ä»·å€¼è§‚çš„ç¢°æ’ã€‚æ¯ä¸€ä¸ªå­—éƒ½æ·åœ°æœ‰å£°ï¼Œæ¯ä¸€ä¸ªçœ¼ç¥éƒ½å……æ»¡åŠ›é‡ã€‚",

            'çº¿ç´¢æ­éœ²': "çœŸç›¸çš„é¢çº±è¢«ç¼“ç¼“æ€å¼€ï¼Œéšè—çš„ç§˜å¯†ç»ˆè§å¤©æ—¥ã€‚è¿™ä¸ªå‘ç°æ”¹å˜äº†ä¸€åˆ‡ï¼Œè®©æ‰€æœ‰äººé‡æ–°å®¡è§†å·²çŸ¥çš„äº‹å®ã€‚çœŸç†å¾€å¾€æ¯”æƒ³è±¡æ›´åŠ éœ‡æ’¼äººå¿ƒã€‚",

            'æƒ…æ„Ÿçˆ†å‘': "æƒ…æ„Ÿçš„é—¸é—¨åœ¨è¿™ä¸€ç¬é—´å¼€å¯ï¼Œæ±¹æ¶Œçš„æƒ…ç»ªå¦‚æ½®æ°´èˆ¬æ¶Œå‡ºã€‚è¿™ç§æ¯«æ— ä¿ç•™çš„çœŸæƒ…æµéœ²ï¼Œè®©è§‚ä¼—æ·±æ·±å…±é¸£ï¼Œä¹Ÿè®©è§’è‰²æ›´åŠ ç«‹ä½“é²œæ´»ã€‚",

            'äººç‰©è½¬æŠ˜': "å‘½è¿çš„è½¬æŠ˜ç‚¹å¾€å¾€å‡ºç°åœ¨æœ€ä¸ç»æ„çš„æ—¶åˆ»ã€‚è¿™ä¸ªé€‰æ‹©å°†å½»åº•æ”¹å˜è§’è‰²çš„äººç”Ÿè½¨è¿¹ï¼Œä¹Ÿä¸ºæ•…äº‹å¼€å¯å…¨æ–°çš„ç¯‡ç« ã€‚æˆé•¿ä¸èœ•å˜ï¼Œå°±åœ¨è¿™å…³é”®çš„ä¸€æ­¥ã€‚",

            'é‡è¦å¯¹è¯': "è¨€è¯­ä¹‹é—´è•´å«ç€æ·±åˆ»çš„å†…æ¶µï¼Œæ¯ä¸€å¥è¯éƒ½æ„å‘³æ·±é•¿ã€‚è¿™æ ·çš„å¯¹è¯ä¸ä»…æ¨è¿›å‰§æƒ…å‘å±•ï¼Œæ›´æ˜¯è§’è‰²å†…å¿ƒä¸–ç•Œçš„çœŸå®å†™ç…§ã€‚æ™ºæ…§ä¸æƒ…æ„Ÿçš„äº¤èï¼Œè®©æ•´ä¸ªåœºæ™¯å‡åã€‚",

            'ä¸»é¢˜å‡å': "åœ¨è¿™ä¸ªå…³é”®æ—¶åˆ»ï¼Œæ•…äº‹çš„æ·±å±‚ä¸»é¢˜å¾—åˆ°äº†å®Œç¾è¯ é‡Šã€‚è¶…è¶Šè¡¨é¢çš„æƒ…èŠ‚ï¼Œè§¦åŠäººæ€§çš„æœ¬è´¨ï¼Œå¼•å‘è§‚ä¼—å¯¹ç”Ÿæ´»ã€å¯¹äººç”Ÿçš„æ·±åº¦æ€è€ƒã€‚"
        }

        # ä¼˜å…ˆä½¿ç”¨ç‰¹å®šç±»å‹æ¨¡æ¿
        template_key = (genre, plot_type)
        if template_key in narration_templates:
            return narration_templates[template_key]
        else:
            return generic_templates.get(plot_type, "è¿™æ˜¯ä¸€ä¸ªç²¾å½©çš„å‰§æƒ…ç‰‡æ®µï¼Œå±•ç°äº†è§’è‰²çš„æ·±åº¦å’Œæ•…äº‹çš„é­…åŠ›ã€‚æƒ…èŠ‚ç´§å‡‘ï¼Œæƒ…æ„Ÿä¸°å¯Œï¼Œä¸ºæ•´éƒ¨å‰§å¢æ·»äº†æµ“å¢¨é‡å½©çš„ä¸€ç¬”ã€‚")

    def _generate_content_highlights(self, plot_type: str, genre: str) -> List[str]:
        """ç”Ÿæˆå†…å®¹äº®ç‚¹ - é—®é¢˜6ï¼šå†…å®¹äº®ç‚¹"""
        highlights_map = {
            'å…³é”®å†²çª': [
                f"{genre}ä¸­çš„ç»å…¸å¯¹æŠ—åœºé¢",
                "é’ˆé”‹ç›¸å¯¹çš„ç²¾å½©äº¤é”‹",
                "çŸ›ç›¾å†²çªçš„é›†ä¸­çˆ†å‘",
                "è§‚ç‚¹ç¢°æ’çš„æ¿€çƒˆæ—¶åˆ»"
            ],
            'çº¿ç´¢æ­éœ²': [
                "å…³é”®ä¿¡æ¯çš„é‡è¦æŠ«éœ²",
                "æ¨ç†é€»è¾‘çš„ç²¾å½©å±•ç¤º",
                "çœŸç›¸å¤§ç™½çš„éœ‡æ’¼æ—¶åˆ»",
                "æ‚¬å¿µè§£å¼€çš„ç²¾å½©è®¾è®¡"
            ],
            'æƒ…æ„Ÿçˆ†å‘': [
                "çœŸå®æƒ…æ„Ÿçš„æ·±åº¦è¡¨è¾¾",
                "è§’è‰²å†…å¿ƒçš„å®Œç¾è¯ é‡Š",
                "æƒ…æ„Ÿå…±é¸£çš„å¼ºçƒˆæ—¶åˆ»",
                "äººæ€§å…‰è¾‰çš„ç”ŸåŠ¨å±•ç°"
            ],
            'äººç‰©è½¬æŠ˜': [
                "è§’è‰²æˆé•¿çš„å…³é”®èŠ‚ç‚¹",
                "äººç”Ÿé€‰æ‹©çš„é‡è¦æ—¶åˆ»",
                "æ€§æ ¼è½¬å˜çš„ç²¾å½©åˆ»ç”»",
                "å‘½è¿è½¬æŠ˜çš„æ·±åº¦è¡¨ç°"
            ],
            'é‡è¦å¯¹è¯': [
                "æ·±åº¦å¯¹è¯çš„æ™ºæ…§ç¢°æ’",
                "å°è¯åŠŸåº•çš„ç²¾å½©å±•ç°",
                "æƒ…æ„Ÿè¡¨è¾¾çš„ç»†è…»åˆ»ç”»",
                "æ€æƒ³äº¤æµçš„æ·±åº¦ä½“ç°"
            ],
            'ä¸»é¢˜å‡å': [
                f"{genre}æ·±å±‚ä¸»é¢˜çš„å®Œç¾ä½“ç°",
                "ä»·å€¼è§‚å¿µçš„æ·±åº¦è¡¨è¾¾",
                "äººç”Ÿå“²ç†çš„æ™ºæ…§åˆ†äº«",
                "ç²¾ç¥å±‚é¢çš„æ·±åº¦æ€è€ƒ"
            ]
        }

        return highlights_map.get(plot_type, ["ç²¾å½©å‰§æƒ…ç‰‡æ®µ", "è§’è‰²æ·±åº¦åˆ»ç”»", "æƒ…èŠ‚ç´§å‡‘å‘å±•", "æƒ…æ„ŸçœŸå®è¡¨è¾¾"])

    def _generate_emotional_impact(self, plot_type: str) -> str:
        """ç”Ÿæˆæƒ…æ„Ÿå†²å‡»æè¿°"""
        impact_map = {
            'å…³é”®å†²çª': "æ¿€çƒˆçš„å¯¹æŠ—è®©è§‚ä¼—è¡€è„‰è´²å¼ ï¼Œç´§å¼ çš„æ°›å›´ä»¤äººå±æ¯å‡ç¥ï¼Œæ¯ä¸€ä¸ªå›åˆéƒ½ç‰µåŠ¨ç€è§‚ä¼—çš„å¿ƒå¼¦ã€‚",
            'çº¿ç´¢æ­éœ²': "çœŸç›¸æ­æ™“çš„ç¬é—´ä»¤äººéœ‡æ’¼ä¸å·²ï¼Œæç„¶å¤§æ‚Ÿçš„æ„Ÿè§‰è®©è§‚ä¼—æ‹æ¡ˆå«ç»ï¼Œæ¨ç†çš„é­…åŠ›å±•éœ²æ— é—ã€‚",
            'æƒ…æ„Ÿçˆ†å‘': "çœŸæŒšçš„æƒ…æ„Ÿè¡¨è¾¾ç›´å‡»å¿ƒçµæ·±å¤„ï¼Œè§‚ä¼—ä¸ç¦æ½¸ç„¶æ³ªä¸‹ï¼Œå…±æƒ…çš„åŠ›é‡è®©æ•´ä¸ªåœºæ™¯å‡åã€‚",
            'äººç‰©è½¬æŠ˜': "è§’è‰²çš„é‡è¦é€‰æ‹©è®©è§‚ä¼—ä¸ºä¹‹åŠ¨å®¹ï¼Œæˆé•¿çš„è¶³è¿¹æ¸…æ™°å¯è§ï¼Œäººæ€§çš„å…‰è¾‰é—ªé—ªå‘å…‰ã€‚",
            'é‡è¦å¯¹è¯': "æ·±åº¦çš„å¯¹è¯å¼•å‘æ€è€ƒå…±é¸£ï¼Œæ™ºæ…§çš„äº¤æµè®©è§‚ä¼—å—ç›ŠåŒªæµ…ï¼Œè¨€è¯­çš„åŠ›é‡éœ‡æ’¼äººå¿ƒã€‚",
            'ä¸»é¢˜å‡å': "æ·±å±‚ä¸»é¢˜çš„è¡¨è¾¾å¼•å‘å“²å­¦æ€è€ƒï¼Œç²¾ç¥å±‚é¢çš„è§¦åŠ¨è®©è§‚ä¼—æ„çŠ¹æœªå°½ï¼Œæ€æƒ³çš„æ·±åº¦ä»¤äººèµå¹ã€‚"
        }

        return impact_map.get(plot_type, "ç²¾å½©çš„å‰§æƒ…è¡¨ç°è®©è§‚ä¼—æ·±æ·±æ²‰æµ¸å…¶ä¸­ï¼Œæƒ…æ„Ÿä¸ç†æ™ºçš„äº¤èåˆ›é€ å‡ºéš¾å¿˜çš„è§‚å‰§ä½“éªŒã€‚")

    def find_video_file(self, srt_filename: str) -> Optional[str]:
        """æŸ¥æ‰¾å¯¹åº”çš„è§†é¢‘æ–‡ä»¶"""
        base_name = os.path.splitext(srt_filename)[0]
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts']

        # ç²¾ç¡®åŒ¹é…
        for ext in video_extensions:
            video_path = os.path.join(self.videos_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path

        # é›†æ•°åŒ¹é…
        episode_num = self._extract_episode_number(srt_filename)
        for filename in os.listdir(self.videos_folder):
            if any(filename.lower().endswith(ext) for ext in video_extensions):
                video_episode = self._extract_episode_number(filename)
                if episode_num == video_episode:
                    return os.path.join(self.videos_folder, filename)

        # æ¨¡ç³ŠåŒ¹é…
        for filename in os.listdir(self.videos_folder):
            if any(filename.lower().endswith(ext) for ext in video_extensions):
                if base_name.lower() in filename.lower() or filename.lower() in base_name.lower():
                    return os.path.join(self.videos_folder, filename)

        return None

    def check_ffmpeg(self) -> bool:
        """æ£€æŸ¥FFmpeg"""
        try:
            result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)
            return result.returncode == 0
        except:
            return False

    def get_clip_status_path(self, srt_file: str, plot_point: Dict) -> str:
        """è·å–å‰ªè¾‘çŠ¶æ€æ–‡ä»¶è·¯å¾„ - é—®é¢˜13ï¼šé¿å…é‡å¤å‰ªè¾‘"""
        episode_num = self._extract_episode_number(srt_file)
        plot_type = plot_point.get('type', 'unknown')
        title_hash = hashlib.md5(plot_point.get('title', '').encode()).hexdigest()[:8]
        return os.path.join(self.clip_status_folder, f"E{episode_num}_{plot_type}_{title_hash}.json")

    def is_clip_completed(self, srt_file: str, plot_point: Dict) -> bool:
        """æ£€æŸ¥å‰ªè¾‘æ˜¯å¦å·²å®Œæˆ - é—®é¢˜13ï¼šé¿å…é‡å¤å‰ªè¾‘"""
        status_path = self.get_clip_status_path(srt_file, plot_point)
        if os.path.exists(status_path):
            try:
                with open(status_path, 'r', encoding='utf-8') as f:
                    status = json.load(f)
                    output_path = status.get('output_path', '')
                    return os.path.exists(output_path) and os.path.getsize(output_path) > 1024
            except:
                return False
        return False

    def mark_clip_completed(self, srt_file: str, plot_point: Dict, output_path: str):
        """æ ‡è®°å‰ªè¾‘å·²å®Œæˆ - é—®é¢˜13ï¼šé¿å…é‡å¤å‰ªè¾‘"""
        status_path = self.get_clip_status_path(srt_file, plot_point)
        try:
            status = {
                'srt_file': srt_file,
                'plot_point': plot_point,
                'output_path': output_path,
                'completed_time': datetime.now().isoformat(),
                'file_size': os.path.getsize(output_path) if os.path.exists(output_path) else 0
            }
            with open(status_path, 'w', encoding='utf-8') as f:
                json.dump(status, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ çŠ¶æ€æ ‡è®°å¤±è´¥: {e}")

    def create_video_clips_stable(self, plot_points: List[Dict], video_file: str, srt_filename: str) -> List[str]:
        """åˆ›å»ºè§†é¢‘ç‰‡æ®µ - ç¨³å®šç‰ˆæœ¬ - é—®é¢˜12,13ï¼šå‰ªè¾‘ç¨³å®šæ€§å’Œä¸€è‡´æ€§"""
        if not self.check_ffmpeg():
            print("âŒ æœªæ‰¾åˆ°FFmpegï¼Œæ— æ³•å‰ªè¾‘è§†é¢‘")
            return []

        created_clips = []
        episode_num = self._extract_episode_number(srt_filename)

        for i, plot_point in enumerate(plot_points, 1):
            # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆå‰ªè¾‘ - é—®é¢˜13
            if self.is_clip_completed(srt_filename, plot_point):
                status_path = self.get_clip_status_path(srt_filename, plot_point)
                try:
                    with open(status_path, 'r', encoding='utf-8') as f:
                        status = json.load(f)
                        existing_path = status.get('output_path', '')
                        if os.path.exists(existing_path):
                            print(f"âœ… ç‰‡æ®µå·²å­˜åœ¨: {os.path.basename(existing_path)}")
                            created_clips.append(existing_path)
                            continue
                except:
                    pass

            plot_type = plot_point.get('type', 'æœªçŸ¥ç±»å‹')
            title = plot_point.get('title', f'ç¬¬{episode_num}é›†ç‰‡æ®µ{i}')

            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å - é—®é¢˜12ï¼šç¡®ä¿ä¸€è‡´æ€§
            safe_title = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', title)
            clip_filename = f"{safe_title}.mp4"
            clip_path = os.path.join(self.clips_folder, clip_filename)

            print(f"\nğŸ¬ å‰ªè¾‘ç‰‡æ®µ {i}: {title}")
            print(f"   ç±»å‹: {plot_type}")

            # å¤„ç†æ—¶é—´æ®µ - é—®é¢˜3ï¼šæ”¯æŒéè¿ç»­æ—¶é—´æ®µ
            time_segments = plot_point.get('time_segments', [])
            if not time_segments:
                print(f"   âŒ ç¼ºå°‘æ—¶é—´æ®µä¿¡æ¯")
                continue

            # åˆ›å»ºç‰‡æ®µ
            if self._create_video_from_segments(video_file, time_segments, clip_path, plot_point):
                created_clips.append(clip_path)
                self.mark_clip_completed(srt_filename, plot_point, clip_path)
                self._create_clip_description_advanced(clip_path, plot_point, episode_num)
            else:
                print(f"   âŒ å‰ªè¾‘å¤±è´¥")

        return created_clips

    def _create_video_from_segments(self, video_file: str, time_segments: List[Dict], output_path: str, plot_point: Dict, max_retries: int = 3) -> bool:
        """ä»æ—¶é—´æ®µåˆ›å»ºè§†é¢‘ - æ”¯æŒéè¿ç»­ç‰‡æ®µ - é—®é¢˜3,12ï¼šéè¿ç»­æ—¶é—´æ®µå’Œç¨³å®šæ€§"""

        for attempt in range(max_retries):
            try:
                if len(time_segments) == 1:
                    # å•ä¸ªè¿ç»­ç‰‡æ®µ
                    segment = time_segments[0]
                    start_time = segment['start_time']
                    end_time = segment['end_time']

                    start_seconds = self._time_to_seconds(start_time)
                    end_seconds = self._time_to_seconds(end_time)
                    duration = end_seconds - start_seconds

                    print(f"   â±ï¸ æ—¶é—´: {start_time} --> {end_time} ({duration:.1f}ç§’)")

                    if duration <= 0:
                        print(f"   âŒ æ— æ•ˆæ—¶é—´æ®µ")
                        return False

                    # æ·»åŠ å°é‡ç¼“å†²
                    buffer_start = max(0, start_seconds - 0.5)
                    buffer_duration = duration + 1

                    cmd = [
                        'ffmpeg',
                        '-i', video_file,
                        '-ss', str(buffer_start),
                        '-t', str(buffer_duration),
                        '-c:v', 'libx264',
                        '-c:a', 'aac',
                        '-preset', 'medium',
                        '-crf', '23',
                        '-avoid_negative_ts', 'make_zero',
                        '-movflags', '+faststart',
                        output_path,
                        '-y'
                    ]
                else:
                    # å¤šä¸ªç‰‡æ®µåˆå¹¶
                    print(f"   ğŸ“ åˆå¹¶ {len(time_segments)} ä¸ªç‰‡æ®µ")

                    # åˆ›å»ºä¸´æ—¶ç‰‡æ®µæ–‡ä»¶
                    temp_files = []
                    temp_list_file = output_path.replace('.mp4', '_segments.txt')

                    for j, segment in enumerate(time_segments):
                        start_seconds = self._time_to_seconds(segment['start_time'])
                        end_seconds = self._time_to_seconds(segment['end_time'])
                        duration = end_seconds - start_seconds

                        if duration <= 0:
                            continue

                        temp_file = output_path.replace('.mp4', f'_temp_{j}.mp4')
                        temp_files.append(temp_file)

                        # åˆ›å»ºä¸´æ—¶ç‰‡æ®µ
                        temp_cmd = [
                            'ffmpeg',
                            '-i', video_file,
                            '-ss', str(start_seconds),
                            '-t', str(duration),
                            '-c:v', 'libx264',
                            '-c:a', 'aac',
                            '-preset', 'medium',
                            '-crf', '23',
                            temp_file,
                            '-y'
                        ]

                        result = subprocess.run(temp_cmd, capture_output=True, text=True, timeout=180)
                        if result.returncode != 0:
                            print(f"   âš ï¸ ä¸´æ—¶ç‰‡æ®µ {j+1} åˆ›å»ºå¤±è´¥")
                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            for tf in temp_files:
                                if os.path.exists(tf):
                                    os.remove(tf)
                            return False

                    if not temp_files:
                        print(f"   âŒ æ²¡æœ‰æœ‰æ•ˆçš„ç‰‡æ®µ")
                        return False

                    # åˆ›å»ºåˆå¹¶åˆ—è¡¨æ–‡ä»¶
                    with open(temp_list_file, 'w', encoding='utf-8') as f:
                        for temp_file in temp_files:
                            f.write(f"file '{temp_file}'\n")

                    # åˆå¹¶ç‰‡æ®µ
                    cmd = [
                        'ffmpeg',
                        '-f', 'concat',
                        '-safe', '0',
                        '-i', temp_list_file,
                        '-c', 'copy',
                        output_path,
                        '-y'
                    ]

                # æ‰§è¡Œå‘½ä»¤ï¼Œå¢å¼ºç¼–ç å¤„ç†
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300, encoding='utf-8', errors='replace')

                if result.returncode == 0 and os.path.exists(output_path) and os.path.getsize(output_path) > 1024:
                    file_size = os.path.getsize(output_path) / (1024*1024)
                    total_duration = plot_point.get('total_duration', 0)
                    print(f"   âœ… æˆåŠŸ: {os.path.basename(output_path)} ({file_size:.1f}MB, {total_duration:.1f}ç§’)")

                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if len(time_segments) > 1:
                        for temp_file in temp_files:
                            if os.path.exists(temp_file):
                                os.remove(temp_file)
                        if os.path.exists(temp_list_file):
                            os.remove(temp_list_file)

                    return True
                else:
                    error_msg = result.stderr[:200] if result.stderr else 'æœªçŸ¥é”™è¯¯'
                    print(f"   âŒ å°è¯• {attempt+1} å¤±è´¥: {error_msg}")

                    # æ¸…ç†å¤±è´¥æ–‡ä»¶
                    if os.path.exists(output_path):
                        os.remove(output_path)

                    if len(time_segments) > 1:
                        for temp_file in temp_files:
                            if os.path.exists(temp_file):
                                os.remove(temp_file)
                        if os.path.exists(temp_list_file):
                            os.remove(temp_list_file)

            except subprocess.TimeoutExpired:
                print(f"   âŒ å°è¯• {attempt+1} è¶…æ—¶")
            except Exception as e:
                print(f"   âŒ å°è¯• {attempt+1} å¼‚å¸¸: {e}")

            # é‡è¯•å‰ç­‰å¾…
            if attempt < max_retries - 1:
                time.sleep(1)

        print(f"   âŒ æ‰€æœ‰é‡è¯•å¤±è´¥")
        return False

    def _create_clip_description_advanced(self, video_path: str, plot_point: Dict, episode_num: str):
        """åˆ›å»ºé«˜çº§ç‰‡æ®µæè¿°æ–‡ä»¶ - é—®é¢˜5ï¼šå›ºå®šè¾“å‡ºæ ¼å¼"""
        try:
            desc_path = video_path.replace('.mp4', '_å®Œæ•´è¯´æ˜.txt')

            content = f"""ğŸ“º {plot_point.get('title', 'ç²¾å½©ç‰‡æ®µ')}
{"=" * 80}

ã€åŸºæœ¬ä¿¡æ¯ã€‘
é›†æ•°ç¼–å·ï¼šç¬¬{episode_num}é›†
ç‰‡æ®µç±»å‹ï¼š{plot_point.get('type', 'æœªçŸ¥ç±»å‹')}
æ€»æ—¶é•¿ï¼š{plot_point.get('total_duration', 0):.1f} ç§’

ã€æ—¶é—´æ®µä¿¡æ¯ã€‘"""

            for i, segment in enumerate(plot_point.get('time_segments', []), 1):
                content += f"""
ç‰‡æ®µ {i}ï¼š{segment.get('start_time')} --> {segment.get('end_time')}
é€‰æ‹©åŸå› ï¼š{segment.get('reason', 'æ ¸å¿ƒç‰‡æ®µ')}"""

            content += f"""

ã€å‰§æƒ…åˆ†æã€‘
å‰§æƒ…æ„ä¹‰ï¼š{plot_point.get('plot_significance', 'æ¨åŠ¨å‰§æƒ…å‘å±•')}
å†…å®¹æ‘˜è¦ï¼š{plot_point.get('content_summary', 'ç²¾å½©ç‰‡æ®µå†…å®¹')}
æƒ…æ„Ÿå†²å‡»ï¼š{plot_point.get('emotional_impact', 'æ·±åº¦æƒ…æ„Ÿè¡¨è¾¾')}

ã€å†…å®¹äº®ç‚¹ã€‘"""
            for highlight in plot_point.get('content_highlights', []):
                content += f"\nâ€¢ {highlight}"

            content += f"""

ã€å…³é”®å°è¯ã€‘"""
            for dialogue in plot_point.get('key_dialogues', []):
                content += f"\n{dialogue}"

            content += f"""

ã€ç¬¬ä¸‰äººç§°æ—ç™½å­—å¹•ã€‘
{plot_point.get('third_person_narration', 'ä¸“ä¸šæ—ç™½è§£è¯´')}

ã€ä¸‹é›†è¡”æ¥ã€‘
{plot_point.get('connection_setup', 'ä¸ºåç»­å‰§æƒ…å‘å±•åšé“ºå«')}

ã€æŠ€æœ¯è¯´æ˜ã€‘
â€¢ æ”¯æŒéè¿ç»­æ—¶é—´æ®µçš„æ™ºèƒ½åˆå¹¶
â€¢ è‡ªåŠ¨ä¿®æ­£é”™åˆ«å­—ï¼Œä¾¿äºå‰ªè¾‘å‚è€ƒ
â€¢ ç¡®ä¿å¥å­å®Œæ•´ï¼Œä¸æˆªæ–­é‡è¦å¯¹è¯
â€¢ ç”Ÿæˆç¬¬ä¸‰äººç§°æ—ç™½ï¼Œé€‚åˆçŸ­è§†é¢‘åˆ¶ä½œ
â€¢ ä¿è¯å‰§æƒ…è¿è´¯æ€§å’Œè·¨é›†è¡”æ¥

ã€å‰ªè¾‘å»ºè®®ã€‘
â€¢ ä¸¥æ ¼æŒ‰ç…§æ ‡æ³¨æ—¶é—´è¿›è¡Œå‰ªè¾‘
â€¢ å¯åœ¨å¼€å¤´æ·»åŠ ç®€çŸ­èƒŒæ™¯ä»‹ç»ï¼ˆ5-10ç§’ï¼‰
â€¢ ç»“å°¾å¯æ·»åŠ ä¸‹é›†é¢„å‘Šæç¤ºï¼ˆ3-5ç§’ï¼‰
â€¢ ä½¿ç”¨æä¾›çš„ç¬¬ä¸‰äººç§°æ—ç™½ä½œä¸ºé…éŸ³æ–‡æœ¬
â€¢ æ³¨æ„ä¿æŒåŸå£°ä¸æ—ç™½çš„å¹³è¡¡

ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

            with open(desc_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"   ğŸ“ è¯´æ˜æ–‡ä»¶: {os.path.basename(desc_path)}")

        except Exception as e:
            print(f"   âš ï¸ è¯´æ˜æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {e}")

    def update_series_context(self, episode_num: str, analysis_result: Dict, plot_points: List[Dict]):
        """æ›´æ–°å…¨å‰§ä¸Šä¸‹æ–‡ - é—®é¢˜4,8ï¼šè·¨é›†è¿è´¯æ€§"""
        try:
            # æ·»åŠ åˆ°å·²å¤„ç†é›†æ•°
            episode_summary = {
                'episode': episode_num,
                'summary': analysis_result.get('episode_summary', {}).get('core_storyline', f'ç¬¬{episode_num}é›†å‰§æƒ…'),
                'main_conflicts': analysis_result.get('episode_analysis', {}).get('main_conflicts', []),
                'key_characters': analysis_result.get('episode_analysis', {}).get('key_characters', []),
                'connection_hint': analysis_result.get('episode_summary', {}).get('next_episode_connection', '')
            }

            self.series_context['previous_episodes'].append(episode_summary)

            # æ›´æ–°ä¸»è¦æ•…äº‹çº¿
            for point in plot_points:
                storyline = f"{point.get('type', 'å‰§æƒ…å‘å±•')}: {point.get('title', 'ç²¾å½©ç‰‡æ®µ')}"
                if storyline not in self.series_context['main_storylines']:
                    self.series_context['main_storylines'].append(storyline)

            # æ›´æ–°æŒç»­å†²çª
            main_conflicts = analysis_result.get('episode_analysis', {}).get('main_conflicts', [])
            for conflict in main_conflicts:
                if conflict not in self.series_context['ongoing_conflicts']:
                    self.series_context['ongoing_conflicts'].append(conflict)

            # åªä¿ç•™æœ€è¿‘çš„ä¸Šä¸‹æ–‡
            if len(self.series_context['previous_episodes']) > 5:
                self.series_context['previous_episodes'] = self.series_context['previous_episodes'][-5:]

            if len(self.series_context['main_storylines']) > 10:
                self.series_context['main_storylines'] = self.series_context['main_storylines'][-10:]

            if len(self.series_context['ongoing_conflicts']) > 6:
                self.series_context['ongoing_conflicts'] = self.series_context['ongoing_conflicts'][-6:]

        except Exception as e:
            print(f"âš ï¸ ä¸Šä¸‹æ–‡æ›´æ–°å¤±è´¥: {e}")

    def process_episode_complete(self, srt_filename: str) -> Optional[Dict]:
        """å¤„ç†å•é›† - å®Œæ•´ç‰ˆ - é—®é¢˜14,15ï¼šç¡®ä¿ä¸€è‡´æ€§"""
        print(f"\nğŸ“º å¤„ç†é›†æ•°: {srt_filename}")

        episode_num = self._extract_episode_number(srt_filename)

        # 1. æ£€æŸ¥åˆ†æç¼“å­˜ - é—®é¢˜11
        cached_analysis = self.load_analysis_cache(srt_filename)
        if cached_analysis:
            print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜çš„åˆ†æç»“æœ")
            analysis_result = cached_analysis
            plot_points = analysis_result.get('plot_points', [])
        else:
            # 2. è§£æå­—å¹•
            srt_path = os.path.join(self.srt_folder, srt_filename)
            subtitles = self.parse_srt_file(srt_path)

            if not subtitles:
                print(f"âŒ å­—å¹•è§£æå¤±è´¥")
                return None

            # 3. ä½¿ç”¨AIè¯†åˆ«å‰§æƒ…ç±»å‹å’Œä¸»é¢˜
            genre, themes = self.detect_genre_and_themes_ai(subtitles)
            
            if not genre or not themes:
                print("âŒ AIç±»å‹è¯†åˆ«å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å¤„ç†")
                return None

            # 4. æ„å»ºå‰§é›†ä¸Šä¸‹æ–‡
            series_context = self.build_series_context(episode_num)

            # 5. åªä½¿ç”¨AIåˆ†æï¼Œå¤±è´¥ç›´æ¥è¿”å›
            ai_analysis = self.ai_analyze_episode_complete(subtitles, episode_num, genre, themes, series_context)

            if ai_analysis and ai_analysis.get('plot_points'):
                analysis_result = ai_analysis
                plot_points = ai_analysis['plot_points']
                print(f"ğŸ¤– AIåˆ†ææˆåŠŸ: {len(plot_points)} ä¸ªå‰§æƒ…ç‚¹")
            else:
                print("âŒ AIåˆ†æå¤±è´¥ï¼Œæ— æ³•å¤„ç†æ­¤é›†")
                print("ğŸ’¡ è¯·æ£€æŸ¥AIé…ç½®æˆ–ç½‘ç»œè¿æ¥")
                return None

            if not plot_points:
                print(f"âŒ AIæœªæ‰¾åˆ°åˆé€‚çš„å‰§æƒ…ç‚¹")
                return None

            # 6. ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜ - é—®é¢˜11
            self.save_analysis_cache(srt_filename, analysis_result)

        # è¾“å‡ºåˆ†æç»“æœ
        print(f"ğŸ¯ è¯†åˆ«åˆ° {len(plot_points)} ä¸ªå‰§æƒ…ç‚¹:")
        for i, point in enumerate(plot_points, 1):
            plot_type = point.get('type', 'æœªçŸ¥ç±»å‹')
            title = point.get('title', 'æ— æ ‡é¢˜')
            duration = point.get('total_duration', 0)
            print(f"    {i}. {plot_type}: {title} ({duration:.1f}ç§’)")

        # 7. æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        video_file = self.find_video_file(srt_filename)
        if not video_file:
            print(f"âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return None

        print(f"ğŸ“ è§†é¢‘æ–‡ä»¶: {os.path.basename(video_file)}")

        # 8. åˆ›å»ºè§†é¢‘ç‰‡æ®µ
        created_clips = self.create_video_clips_stable(plot_points, video_file, srt_filename)

        # 9. æ›´æ–°å…¨å‰§ä¸Šä¸‹æ–‡
        self.update_series_context(episode_num, analysis_result, plot_points)

        return {
            'episode_number': episode_num,
            'filename': srt_filename,
            'analysis_result': analysis_result,
            'plot_points': plot_points,
            'created_clips': len(created_clips),
            'clip_paths': created_clips,
            'processing_timestamp': datetime.now().isoformat()
        }

    def process_all_episodes(self):
        """å¤„ç†æ‰€æœ‰é›†æ•° - ä¸»å‡½æ•° - é—®é¢˜15ï¼šå¤„ç†æ‰€æœ‰SRTæ–‡ä»¶"""
        print("\nğŸš€ å¼€å§‹å®Œæ•´æ™ºèƒ½å‰§æƒ…å‰ªè¾‘å¤„ç†")
        print("=" * 60)

        # è·å–æ‰€æœ‰SRTæ–‡ä»¶å¹¶æŒ‰åç§°æ’åº - é—®é¢˜2ï¼šæŒ‰é¡ºåºå¤„ç†
        srt_files = [f for f in os.listdir(self.srt_folder) 
                     if f.lower().endswith(('.srt', '.txt')) and not f.startswith('.')]

        if not srt_files:
            print(f"âŒ {self.srt_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            return

        # æŒ‰å­—ç¬¦ä¸²æ’åºï¼ˆæ–‡ä»¶åé¡ºåºï¼‰
        srt_files.sort()

        print(f"ğŸ“ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰")
        for i, f in enumerate(srt_files, 1):
            print(f"   {i}. {f}")

        print(f"\nğŸ¬ è§†é¢‘ç›®å½•: {self.videos_folder}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.clips_folder}")
        print(f"ğŸ’¾ ç¼“å­˜ç³»ç»Ÿ: å¯ç”¨")

        if self.ai_config.get('enabled'):
            api_type = self.ai_config.get('api_type', 'æœªçŸ¥')
            provider = self.ai_config.get('provider', 'æœªçŸ¥')
            print(f"ğŸ¤– AIåˆ†æ: å¯ç”¨ ({api_type} - {provider})")
        else:
            print(f"ğŸ“ AIåˆ†æ: æœªå¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€è§„åˆ™")

        # å¤„ç†æ¯ä¸€é›†
        all_episodes = []
        total_clips = 0
        success_count = 0

        for i, srt_file in enumerate(srt_files):
            try:
                print(f"\n{'='*80}")
                print(f"ğŸ“º å¤„ç†ç¬¬ {i+1}/{len(srt_files)} é›†: {srt_file}")
                print(f"{'='*80}")

                episode_summary = self.process_episode_complete(srt_file)
                if episode_summary:
                    all_episodes.append(episode_summary)
                    total_clips += episode_summary['created_clips']
                    success_count += 1
                    print(f"âœ… ç¬¬{i+1}é›†å¤„ç†æˆåŠŸ: {episode_summary['created_clips']} ä¸ªç‰‡æ®µ")
                else:
                    print(f"âŒ ç¬¬{i+1}é›†å¤„ç†å¤±è´¥")

            except Exception as e:
                print(f"âŒ å¤„ç† {srt_file} å‡ºé”™: {e}")

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self._create_comprehensive_report(all_episodes, total_clips, len(srt_files))

        print(f"\n{'='*80}")
        print(f"ğŸ“Š å®Œæ•´å¤„ç†ç»Ÿè®¡:")
        print(f"âœ… æˆåŠŸå¤„ç†: {success_count}/{len(srt_files)} é›†")
        print(f"ğŸ¬ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.clips_folder}/")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {os.path.join(self.reports_folder, 'å®Œæ•´æ™ºèƒ½å‰ªè¾‘æŠ¥å‘Š.txt')}")
        print(f"ğŸ’¾ ç¼“å­˜æ–‡ä»¶: {len(os.listdir(self.analysis_cache_folder))} ä¸ª")
        print(f"ğŸ¯ å‰ªè¾‘çŠ¶æ€: {len(os.listdir(self.clip_status_folder))} ä¸ª")
        print("ğŸ‰ æ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿå¤„ç†å®Œæˆï¼")

    def _create_comprehensive_report(self, episodes: List[Dict], total_clips: int, total_episodes: int):
        """åˆ›å»ºç»¼åˆæŠ¥å‘Š - é—®é¢˜5ï¼šå›ºå®šè¾“å‡ºæ ¼å¼"""
        if not episodes:
            return

        report_path = os.path.join(self.reports_folder, "å®Œæ•´æ™ºèƒ½å‰ªè¾‘æŠ¥å‘Š.txt")

        content = f"""ğŸ“º å®Œæ•´æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»ŸæŠ¥å‘Š
{"=" * 100}

ğŸ“Š å¤„ç†ç»Ÿè®¡ï¼š
â€¢ æ€»é›†æ•°: {total_episodes} é›†
â€¢ æˆåŠŸå¤„ç†: {len(episodes)} é›†
â€¢ æˆåŠŸç‡: {len(episodes)/total_episodes*100:.1f}%
â€¢ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª
â€¢ å¹³å‡æ¯é›†ç‰‡æ®µ: {total_clips/len(episodes):.1f} ä¸ª

ğŸ¤– ç³»ç»Ÿé…ç½®ï¼š
â€¢ AIåˆ†æçŠ¶æ€: {'å·²å¯ç”¨' if self.ai_config.get('enabled') else 'åŸºç¡€è§„åˆ™åˆ†æ'}
â€¢ ç¼“å­˜æœºåˆ¶: å¯ç”¨ (é¿å…é‡å¤åˆ†æå’Œå‰ªè¾‘)
â€¢ ä¸€è‡´æ€§ä¿è¯: å¯ç”¨ (å¤šæ¬¡æ‰§è¡Œç»“æœä¸€è‡´)
â€¢ é”™åˆ«å­—ä¿®æ­£: å¯ç”¨

ğŸ­ å‰§æƒ…ç±»å‹åˆ†æï¼š
â€¢ æ£€æµ‹ç±»å‹: {self.series_context.get('genre_detected', 'æœªæ£€æµ‹')}
â€¢ ä¸»è¦ä¸»é¢˜: {', '.join(self.series_context.get('main_themes', []))}

ğŸ“ˆ å‰§æƒ…ç‚¹ç±»å‹åˆ†å¸ƒï¼š
"""

        # ç»Ÿè®¡å‰§æƒ…ç‚¹ç±»å‹
        plot_type_stats = {}
        total_duration = 0

        for episode in episodes:
            for plot_point in episode.get('plot_points', []):
                plot_type = plot_point.get('type', 'æœªçŸ¥ç±»å‹')
                plot_type_stats[plot_type] = plot_type_stats.get(plot_type, 0) + 1
                total_duration += plot_point.get('total_duration', 0)

        for plot_type, count in sorted(plot_type_stats.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / sum(plot_type_stats.values())) * 100
            content += f"â€¢ {plot_type}: {count} ä¸ª ({percentage:.1f}%)\n"

        avg_duration = total_duration / sum(plot_type_stats.values()) if plot_type_stats else 0

        content += f"""
ğŸ“ æ—¶é•¿ç»Ÿè®¡ï¼š
â€¢ æ€»æ—¶é•¿: {total_duration:.1f} ç§’ ({total_duration/60:.1f} åˆ†é’Ÿ)
â€¢ å¹³å‡ç‰‡æ®µæ—¶é•¿: {avg_duration:.1f} ç§’ ({avg_duration/60:.1f} åˆ†é’Ÿ)

ğŸ”— è·¨é›†è¿è´¯æ€§ï¼š
â€¢ ä¸Šä¸‹æ–‡ç®¡ç†: å¯ç”¨
â€¢ å‰æƒ…å›é¡¾: è‡ªåŠ¨ç”Ÿæˆ
â€¢ è¡”æ¥ç‚¹åˆ†æ: æ™ºèƒ½è¯†åˆ«
â€¢ æ•…äº‹çº¿è¿½è¸ª: å®Œæ•´ä¿æŒ

ğŸ“ è¯¦ç»†åˆ†é›†ä¿¡æ¯ï¼š
{"=" * 100}
"""

        # è¯¦ç»†åˆ†é›†ä¿¡æ¯
        for i, episode in enumerate(episodes, 1):
            analysis = episode.get('analysis_result', {})
            episode_analysis = analysis.get('episode_analysis', {})
            episode_summary = analysis.get('episode_summary', {})

            content += f"""
ã€ç¬¬{episode['episode_number']}é›†ã€‘{episode['filename']}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å‰§æƒ…ç±»å‹ï¼š{episode_analysis.get('genre', 'æœªçŸ¥')}
æ ¸å¿ƒä¸»é¢˜ï¼š{episode_analysis.get('main_theme', 'ä¸»è¦å†…å®¹')}
æ•…äº‹è¿›å±•ï¼š{episode_analysis.get('story_progression', 'å‰§æƒ…å‘å±•')}
æƒ…æ„Ÿå‘å±•ï¼š{episode_analysis.get('emotional_arc', 'æƒ…æ„Ÿæ¨è¿›')}
ä¸»è¦è§’è‰²ï¼š{', '.join(episode_analysis.get('key_characters', []))}
æ ¸å¿ƒå†²çªï¼š{', '.join(episode_analysis.get('main_conflicts', []))}

ç”Ÿæˆç‰‡æ®µï¼š{episode['created_clips']} ä¸ª
å‰§æƒ…ç‚¹è¯¦æƒ…ï¼š
"""

            for j, plot_point in enumerate(episode.get('plot_points', []), 1):
                time_segments = plot_point.get('time_segments', [])
                time_info = ""
                if len(time_segments) == 1:
                    seg = time_segments[0]
                    time_info = f"{seg.get('start_time')} --> {seg.get('end_time')}"
                else:
                    time_info = f"{len(time_segments)} ä¸ªç‰‡æ®µåˆå¹¶"

                content += f"""  {j}. {plot_point.get('type', 'æœªçŸ¥ç±»å‹')} - {plot_point.get('title', 'æ— æ ‡é¢˜')}
     æ—¶é—´ï¼š{time_info} (æ€»æ—¶é•¿: {plot_point.get('total_duration', 0):.1f}ç§’)
     æ„ä¹‰ï¼š{plot_point.get('plot_significance', 'å‰§æƒ…æ¨è¿›')[:60]}...
     æ—ç™½ï¼š{plot_point.get('third_person_narration', 'ä¸“ä¸šè§£è¯´')[:60]}...
"""

            content += f"""

ä¸‹é›†è¡”æ¥ï¼š{episode_summary.get('next_episode_connection', 'è‡ªç„¶è¿‡æ¸¡')}
"""

        content += f"""

ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š
â€¢ æ‰€æœ‰è§†é¢‘ç‰‡æ®µå·²ä¿å­˜åœ¨ {self.clips_folder}/ ç›®å½•
â€¢ æ¯ä¸ªç‰‡æ®µéƒ½æœ‰å¯¹åº”çš„è¯¦ç»†è¯´æ˜æ–‡æ¡£
â€¢ æ”¯æŒéè¿ç»­æ—¶é—´æ®µçš„æ™ºèƒ½åˆå¹¶å‰ªè¾‘
â€¢ ç¬¬ä¸‰äººç§°æ—ç™½å¯ç›´æ¥ç”¨äºé…éŸ³åˆ¶ä½œ
â€¢ é”™åˆ«å­—å·²è‡ªåŠ¨ä¿®æ­£ï¼Œä¾¿äºå‰ªè¾‘å‚è€ƒ
â€¢ ç¼“å­˜ç³»ç»Ÿç¡®ä¿é‡å¤æ‰§è¡Œçš„ä¸€è‡´æ€§

ğŸ”§ æŠ€æœ¯ç‰¹æ€§ï¼š
â€¢ æ™ºèƒ½å‰§æƒ…ç±»å‹è¯†åˆ«
â€¢ AIé©±åŠ¨çš„å‰§æƒ…ç‚¹åˆ†æ
â€¢ å®Œæ•´å¥å­è¾¹ç•Œä¿è¯
â€¢ è·¨é›†è¿è´¯æ€§ç®¡ç†
â€¢ ç¨³å®šçš„ç¼“å­˜æœºåˆ¶
â€¢ æ–­ç‚¹ç»­ä¼ æ”¯æŒ
â€¢ å¤šé‡é‡è¯•æœºåˆ¶

ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ç³»ç»Ÿç‰ˆæœ¬ï¼šå®Œæ•´æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ v2.0
"""

        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"ğŸ“„ ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        except Exception as e:
            print(f"âš ï¸ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")

def show_main_menu():
    """æ˜¾ç¤ºä¸»èœå•"""
    print("\nğŸ¤– AIæ™ºèƒ½è§†é¢‘å‰ªè¾‘ç³»ç»Ÿ")
    print("=" * 50)
    print("ğŸ“‹ è¯·é€‰æ‹©æ“ä½œ:")
    print("1. ğŸš€ å¼€å§‹ç”µè§†å‰§AIåˆ†æå’Œå‰ªè¾‘")
    print("2. ğŸ¬ å¼€å§‹ç”µå½±AIåˆ†æå’Œå‰ªè¾‘")
    print("3. âš™ï¸ æ£€æŸ¥AIé…ç½®")
    print("4. ğŸ”§ é‡æ–°é…ç½®AI")
    print("5. ğŸ“Š æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
    print("6. ğŸ“– æŸ¥çœ‹ä½¿ç”¨æ•™ç¨‹")
    print("7. âŒ é€€å‡ºç³»ç»Ÿ")
    print("=" * 50)

def show_tutorial():
    """æ˜¾ç¤ºä½¿ç”¨æ•™ç¨‹"""
    print("\nğŸ“– AIæ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿä½¿ç”¨æ•™ç¨‹")
    print("=" * 60)
    print("ğŸ“º 1. ç”µè§†å‰§å‰ªè¾‘:")
    print("   â€¢ å°†å­—å¹•æ–‡ä»¶(.srt/.txt)æ”¾å…¥ srt/ ç›®å½•")
    print("   â€¢ å°†è§†é¢‘æ–‡ä»¶(.mp4/.mkvç­‰)æ”¾å…¥ videos/ ç›®å½•")
    print("   â€¢ ç¡®ä¿æ–‡ä»¶ååŒ…å«é›†æ•°ä¿¡æ¯(å¦‚: E01.srt)")
    print()
    print("ğŸ¬ 2. ç”µå½±å‰ªè¾‘ (æ–°åŠŸèƒ½):")
    print("   â€¢ å°†ç”µå½±å­—å¹•æ–‡ä»¶æ”¾å…¥ movie_srt/ ç›®å½•")
    print("   â€¢ å°†ç”µå½±è§†é¢‘æ–‡ä»¶æ”¾å…¥ movie_videos/ ç›®å½•")
    print("   â€¢ æ”¯æŒæ— å£°è§†é¢‘å‰ªè¾‘ï¼Œä¸“ä¸ºç¬¬ä¸€äººç§°å™è¿°è®¾è®¡")
    print("   â€¢ è‡ªåŠ¨ä¿®æ­£é”™åˆ«å­—: 'é˜²è¡›'â†’'é˜²å«', 'æ­£ç•¶'â†’'æ­£å½“'")
    print("   â€¢ ç¬¬ä¸€äººç§°å™è¿°ä¸è§†é¢‘å†…å®¹å®æ—¶åŒæ­¥")
    print()
    print("ğŸ¤– 3. AIé…ç½®è¦æ±‚:")
    print("   â€¢ æœ¬ç³»ç»Ÿåªä½¿ç”¨AIåˆ†æï¼Œæ— åŸºç¡€åˆ†æå¤‡é€‰")
    print("   â€¢ æ”¯æŒå®˜æ–¹APIå’Œä¸­è½¬API")
    print("   â€¢ æ¨èä½¿ç”¨: Gemini, GPT-4, DeepSeekç­‰")
    print()
    print("âš¡ 4. ç³»ç»Ÿç‰¹è‰²:")
    print("   â€¢ å®Œå…¨AIé©±åŠ¨çš„å‰§æƒ…ç‚¹è¯†åˆ«")
    print("   â€¢ æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£")
    print("   â€¢ è·¨é›†è¿è´¯æ€§åˆ†æ")
    print("   â€¢ è‡ªåŠ¨ç”Ÿæˆç¬¬ä¸‰äººç§°æ—ç™½")
    print("   â€¢ ç”µå½±ç¬¬ä¸€äººç§°å™è¿°å‰ªè¾‘")
    print("   â€¢ æ— å£°è§†é¢‘é…éŸ³å‡†å¤‡")
    print("   â€¢ ç¼“å­˜æœºåˆ¶é¿å…é‡å¤åˆ†æ")
    print("=" * 60)
    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")

def check_system_status(clipper):
    """æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"""
    print("\nğŸ“Š ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
    print("=" * 50)
    
    # æ£€æŸ¥ç›®å½•
    dirs_status = []
    for folder in ['srt', 'videos', 'clips', 'analysis_cache']:
        exists = os.path.exists(folder)
        status = "âœ…" if exists else "âŒ"
        dirs_status.append(f"{status} {folder}/ ç›®å½•")
    
    print("ğŸ“ ç›®å½•çŠ¶æ€:")
    for status in dirs_status:
        print(f"   {status}")
    
    # æ£€æŸ¥æ–‡ä»¶
    srt_count = len([f for f in os.listdir('srt') if f.lower().endswith(('.srt', '.txt'))]) if os.path.exists('srt') else 0
    video_count = len([f for f in os.listdir('videos') if f.lower().endswith(('.mp4', '.mkv', '.avi', '.mov'))]) if os.path.exists('videos') else 0
    
    print(f"\nğŸ“„ æ–‡ä»¶ç»Ÿè®¡:")
    print(f"   ğŸ“ å­—å¹•æ–‡ä»¶: {srt_count} ä¸ª")
    print(f"   ğŸ¬ è§†é¢‘æ–‡ä»¶: {video_count} ä¸ª")
    
    # æ£€æŸ¥AIé…ç½®
    ai_status = "âœ… å·²é…ç½®" if clipper.ai_config.get('enabled') else "âŒ æœªé…ç½®"
    print(f"\nğŸ¤– AIçŠ¶æ€: {ai_status}")
    
    if clipper.ai_config.get('enabled'):
        print(f"   æä¾›å•†: {clipper.ai_config.get('provider', 'æœªçŸ¥')}")
        print(f"   æ¨¡å‹: {clipper.ai_config.get('model', 'æœªçŸ¥')}")
    
    # ç³»ç»Ÿå‡†å¤‡çŠ¶æ€
    ready = srt_count > 0 and video_count > 0 and clipper.ai_config.get('enabled')
    status = "âœ… å‡†å¤‡å°±ç»ª" if ready else "âŒ éœ€è¦é…ç½®"
    print(f"\nğŸ¯ ç³»ç»ŸçŠ¶æ€: {status}")
    
    if not ready:
        print("\nğŸ’¡ å»ºè®®æ“ä½œ:")
        if srt_count == 0:
            print("   â€¢ æ·»åŠ å­—å¹•æ–‡ä»¶åˆ° srt/ ç›®å½•")
        if video_count == 0:
            print("   â€¢ æ·»åŠ è§†é¢‘æ–‡ä»¶åˆ° videos/ ç›®å½•")
        if not clipper.ai_config.get('enabled'):
            print("   â€¢ é…ç½®AIæ¥å£ (é€‰æ‹©èœå•é€‰é¡¹3)")
    
    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")

def main():
    """ä¸»å‡½æ•° - å¼•å¯¼å¼èœå•ç³»ç»Ÿ"""
    clipper = CompleteIntelligentTVClipper()
    
    while True:
        try:
            show_main_menu()
            choice = input("è¯·è¾“å…¥é€‰æ‹© (1-6): ").strip()
            
            if choice == '1':
                # æ£€æŸ¥AIé…ç½®
                if not clipper.ai_config.get('enabled') or not clipper.ai_config.get('api_key'):
                    print("\nâŒ AIæœªé…ç½®ï¼Œæ— æ³•å¼€å§‹åˆ†æ")
                    print("ğŸ’¡ è¯·å…ˆé€‰æ‹©èœå•é€‰é¡¹4é…ç½®AI")
                    input("æŒ‰å›è½¦é”®ç»§ç»­...")
                    continue
                
                # æ£€æŸ¥æ–‡ä»¶
                if not os.path.exists('srt') or not os.listdir('srt'):
                    print("\nâŒ æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
                    print("ğŸ’¡ è¯·å°†å­—å¹•æ–‡ä»¶æ”¾å…¥ srt/ ç›®å½•")
                    input("æŒ‰å›è½¦é”®ç»§ç»­...")
                    continue
                
                print("\nğŸš€ å¼€å§‹ç”µè§†å‰§AIåˆ†æå’Œå‰ªè¾‘...")
                clipper.process_all_episodes()
                input("\nå¤„ç†å®Œæˆï¼ŒæŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                
            elif choice == '2':
                # ç”µå½±AIå‰ªè¾‘
                print("\nğŸ¬ å¯åŠ¨ç”µå½±AIåˆ†æå’Œå‰ªè¾‘ç³»ç»Ÿ...")
                movie_clipper = MovieAIClipper()
                if not movie_clipper.ai_config.get('enabled'):
                    print("âŒ AIæœªé…ç½®ï¼Œæ— æ³•è¿›è¡Œç”µå½±åˆ†æ")
                    print("ğŸ’¡ è¯·å…ˆé…ç½®AIæ¥å£")
                    input("æŒ‰å›è½¦é”®ç»§ç»­...")
                    continue
                
                # æ£€æŸ¥ç”µå½±å­—å¹•æ–‡ä»¶
                movie_srt_folder = "movie_srt"
                if not os.path.exists(movie_srt_folder) or not os.listdir(movie_srt_folder):
                    print(f"âŒ æœªæ‰¾åˆ°ç”µå½±å­—å¹•æ–‡ä»¶")
                    print(f"ğŸ’¡ è¯·å°†ç”µå½±å­—å¹•æ–‡ä»¶æ”¾å…¥ {movie_srt_folder}/ ç›®å½•")
                    input("æŒ‰å›è½¦é”®ç»§ç»­...")
                    continue
                
                # æ£€æŸ¥ç”µå½±è§†é¢‘æ–‡ä»¶
                movie_video_folder = "movie_videos"
                if not os.path.exists(movie_video_folder) or not os.listdir(movie_video_folder):
                    print(f"âŒ æœªæ‰¾åˆ°ç”µå½±è§†é¢‘æ–‡ä»¶")
                    print(f"ğŸ’¡ è¯·å°†ç”µå½±è§†é¢‘æ–‡ä»¶æ”¾å…¥ {movie_video_folder}/ ç›®å½•")
                    input("æŒ‰å›è½¦é”®ç»§ç»­...")
                    continue
                
                print("ğŸ¬ å¼€å§‹ç”µå½±AIåˆ†æå’Œå‰ªè¾‘...")
                print("ğŸ“‹ ç‰¹è‰²åŠŸèƒ½:")
                print("  â€¢ æ— å£°è§†é¢‘å‰ªè¾‘ï¼Œä¸“ä¸ºç¬¬ä¸€äººç§°å™è¿°è®¾è®¡")
                print("  â€¢ æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£ (é˜²è¡›â†’é˜²å«, æ­£ç•¶â†’æ­£å½“)")
                print("  â€¢ ç¬¬ä¸€äººç§°å™è¿°ä¸è§†é¢‘å†…å®¹å®æ—¶åŒæ­¥")
                
                movie_clipper.process_all_movies()
                input("\nç”µå½±å¤„ç†å®Œæˆï¼ŒæŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                
            elif choice == '3':
                clipper.test_current_connection()
                
            elif choice == '4':
                clipper.configure_ai_interactive()
                
            elif choice == '5':
                check_system_status(clipper)
                
            elif choice == '6':
                show_tutorial()
                
            elif choice == '7':
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨AIæ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿï¼")
                break
                
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-7")
                input("æŒ‰å›è½¦é”®ç»§ç»­...")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œç³»ç»Ÿé€€å‡º")
            break
        except Exception as e:
            print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
            input("æŒ‰å›è½¦é”®ç»§ç»­...")

if __name__ == "__main__":
    main()