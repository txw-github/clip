
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œæ•´æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ - ç¨³å®šç‰ˆæœ¬
æ”¯æŒå¤šå‰§æƒ…ç±»å‹ã€å‰§æƒ…ç‚¹åˆ†æã€è·¨é›†è¿è´¯æ€§ã€ç¬¬ä¸‰äººç§°æ—ç™½ç”Ÿæˆ
å…³é”®æ”¹è¿›ï¼š
10. å‰ªè¾‘æ—¶ä¿è¯ä¸€å¥è¯è®²å®Œ
11. APIåˆ†æç»“æœç¼“å­˜ï¼Œé¿å…é‡å¤è°ƒç”¨
12. å‰ªè¾‘ç»“æœä¸€è‡´æ€§ä¿è¯
13. æ–­ç‚¹ç»­ä¼ ï¼Œå·²å‰ªè¾‘å¥½çš„ä¸é‡å¤å¤„ç†
14. å¤šæ¬¡æ‰§è¡Œç»“æœä¸€è‡´æ€§
15. æ‰¹é‡å¤„ç†æ‰€æœ‰srtæ–‡ä»¶
"""

import os
import re
import json
import hashlib
import subprocess
import sys
from typing import List, Dict, Optional, Tuple
from datetime import datetime

class StableTVClipper:
    """ç¨³å®šçš„æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ"""

    def __init__(self):
        # æ ‡å‡†ç›®å½•ç»“æ„
        self.srt_folder = "srt"
        self.videos_folder = "videos"
        self.clips_folder = "clips"
        self.cache_folder = "cache"
        self.reports_folder = "reports"

        # åˆ›å»ºå¿…è¦ç›®å½•
        for folder in [self.srt_folder, self.videos_folder, self.clips_folder, 
                      self.cache_folder, self.reports_folder]:
            os.makedirs(folder, exist_ok=True)

        # å‰§æƒ…ç‚¹åˆ†ç±»å®šä¹‰
        self.plot_point_types = {
            'å…³é”®å†²çª': {
                'keywords': ['å†²çª', 'äº‰æ‰§', 'å¯¹æŠ—', 'è´¨ç–‘', 'åé©³', 'äº‰è®®', 'æ¿€çƒˆ', 'æ„¤æ€’', 'ä¸åŒæ„', 'çŸ›ç›¾'],
                'weight': 10,
                'ideal_duration': 180
            },
            'äººç‰©è½¬æŠ˜': {
                'keywords': ['å†³å®š', 'æ”¹å˜', 'é€‰æ‹©', 'è½¬å˜', 'è§‰æ‚Ÿ', 'æ˜ç™½', 'æ„è¯†åˆ°', 'å‘ç°è‡ªå·±', 'æˆé•¿'],
                'weight': 9,
                'ideal_duration': 150
            },
            'çº¿ç´¢æ­éœ²': {
                'keywords': ['å‘ç°', 'æ­éœ²', 'çœŸç›¸', 'è¯æ®', 'çº¿ç´¢', 'ç§˜å¯†', 'æš´éœ²', 'è¯æ˜', 'æ‰¾åˆ°', 'æ›å…‰'],
                'weight': 8,
                'ideal_duration': 160
            },
            'æƒ…æ„Ÿçˆ†å‘': {
                'keywords': ['å“­', 'ç—›è‹¦', 'ç»æœ›', 'æ„¤æ€’', 'æ¿€åŠ¨', 'å´©æºƒ', 'å¿ƒç—›', 'æ„ŸåŠ¨', 'éœ‡æ’¼', 'æ³ªæ°´'],
                'weight': 7,
                'ideal_duration': 140
            },
            'é‡è¦å¯¹è¯': {
                'keywords': ['å‘Šè¯‰', 'æ‰¿è®¤', 'å¦ç™½', 'è§£é‡Š', 'æ¾„æ¸…', 'è¯´æ˜', 'è¡¨æ€', 'ä¿è¯', 'æ‰¿è¯º'],
                'weight': 6,
                'ideal_duration': 170
            }
        }

        # å‰§æƒ…ç±»å‹è¯†åˆ«
        self.genre_patterns = {
            'æ³•å¾‹å‰§': {
                'keywords': ['æ³•å®˜', 'æ£€å¯Ÿå®˜', 'å¾‹å¸ˆ', 'æ³•åº­', 'å®¡åˆ¤', 'è¯æ®', 'æ¡ˆä»¶', 'èµ·è¯‰', 'è¾©æŠ¤', 'åˆ¤å†³', 'ç”³è¯‰', 'å¬è¯ä¼š'],
                'weight': 1.0
            },
            'çˆ±æƒ…å‰§': {
                'keywords': ['çˆ±æƒ…', 'å–œæ¬¢', 'å¿ƒåŠ¨', 'è¡¨ç™½', 'çº¦ä¼š', 'åˆ†æ‰‹', 'å¤åˆ', 'ç»“å©š', 'æƒ…ä¾£', 'æ‹äºº'],
                'weight': 1.0
            },
            'æ‚¬ç–‘å‰§': {
                'keywords': ['çœŸç›¸', 'ç§˜å¯†', 'è°ƒæŸ¥', 'çº¿ç´¢', 'ç ´æ¡ˆ', 'å‡¶æ‰‹', 'ç¥ç§˜', 'éšç’'],
                'weight': 1.0
            },
            'å®¶åº­å‰§': {
                'keywords': ['å®¶åº­', 'çˆ¶æ¯', 'å­©å­', 'å…„å¼Ÿ', 'å§å¦¹', 'äº²æƒ…', 'å®¶äºº', 'å›¢èš'],
                'weight': 1.0
            }
        }

        # é”™åˆ«å­—ä¿®æ­£åº“
        self.corrections = {
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'å¯©åˆ¤': 'å®¡åˆ¤', 'è¾¯è­·': 'è¾©æŠ¤', 'èµ·è¨´': 'èµ·è¯‰', 'èª¿æŸ¥': 'è°ƒæŸ¥',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'è½è­‰æœƒ': 'å¬è¯ä¼š',
            'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'é–‹å§‹': 'å¼€å§‹', 'çµæŸ': 'ç»“æŸ'
        }

        # æ£€æµ‹åˆ°çš„å‰§æƒ…ç±»å‹
        self.detected_genre = None
        self.genre_confidence = 0.0

        print("ğŸš€ ç¨³å®šç‰ˆæ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿå·²å¯åŠ¨")
        print(f"ğŸ“ å­—å¹•ç›®å½•: {self.srt_folder}/")
        print(f"ğŸ¬ è§†é¢‘ç›®å½•: {self.videos_folder}/")
        print(f"ğŸ“¤ è¾“å‡ºç›®å½•: {self.clips_folder}/")
        print(f"ğŸ’¾ ç¼“å­˜ç›®å½•: {self.cache_folder}/")

    def get_file_hash(self, filepath: str) -> str:
        """è·å–æ–‡ä»¶å†…å®¹çš„MD5å“ˆå¸Œå€¼"""
        try:
            with open(filepath, 'rb') as f:
                content = f.read()
                return hashlib.md5(content).hexdigest()[:12]
        except:
            return hashlib.md5(filepath.encode()).hexdigest()[:12]

    def get_analysis_cache_path(self, srt_file: str) -> str:
        """è·å–åˆ†æç»“æœç¼“å­˜è·¯å¾„"""
        file_hash = self.get_file_hash(os.path.join(self.srt_folder, srt_file))
        episode_num = self.extract_episode_number(srt_file)
        return os.path.join(self.cache_folder, f"analysis_E{episode_num}_{file_hash}.json")

    def save_analysis_cache(self, srt_file: str, analysis_result: Dict):
        """ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜"""
        cache_path = self.get_analysis_cache_path(srt_file)
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ åˆ†æç»“æœå·²ç¼“å­˜: {os.path.basename(cache_path)}")
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

    def load_analysis_cache(self, srt_file: str) -> Optional[Dict]:
        """ä»ç¼“å­˜åŠ è½½åˆ†æç»“æœ"""
        cache_path = self.get_analysis_cache_path(srt_file)
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    result = json.load(f)
                print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜çš„åˆ†æç»“æœ: {os.path.basename(cache_path)}")
                return result
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")
                return None
        return None

    def get_clip_status_path(self, srt_file: str) -> str:
        """è·å–å‰ªè¾‘çŠ¶æ€æ–‡ä»¶è·¯å¾„"""
        file_hash = self.get_file_hash(os.path.join(self.srt_folder, srt_file))
        episode_num = self.extract_episode_number(srt_file)
        return os.path.join(self.cache_folder, f"clip_status_E{episode_num}_{file_hash}.json")

    def save_clip_status(self, srt_file: str, clip_status: Dict):
        """ä¿å­˜å‰ªè¾‘çŠ¶æ€"""
        status_path = self.get_clip_status_path(srt_file)
        try:
            with open(status_path, 'w', encoding='utf-8') as f:
                json.dump(clip_status, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ å‰ªè¾‘çŠ¶æ€ä¿å­˜å¤±è´¥: {e}")

    def load_clip_status(self, srt_file: str) -> Dict:
        """åŠ è½½å‰ªè¾‘çŠ¶æ€"""
        status_path = self.get_clip_status_path(srt_file)
        if os.path.exists(status_path):
            try:
                with open(status_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ å‰ªè¾‘çŠ¶æ€è¯»å–å¤±è´¥: {e}")
        return {}

    def parse_srt_file(self, filepath: str) -> List[Dict]:
        """è§£æSRTå­—å¹•æ–‡ä»¶å¹¶ä¿®æ­£é”™åˆ«å­—"""
        print(f"ğŸ“– è§£æå­—å¹•: {os.path.basename(filepath)}")

        # å°è¯•å¤šç§ç¼–ç 
        content = None
        for encoding in ['utf-8', 'gbk', 'utf-16', 'gb2312']:
            try:
                with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                    content = f.read()
                    break
            except:
                continue

        if not content:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {filepath}")
            return []

        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£
        for old, new in self.corrections.items():
            content = content.replace(old, new)

        # è§£æå­—å¹•æ¡ç›®
        subtitles = []
        blocks = re.split(r'\n\s*\n', content.strip())

        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                try:
                    index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1

                    # åŒ¹é…æ—¶é—´æ ¼å¼
                    time_pattern = r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})'
                    time_match = re.search(time_pattern, lines[1])

                    if time_match:
                        start_time = time_match.group(1).replace('.', ',')
                        end_time = time_match.group(2).replace('.', ',')
                        text = '\n'.join(lines[2:]).strip()

                        if text:
                            subtitles.append({
                                'index': index,
                                'start': start_time,
                                'end': end_time,
                                'text': text
                            })
                except (ValueError, IndexError):
                    continue

        print(f"âœ… è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return subtitles

    def detect_genre(self, subtitles: List[Dict]) -> str:
        """æ™ºèƒ½è¯†åˆ«å‰§æƒ…ç±»å‹"""
        if len(subtitles) < 50:
            return 'é€šç”¨å‰§'

        # åˆ†æå‰200æ¡å­—å¹•
        sample_text = " ".join([sub['text'] for sub in subtitles[:200]])

        genre_scores = {}
        for genre, pattern in self.genre_patterns.items():
            score = 0
            for keyword in pattern['keywords']:
                score += sample_text.count(keyword) * pattern['weight']
            genre_scores[genre] = score

        if genre_scores:
            best_genre = max(genre_scores, key=genre_scores.get)
            max_score = genre_scores[best_genre]

            if max_score >= 3:
                self.detected_genre = best_genre
                self.genre_confidence = min(max_score / 20, 1.0)
                print(f"ğŸ­ æ£€æµ‹åˆ°å‰§æƒ…ç±»å‹: {best_genre} (ç½®ä¿¡åº¦: {self.genre_confidence:.2f})")
                return best_genre

        self.detected_genre = 'é€šç”¨å‰§'
        self.genre_confidence = 0.5
        return 'é€šç”¨å‰§'

    def analyze_plot_points(self, subtitles: List[Dict], episode_num: str) -> List[Dict]:
        """åˆ†æå‰§æƒ…ç‚¹å¹¶è¿”å›å¤šä¸ªé‡è¦ç‰‡æ®µ"""
        if not subtitles:
            return []

        # æ£€æµ‹å‰§æƒ…ç±»å‹
        if self.detected_genre is None:
            self.detect_genre(subtitles)

        plot_points = []
        window_size = 20  # åˆ†æçª—å£å¤§å°

        # æ»‘åŠ¨çª—å£åˆ†æ
        for i in range(0, len(subtitles) - window_size, 10):
            window_subtitles = subtitles[i:i + window_size]
            combined_text = ' '.join([sub['text'] for sub in window_subtitles])

            # è®¡ç®—å„ç±»å‰§æƒ…ç‚¹å¾—åˆ†
            plot_scores = {}
            for plot_type, config in self.plot_point_types.items():
                score = 0

                # å…³é”®è¯åŒ¹é…
                for keyword in config['keywords']:
                    score += combined_text.count(keyword) * config['weight']

                # å‰§æƒ…ç±»å‹åŠ æƒ
                if self.detected_genre in self.genre_patterns:
                    genre_keywords = self.genre_patterns[self.detected_genre]['keywords']
                    for keyword in genre_keywords:
                        if keyword in combined_text:
                            score += 5

                # æ ‡ç‚¹ç¬¦å·å¼ºåº¦
                score += combined_text.count('ï¼') * 2
                score += combined_text.count('ï¼Ÿ') * 1.5
                score += combined_text.count('...') * 1

                plot_scores[plot_type] = score

            # æ‰¾åˆ°æœ€é«˜åˆ†çš„å‰§æƒ…ç‚¹ç±»å‹
            best_plot_type = max(plot_scores, key=plot_scores.get)
            best_score = plot_scores[best_plot_type]

            if best_score >= 12:  # åŠ¨æ€é˜ˆå€¼
                plot_points.append({
                    'start_index': i,
                    'end_index': i + window_size - 1,
                    'plot_type': best_plot_type,
                    'score': best_score,
                    'content': combined_text,
                    'position_ratio': i / len(subtitles)
                })

        # å»é‡å’Œä¼˜åŒ–
        plot_points = self._deduplicate_plot_points(plot_points)

        # é€‰æ‹©æœ€ä½³å‰§æƒ…ç‚¹ï¼ˆæ¯é›†2-4ä¸ªï¼‰
        plot_points.sort(key=lambda x: x['score'], reverse=True)
        selected_points = plot_points[:4]

        # æŒ‰æ—¶é—´é¡ºåºæ’åº
        selected_points.sort(key=lambda x: x['start_index'])

        # ä¼˜åŒ–å‰§æƒ…ç‚¹ç‰‡æ®µï¼ˆé‡ç‚¹ï¼šä¿è¯ä¸€å¥è¯è®²å®Œï¼‰
        optimized_points = []
        for point in selected_points:
            optimized_point = self._optimize_plot_point_complete_sentence(subtitles, point, episode_num)
            if optimized_point:
                optimized_points.append(optimized_point)

        return optimized_points

    def _optimize_plot_point_complete_sentence(self, subtitles: List[Dict], plot_point: Dict, episode_num: str) -> Optional[Dict]:
        """ä¼˜åŒ–å‰§æƒ…ç‚¹ç‰‡æ®µï¼Œç¡®ä¿åœ¨å®Œæ•´å¥å­å¤„ç»“æŸ"""
        plot_type = plot_point['plot_type']
        target_duration = self.plot_point_types[plot_type]['ideal_duration']

        start_idx = plot_point['start_index']
        end_idx = plot_point['end_index']

        # æ‰©å±•åˆ°ç›®æ ‡æ—¶é•¿
        current_duration = self._calculate_duration(subtitles, start_idx, end_idx)

        # å‘å‰åæ‰©å±•
        while current_duration < target_duration and (start_idx > 0 or end_idx < len(subtitles) - 1):
            if end_idx < len(subtitles) - 1:
                end_idx += 1
                current_duration = self._calculate_duration(subtitles, start_idx, end_idx)

            if current_duration < target_duration and start_idx > 0:
                start_idx -= 1
                current_duration = self._calculate_duration(subtitles, start_idx, end_idx)

            if current_duration >= target_duration * 1.2:
                break

        # é‡ç‚¹ï¼šå¯»æ‰¾å®Œæ•´å¥å­è¾¹ç•Œ
        start_idx = self._find_sentence_start(subtitles, start_idx, plot_point['start_index'])
        end_idx = self._find_sentence_end(subtitles, plot_point['end_index'], end_idx)

        # ç”Ÿæˆç‰‡æ®µä¿¡æ¯
        final_duration = self._calculate_duration(subtitles, start_idx, end_idx)
        start_time = subtitles[start_idx]['start']
        end_time = subtitles[end_idx]['end']

        return {
            'episode_number': episode_num,
            'plot_type': plot_type,
            'title': self._generate_plot_title(subtitles, start_idx, end_idx, plot_type, episode_num),
            'start_time': start_time,
            'end_time': end_time,
            'duration': final_duration,
            'start_index': start_idx,
            'end_index': end_idx,
            'score': plot_point['score'],
            'key_dialogues': self._extract_key_dialogues(subtitles, start_idx, end_idx),
            'plot_significance': self._analyze_plot_significance(subtitles, start_idx, end_idx, plot_type),
            'content_summary': self._generate_content_summary(subtitles, start_idx, end_idx),
            'third_person_narration': self._generate_third_person_narration(subtitles, start_idx, end_idx, plot_type),
            'content_highlights': self._extract_content_highlights(subtitles, start_idx, end_idx),
            'genre': self.detected_genre
        }

    def _find_sentence_start(self, subtitles: List[Dict], search_start: int, anchor: int) -> int:
        """å¯»æ‰¾å®Œæ•´å¥å­çš„å¼€å§‹ç‚¹"""
        sentence_starters = ['é‚£ä¹ˆ', 'ç°åœ¨', 'è¿™æ—¶', 'çªç„¶', 'æ¥ä¸‹æ¥', 'é¦–å…ˆ', 'ç„¶å', 'äºæ˜¯', 'éšç€', 'åˆšæ‰', 'ä½†æ˜¯', 'ä¸è¿‡', 'å› ä¸º', 'æ‰€ä»¥']
        
        for i in range(anchor, max(0, search_start - 10), -1):
            if i < len(subtitles):
                text = subtitles[i]['text']
                
                # å¯»æ‰¾å¥å­å¼€å§‹æ ‡å¿—
                if any(starter in text[:10] for starter in sentence_starters):
                    return i
                
                # å¯»æ‰¾ä¸Šä¸€å¥çš„ç»“æŸç‚¹
                if i > 0 and any(subtitles[i-1]['text'].endswith(end) for end in ['ã€‚', 'ï¼', 'ï¼Ÿ', '...', 'â€”â€”']):
                    return i
                
                # é¿å…åœ¨å¯¹è¯ä¸­é—´æˆªæ–­
                if text.startswith('"') or text.startswith('"'):
                    return i

        return search_start

    def _find_sentence_end(self, subtitles: List[Dict], anchor: int, search_end: int) -> int:
        """å¯»æ‰¾å®Œæ•´å¥å­çš„ç»“æŸç‚¹"""
        sentence_enders = ['ã€‚', 'ï¼', 'ï¼Ÿ', '...', 'â€”â€”', '"', '"']
        
        for i in range(anchor, min(len(subtitles), search_end + 10)):
            if i < len(subtitles):
                text = subtitles[i]['text']
                
                # å¯»æ‰¾å¥å­ç»“æŸæ ‡å¿—
                if any(text.endswith(ender) for ender in sentence_enders):
                    return i
                
                # é¿å…åœ¨é‡è¦è¯æ±‡ä¸­é—´æˆªæ–­
                important_words = ['ä½†æ˜¯', 'ä¸è¿‡', 'ç„¶è€Œ', 'å› æ­¤', 'æ‰€ä»¥', 'å¦‚æœ', 'è™½ç„¶', 'å°½ç®¡']
                if i < len(subtitles) - 1:
                    next_text = subtitles[i + 1]['text']
                    if any(next_text.startswith(word) for word in important_words):
                        continue
                
                # è¶…è¿‡æœ€å°é•¿åº¦åå¯»æ‰¾è‡ªç„¶åœé¡¿ç‚¹
                if i > anchor + 15 and text.endswith('ï¼Œ'):
                    return i

        return min(search_end, len(subtitles) - 1)

    def _deduplicate_plot_points(self, plot_points: List[Dict]) -> List[Dict]:
        """å»é™¤é‡å çš„å‰§æƒ…ç‚¹"""
        if not plot_points:
            return []

        plot_points.sort(key=lambda x: x['start_index'])
        deduplicated = [plot_points[0]]

        for point in plot_points[1:]:
            last_point = deduplicated[-1]
            overlap = (point['start_index'] <= last_point['end_index'])

            if overlap:
                if point['score'] > last_point['score']:
                    deduplicated[-1] = point
            else:
                gap = point['start_index'] - last_point['end_index']
                if gap >= 30:  # è‡³å°‘é—´éš”30ä¸ªå­—å¹•æ¡
                    deduplicated.append(point)

        return deduplicated

    def _calculate_duration(self, subtitles: List[Dict], start_idx: int, end_idx: int) -> float:
        """è®¡ç®—å­—å¹•ç‰‡æ®µçš„æ—¶é•¿"""
        if start_idx >= len(subtitles) or end_idx >= len(subtitles):
            return 0

        start_seconds = self.time_to_seconds(subtitles[start_idx]['start'])
        end_seconds = self.time_to_seconds(subtitles[end_idx]['end'])
        return end_seconds - start_seconds

    def _generate_plot_title(self, subtitles: List[Dict], start_idx: int, end_idx: int, plot_type: str, episode_num: str) -> str:
        """ç”Ÿæˆå‰§æƒ…ç‚¹æ ‡é¢˜"""
        content = ' '.join([subtitles[i]['text'] for i in range(start_idx, min(end_idx + 1, start_idx + 10))])

        # æ ¹æ®å‰§æƒ…ç±»å‹å’Œå‰§æƒ…ç‚¹ç±»å‹ç”Ÿæˆæ ‡é¢˜
        if self.detected_genre == 'æ³•å¾‹å‰§':
            if plot_type == 'å…³é”®å†²çª':
                return f"E{episode_num}-æ³•åº­æ¿€è¾©ï¼š{plot_type}å…³é”®æ—¶åˆ»"
            elif plot_type == 'çº¿ç´¢æ­éœ²':
                return f"E{episode_num}-è¯æ®æŠ«éœ²ï¼š{plot_type}éœ‡æ’¼æ—¶åˆ»"
            else:
                return f"E{episode_num}-æ³•å¾‹çº è‘›ï¼š{plot_type}æ ¸å¿ƒç‰‡æ®µ"

        elif self.detected_genre == 'çˆ±æƒ…å‰§':
            if plot_type == 'æƒ…æ„Ÿçˆ†å‘':
                return f"E{episode_num}-æƒ…æ„Ÿé«˜æ½®ï¼š{plot_type}æ„Ÿäººç¬é—´"
            elif plot_type == 'äººç‰©è½¬æŠ˜':
                return f"E{episode_num}-çˆ±æƒ…è½¬æŠ˜ï¼š{plot_type}å…³é”®å†³å®š"
            else:
                return f"E{episode_num}-çˆ±æƒ…æ•…äº‹ï¼š{plot_type}ç²¾å½©ç‰‡æ®µ"

        else:
            return f"E{episode_num}-{plot_type}ï¼šå‰§æƒ…æ ¸å¿ƒæ—¶åˆ»"

    def _extract_key_dialogues(self, subtitles: List[Dict], start_idx: int, end_idx: int) -> List[str]:
        """æå–å…³é”®å°è¯"""
        key_dialogues = []

        for i in range(start_idx, min(end_idx + 1, start_idx + 25)):
            if i >= len(subtitles):
                break

            subtitle = subtitles[i]
            text = subtitle['text']

            # è¯„ä¼°å°è¯é‡è¦æ€§
            importance = 0

            # æƒ…æ„Ÿå¼ºåº¦
            importance += text.count('ï¼') * 2
            importance += text.count('ï¼Ÿ') * 1.5

            # æˆå‰§æ€§è¯æ±‡
            dramatic_words = ['ä¸å¯èƒ½', 'éœ‡æƒŠ', 'çœŸç›¸', 'è¯æ˜', 'æ¨ç¿»', 'å‘ç°', 'æ„å¤–', 'åŸæ¥']
            for word in dramatic_words:
                if word in text:
                    importance += 2

            # å‰§æƒ…ç±»å‹ç›¸å…³è¯æ±‡
            if self.detected_genre in self.genre_patterns:
                genre_keywords = self.genre_patterns[self.detected_genre]['keywords']
                for keyword in genre_keywords:
                    if keyword in text:
                        importance += 3

            if importance >= 4 and len(text) > 8:
                time_code = f"{subtitle['start']} --> {subtitle['end']}"
                key_dialogues.append(f"[{time_code}] {text}")

        return key_dialogues[:6]

    def _analyze_plot_significance(self, subtitles: List[Dict], start_idx: int, end_idx: int, plot_type: str) -> str:
        """åˆ†æå‰§æƒ…ç‚¹æ„ä¹‰"""
        content = ' '.join([subtitles[i]['text'] for i in range(start_idx, end_idx + 1)])
        significance_parts = []

        # åŸºäºå‰§æƒ…ç‚¹ç±»å‹åˆ†æ
        if plot_type == 'å…³é”®å†²çª':
            if 'äº‰è®®' in content or 'å¯¹æŠ—' in content:
                significance_parts.append("æ ¸å¿ƒçŸ›ç›¾å†²çªçˆ†å‘")
            if 'æ³•åº­' in content or 'å®¡åˆ¤' in content:
                significance_parts.append("æ³•åº­æ¿€è¾©å…³é”®äº¤é”‹")

        elif plot_type == 'äººç‰©è½¬æŠ˜':
            if 'å†³å®š' in content or 'é€‰æ‹©' in content:
                significance_parts.append("è§’è‰²å…³é”®å†³å®šæ—¶åˆ»")
            if 'æ”¹å˜' in content or 'è§‰æ‚Ÿ' in content:
                significance_parts.append("äººç‰©å‘½è¿è½¬æŠ˜ç‚¹")

        elif plot_type == 'çº¿ç´¢æ­éœ²':
            if 'å‘ç°' in content or 'çœŸç›¸' in content:
                significance_parts.append("é‡è¦çœŸç›¸æŠ«éœ²")
            if 'è¯æ®' in content or 'çº¿ç´¢' in content:
                significance_parts.append("å…³é”®è¯æ®æ­éœ²")

        elif plot_type == 'æƒ…æ„Ÿçˆ†å‘':
            significance_parts.append("æƒ…æ„Ÿå†²å‡»é«˜æ½®æ—¶åˆ»")

        elif plot_type == 'é‡è¦å¯¹è¯':
            significance_parts.append("å…³é”®ä¿¡æ¯äº¤æµæ—¶åˆ»")

        # é€šç”¨åˆ†æ
        if 'çœŸç›¸' in content:
            significance_parts.append("æ¡ˆä»¶çœŸç›¸é‡è¦æŠ«éœ²")
        if 'å†²çª' in content:
            significance_parts.append("å‰§æƒ…å†²çªæ¿€åŒ–")

        return "ï¼›".join(significance_parts) if significance_parts else f"{plot_type}é‡è¦å‰§æƒ…å‘å±•èŠ‚ç‚¹"

    def _generate_content_summary(self, subtitles: List[Dict], start_idx: int, end_idx: int) -> str:
        """ç”Ÿæˆå†…å®¹æ‘˜è¦"""
        content = ' '.join([subtitles[i]['text'] for i in range(start_idx, min(end_idx + 1, start_idx + 20))])

        # æå–å…³é”®ä¿¡æ¯
        key_elements = []

        # æ ¹æ®å‰§æƒ…ç±»å‹æå–å…³é”®å…ƒç´ 
        if self.detected_genre == 'æ³•å¾‹å‰§':
            legal_elements = ['æ¡ˆä»¶', 'è¯æ®', 'æ³•åº­', 'å®¡åˆ¤', 'å¾‹å¸ˆ', 'æ£€å¯Ÿå®˜', 'åˆ¤å†³']
            for element in legal_elements:
                if element in content:
                    key_elements.append(element)

        elif self.detected_genre == 'çˆ±æƒ…å‰§':
            romance_elements = ['çˆ±æƒ…', 'è¡¨ç™½', 'çº¦ä¼š', 'åˆ†æ‰‹', 'ç»“å©š', 'æƒ…ä¾£']
            for element in romance_elements:
                if element in content:
                    key_elements.append(element)

        # é€šç”¨é‡è¦å…ƒç´ 
        general_elements = ['çœŸç›¸', 'ç§˜å¯†', 'å‘ç°', 'å†³å®š', 'æ”¹å˜', 'å†²çª']
        for element in general_elements:
            if element in content and element not in key_elements:
                key_elements.append(element)

        elements_str = "ã€".join(key_elements[:5]) if key_elements else "æ ¸å¿ƒå‰§æƒ…"
        return f"{elements_str}çš„é‡è¦å‘å±•ï¼Œ{content[:50]}..."

    def _generate_third_person_narration(self, subtitles: List[Dict], start_idx: int, end_idx: int, plot_type: str) -> str:
        """ç”Ÿæˆç¬¬ä¸‰äººç§°æ—ç™½å­—å¹•"""
        content = ' '.join([subtitles[i]['text'] for i in range(start_idx, end_idx + 1)])

        # åŸºäºå‰§æƒ…ç‚¹ç±»å‹ç”Ÿæˆç¬¬ä¸‰äººç§°æ—ç™½
        if plot_type == 'å…³é”®å†²çª':
            if 'æ³•åº­' in content or 'å®¡åˆ¤' in content:
                return "æ­¤æ—¶æ³•åº­ä¸ŠåŒæ–¹å±•å¼€æ¿€çƒˆè¾©è®ºï¼Œå„è‡ªåšæŒå·±è§ï¼Œäº‰è®®ç„¦ç‚¹é€æ¸æ˜æœ—ã€‚å…³é”®è¯æ®çš„æ•ˆåŠ›æˆä¸ºäº‰è®®æ ¸å¿ƒï¼Œæ¯ä¸€ä¸ªç»†èŠ‚éƒ½å¯èƒ½å½±å“æœ€ç»ˆåˆ¤å†³ã€‚"
            elif 'äº‰è®®' in content or 'å†²çª' in content:
                return "çŸ›ç›¾åœ¨æ­¤åˆ»è¾¾åˆ°ç™½çƒ­åŒ–é˜¶æ®µï¼ŒåŒæ–¹ç«‹åœºæˆªç„¶å¯¹ç«‹ã€‚è¿™åœºå†²çªä¸ä»…æ˜¯è§‚ç‚¹çš„ç¢°æ’ï¼Œæ›´æ˜¯ä»·å€¼è§‚å¿µçš„è¾ƒé‡ï¼Œå°†å¯¹åç»­å‘å±•äº§ç”Ÿæ·±è¿œå½±å“ã€‚"
            else:
                return "å…³é”®æ—¶åˆ»åˆ°æ¥ï¼Œå„æ–¹åŠ›é‡å¼€å§‹æ­£é¢äº¤é”‹ã€‚è¿™åœºå†²çªçš„ç»“æœå°†å†³å®šæ•…äº‹çš„èµ°å‘ï¼Œæ¯ä¸ªäººéƒ½é¢ä¸´ç€é‡è¦çš„é€‰æ‹©ã€‚"

        elif plot_type == 'äººç‰©è½¬æŠ˜':
            if 'å†³å®š' in content or 'é€‰æ‹©' in content:
                return "åœ¨ç»å†äº†å†…å¿ƒçš„æŒ£æ‰åï¼Œä¸»äººå…¬ç»ˆäºåšå‡ºäº†å…³é”®å†³å®šã€‚è¿™ä¸ªé€‰æ‹©å°†æ”¹å˜ä»–ä»¬çš„äººç”Ÿè½¨è¿¹ï¼Œä¹Ÿä¸ºæ•…äº‹å¸¦æ¥æ–°çš„è½¬æœºã€‚"
            elif 'è§‰æ‚Ÿ' in content or 'æ˜ç™½' in content:
                return "åœ¨è¿™ä¸ªé‡è¦æ—¶åˆ»ï¼Œè§’è‰²å†…å¿ƒå‘ç”Ÿäº†æ·±åˆ»å˜åŒ–ã€‚è¿‡å¾€çš„ç»å†è®©ä»–ä»¬è·å¾—äº†æ–°çš„è®¤çŸ¥ï¼Œè¿™ç§è§‰æ‚Ÿå°†æŒ‡å¼•ä»–ä»¬èµ°å‘ä¸åŒçš„é“è·¯ã€‚"
            else:
                return "äººç‰©è¿æ¥é‡è¦çš„è½¬æŠ˜ç‚¹ï¼Œè¿‡å»çš„ç»å†å’Œå½“å‰çš„å¤„å¢ƒä¿ƒä½¿ä»–ä»¬é‡æ–°å®¡è§†è‡ªå·±çš„é€‰æ‹©ï¼Œä¸€ä¸ªæ–°çš„äººç”Ÿé˜¶æ®µå³å°†å¼€å§‹ã€‚"

        elif plot_type == 'çº¿ç´¢æ­éœ²':
            if 'çœŸç›¸' in content or 'å‘ç°' in content:
                return "éšè—å·²ä¹…çš„çœŸç›¸ç»ˆäºæµ®å‡ºæ°´é¢ï¼Œè¿™ä¸ªå‘ç°éœ‡æ’¼äº†æ‰€æœ‰äººã€‚äº‹æƒ…çš„çœŸå®é¢è²Œè¿œæ¯”æƒ³è±¡çš„å¤æ‚ï¼Œä¸ºæ¡ˆä»¶è°ƒæŸ¥å¼€è¾Ÿäº†æ–°çš„æ–¹å‘ã€‚"
            elif 'è¯æ®' in content or 'çº¿ç´¢' in content:
                return "å…³é”®è¯æ®çš„å‡ºç°ä¸ºæ¡ˆä»¶å¸¦æ¥äº†çªç ´æ€§è¿›å±•ã€‚è¿™äº›æ–°å‘ç°çš„çº¿ç´¢ä¸²è”èµ·äº†æ•´ä¸ªäº‹ä»¶çš„è„‰ç»œï¼ŒçœŸç›¸è·ç¦»æ­éœ²åˆè¿‘äº†ä¸€æ­¥ã€‚"
            else:
                return "é‡è¦ä¿¡æ¯åœ¨æ­¤æ—¶è¢«æŠ«éœ²ï¼Œè¿™ä¸ªå‘ç°æ”¹å˜äº†æ‰€æœ‰äººå¯¹äº‹ä»¶çš„è®¤çŸ¥ã€‚æ–°çš„çº¿ç´¢æŒ‡å‘äº†æ„æƒ³ä¸åˆ°çš„æ–¹å‘ï¼Œæ¡ˆä»¶è°ƒæŸ¥è¿æ¥è½¬æœºã€‚"

        elif plot_type == 'æƒ…æ„Ÿçˆ†å‘':
            return "æƒ…æ„Ÿåœ¨æ­¤åˆ»è¾¾åˆ°äº†ä¸´ç•Œç‚¹ï¼Œå†…å¿ƒçš„å‹æŠ‘å’Œç—›è‹¦å†ä¹Ÿæ— æ³•æ©é¥°ã€‚è¿™ç§çœŸå®çš„æƒ…æ„Ÿè¡¨è¾¾è§¦åŠ¨äººå¿ƒï¼Œè®©è§‚ä¼—æ·±æ·±æ„Ÿå—åˆ°è§’è‰²çš„å†…å¿ƒä¸–ç•Œã€‚"

        elif plot_type == 'é‡è¦å¯¹è¯':
            return "è¿™åœºå…³é”®å¯¹è¯æ‰¿è½½ç€é‡è¦ä¿¡æ¯çš„ä¼ é€’ï¼Œæ¯ä¸€å¥è¯éƒ½æ„ä¹‰æ·±è¿œã€‚é€šè¿‡è¿™æ¬¡äº¤æµï¼Œéšè—çš„ç§˜å¯†è¢«æ­å¼€ï¼Œäººç‰©å…³ç³»ä¹Ÿå‘ç”Ÿäº†å¾®å¦™å˜åŒ–ã€‚"

        else:
            return f"åœ¨è¿™ä¸ª{plot_type}çš„é‡è¦æ—¶åˆ»ï¼Œå‰§æƒ…è¿æ¥å…³é”®å‘å±•ã€‚è§’è‰²é¢ä¸´é‡è¦é€‰æ‹©ï¼Œæ¯ä¸ªå†³å®šéƒ½å°†å½±å“æ•…äº‹çš„èµ°å‘ã€‚"

    def _extract_content_highlights(self, subtitles: List[Dict], start_idx: int, end_idx: int) -> List[str]:
        """æå–å†…å®¹äº®ç‚¹"""
        highlights = []
        content = ' '.join([subtitles[i]['text'] for i in range(start_idx, end_idx + 1)])

        # åŸºäºå‰§æƒ…ç±»å‹åˆ†æäº®ç‚¹
        if self.detected_genre == 'æ³•å¾‹å‰§':
            if 'è¯æ®' in content:
                highlights.append("å…³é”®è¯æ®é¦–æ¬¡æŠ«éœ²")
            if 'æ³•åº­' in content or 'å®¡åˆ¤' in content:
                highlights.append("æ³•åº­æ¿€è¾©ç²¾å½©äº¤é”‹")
            if 'çœŸç›¸' in content:
                highlights.append("æ¡ˆä»¶çœŸç›¸é‡è¦æ­éœ²")

        elif self.detected_genre == 'çˆ±æƒ…å‰§':
            if 'è¡¨ç™½' in content:
                highlights.append("æµªæ¼«è¡¨ç™½æ„Ÿäººæ—¶åˆ»")
            if 'åˆ†æ‰‹' in content:
                highlights.append("åˆ†ç¦»åœºé¢å‚¬äººæ³ªä¸‹")
            if 'ç»“å©š' in content:
                highlights.append("ç”œèœœå©šç¤¼å¹¸ç¦æ—¶å…‰")

        # é€šç”¨äº®ç‚¹
        if 'å†²çª' in content:
            highlights.append("æ¿€çƒˆå†²çªæˆå‰§å¼ åŠ›")
        if 'åè½¬' in content or 'æ„å¤–' in content:
            highlights.append("å‰§æƒ…åè½¬å‡ºäººæ„æ–™")
        if 'æ„ŸåŠ¨' in content or 'éœ‡æ’¼' in content:
            highlights.append("æƒ…æ„Ÿå†²å‡»æ·±åº¦å…±é¸£")

        return highlights if highlights else ["ç²¾å½©å‰§æƒ…å‘å±•", "è§’è‰²æ·±åº¦åˆ»ç”»"]

    def generate_next_episode_connection(self, plot_points: List[Dict], episode_num: str, previous_context: str = "") -> str:
        """ç”Ÿæˆä¸ä¸‹ä¸€é›†çš„è¡”æ¥è¯´æ˜"""
        if not plot_points:
            return f"ç¬¬{episode_num}é›†å‰§æƒ…å‘å±•å®Œæ•´ï¼Œä¸‹ä¸€é›†å°†ç»§ç»­æ¨è¿›æ•…äº‹ä¸»çº¿"

        last_segment = plot_points[-1]
        content = last_segment.get('content_summary', '')
        plot_type = last_segment.get('plot_type', '')
        
        # åˆ†ææœ¬é›†æ•´ä½“å‰§æƒ…èµ°å‘
        all_content = ' '.join([point.get('content_summary', '') for point in plot_points])
        
        # åŸºäºå‰§æƒ…å‘å±•é˜¶æ®µç”Ÿæˆæ›´ç²¾å‡†çš„è¡”æ¥
        if 'è¯æ®' in content and 'å‘ç°' in content:
            if 'æ–°è¯æ®' in all_content or 'å…³é”®çº¿ç´¢' in all_content:
                return f"ç¬¬{episode_num}é›†å…³é”®è¯æ®æµ®ç°ï¼Œä¸‹ä¸€é›†å°†æ·±å…¥è°ƒæŸ¥è¿™äº›æ–°å‘ç°çš„çº¿ç´¢ï¼Œæ¡ˆä»¶çœŸç›¸å³å°†å¤§ç™½"
            else:
                return f"ç¬¬{episode_num}é›†è¯æ®é“¾é€æ­¥å®Œå–„ï¼Œä¸‹ä¸€é›†å°†åœ¨æ­¤åŸºç¡€ä¸Šå±•å¼€æ›´æ·±å…¥çš„è°ƒæŸ¥"

        elif 'å†²çª' in content or plot_type == 'å…³é”®å†²çª':
            if 'æ¿€åŒ–' in all_content or 'å‡çº§' in all_content:
                return f"ç¬¬{episode_num}é›†çŸ›ç›¾æ¿€åŒ–ï¼Œä¸‹ä¸€é›†å†²çªå°†è¿›ä¸€æ­¥å‡çº§ï¼Œå„æ–¹åŠ›é‡çš„è¾ƒé‡æ›´åŠ æ¿€çƒˆ"
            else:
                return f"ç¬¬{episode_num}é›†å†²çªçˆ†å‘ï¼Œä¸‹ä¸€é›†å°†å¤„ç†å†²çªå¸¦æ¥çš„åç»­å½±å“å’Œæ–°çš„æŒ‘æˆ˜"

        elif 'å†³å®š' in content or plot_type == 'äººç‰©è½¬æŠ˜':
            return f"ç¬¬{episode_num}é›†é‡è¦å†³å®šå·²åšå‡ºï¼Œä¸‹ä¸€é›†å°†å±•ç°è¿™ä¸ªé€‰æ‹©å¸¦æ¥çš„åæœå’Œæ–°çš„æŒ‘æˆ˜"

        elif 'çœŸç›¸' in content or plot_type == 'çº¿ç´¢æ­éœ²':
            if 'éƒ¨åˆ†' in content or 'åˆæ­¥' in content:
                return f"ç¬¬{episode_num}é›†éƒ¨åˆ†çœŸç›¸æ­éœ²ï¼Œä¸‹ä¸€é›†å°†æœ‰æ›´å¤šéšè—çš„ç§˜å¯†æµ®å‡ºæ°´é¢ï¼Œå®Œæ•´çœŸç›¸å³å°†å¤§ç™½"
            else:
                return f"ç¬¬{episode_num}é›†é‡è¦çœŸç›¸æŠ«éœ²ï¼Œä¸‹ä¸€é›†å°†å¤„ç†çœŸç›¸å¸¦æ¥çš„éœ‡æ’¼å’Œåç»­å‘å±•"

        elif plot_type == 'æƒ…æ„Ÿçˆ†å‘':
            return f"ç¬¬{episode_num}é›†æƒ…æ„Ÿè¾¾åˆ°é«˜æ½®ï¼Œä¸‹ä¸€é›†å°†å¤„ç†è¿™æ¬¡çˆ†å‘çš„åç»­å½±å“ï¼Œäººç‰©å…³ç³»é¢ä¸´é‡å¤§å˜åŒ–"

        else:
            # åŸºäºå‰§æƒ…ç±»å‹ç”Ÿæˆæ›´å…·ä½“çš„è¡”æ¥
            if self.detected_genre == 'æ³•å¾‹å‰§':
                return f"ç¬¬{episode_num}é›†æ³•å¾‹ç¨‹åºé‡è¦è¿›å±•ï¼Œä¸‹ä¸€é›†å°†ç»§ç»­æ¨è¿›æ¡ˆä»¶è°ƒæŸ¥å’Œæ³•åº­äº‰è®®"
            elif self.detected_genre == 'çˆ±æƒ…å‰§':
                return f"ç¬¬{episode_num}é›†æƒ…æ„Ÿå…³ç³»å‘å±•ï¼Œä¸‹ä¸€é›†å°†å±•ç°æ›´å¤šæ„Ÿäººçš„æƒ…æ„Ÿçº è‘›"
            else:
                return f"ç¬¬{episode_num}é›†é‡è¦æƒ…èŠ‚å‘å±•ï¼Œä¸‹ä¸€é›†æ•…äº‹å°†åœ¨æ­¤åŸºç¡€ä¸Šç»§ç»­æ¨è¿›ï¼Œæ›´å¤šç²¾å½©å†…å®¹å€¼å¾—æœŸå¾…"

    def time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace('.', ',')
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0.0

    def find_video_file(self, srt_filename: str) -> Optional[str]:
        """æŸ¥æ‰¾å¯¹åº”çš„è§†é¢‘æ–‡ä»¶"""
        base_name = os.path.splitext(srt_filename)[0]
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv']

        # ç²¾ç¡®åŒ¹é…
        for ext in video_extensions:
            video_path = os.path.join(self.videos_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path

        # æ¨¡ç³ŠåŒ¹é…
        for filename in os.listdir(self.videos_folder):
            if any(filename.lower().endswith(ext) for ext in video_extensions):
                if base_name.lower() in filename.lower():
                    return os.path.join(self.videos_folder, filename)

        return None

    def extract_episode_number(self, filename: str) -> str:
        """ä»æ–‡ä»¶åæå–é›†æ•°"""
        # å°è¯•å¤šç§é›†æ•°æ¨¡å¼
        patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)', r'(\d+)']

        for pattern in patterns:
            match = re.search(pattern, filename, re.I)
            if match:
                return match.group(1).zfill(2)

        return "00"

    def check_ffmpeg(self) -> bool:
        """æ£€æŸ¥FFmpeg"""
        try:
            result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)
            return result.returncode == 0
        except:
            return False

    def create_video_clips_stable(self, plot_points: List[Dict], video_file: str, srt_filename: str) -> List[str]:
        """åˆ›å»ºè§†é¢‘ç‰‡æ®µï¼ˆç¨³å®šç‰ˆæœ¬ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
        if not self.check_ffmpeg():
            print("âŒ æœªæ‰¾åˆ°FFmpegï¼Œæ— æ³•å‰ªè¾‘è§†é¢‘")
            return []

        created_clips = []
        episode_num = self.extract_episode_number(srt_filename)
        clip_status = self.load_clip_status(srt_filename)

        for i, plot_point in enumerate(plot_points, 1):
            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            plot_type = plot_point['plot_type']
            safe_title = re.sub(r'[^\w\u4e00-\u9fff]', '_', f"E{episode_num}_{plot_type}_{i}")
            clip_filename = f"{safe_title}.mp4"
            clip_path = os.path.join(self.clips_folder, clip_filename)

            # æ£€æŸ¥æ˜¯å¦å·²ç»æˆåŠŸå‰ªè¾‘è¿‡
            clip_key = f"clip_{i}_{plot_type}"
            if clip_key in clip_status and os.path.exists(clip_path) and os.path.getsize(clip_path) > 1024:
                print(f"âœ… ç‰‡æ®µå·²å­˜åœ¨ï¼ˆè·³è¿‡ï¼‰: {clip_filename}")
                created_clips.append(clip_path)
                continue

            # åˆ›å»ºå•ä¸ªç‰‡æ®µ
            if self.create_single_clip_stable(video_file, plot_point, clip_path):
                created_clips.append(clip_path)
                self.create_clip_description(clip_path, plot_point, episode_num)
                
                # è®°å½•æˆåŠŸçŠ¶æ€
                clip_status[clip_key] = {
                    'status': 'completed',
                    'timestamp': datetime.now().isoformat(),
                    'file_path': clip_path,
                    'file_size': os.path.getsize(clip_path) if os.path.exists(clip_path) else 0
                }
                self.save_clip_status(srt_filename, clip_status)

        return created_clips

    def create_single_clip_stable(self, video_file: str, plot_point: Dict, output_path: str, max_retries: int = 3) -> bool:
        """åˆ›å»ºå•ä¸ªè§†é¢‘ç‰‡æ®µï¼ˆç¨³å®šç‰ˆæœ¬ï¼Œæ”¯æŒé‡è¯•ï¼‰"""
        for attempt in range(max_retries):
            try:
                start_time = plot_point['start_time']
                end_time = plot_point['end_time']

                if attempt == 0:
                    print(f"ğŸ¬ å‰ªè¾‘ç‰‡æ®µ: {os.path.basename(output_path)}")
                    print(f"   æ—¶é—´: {start_time} --> {end_time}")
                    print(f"   ç±»å‹: {plot_point['plot_type']}")
                    print(f"   æ—¶é•¿: {plot_point['duration']:.1f}ç§’")
                else:
                    print(f"   ğŸ”„ é‡è¯•ç¬¬{attempt}æ¬¡...")

                start_seconds = self.time_to_seconds(start_time)
                end_seconds = self.time_to_seconds(end_time)
                duration = end_seconds - start_seconds

                if duration <= 0:
                    print(f"   âŒ æ— æ•ˆæ—¶é—´æ®µ")
                    return False

                # æ·»åŠ ç¼“å†²ç¡®ä¿å®Œæ•´æ€§
                buffer_start = max(0, start_seconds - 2)
                buffer_duration = duration + 4

                # FFmpegå‘½ä»¤ï¼ˆä¼˜åŒ–ç¨³å®šæ€§ï¼‰
                cmd = [
                    'ffmpeg',
                    '-i', video_file,
                    '-ss', str(buffer_start),
                    '-t', str(buffer_duration),
                    '-c:v', 'libx264',
                    '-c:a', 'aac',
                    '-preset', 'medium',
                    '-crf', '23',
                    '-avoid_negative_ts', 'make_zero',
                    '-movflags', '+faststart',
                    '-max_muxing_queue_size', '9999',
                    output_path,
                    '-y'
                ]

                # æ‰§è¡Œå‰ªè¾‘ï¼ˆå¢åŠ è¶…æ—¶ä¿æŠ¤ï¼‰
                timeout = max(120, duration * 3)
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)

                if result.returncode == 0 and os.path.exists(output_path) and os.path.getsize(output_path) > 1024:
                    file_size = os.path.getsize(output_path) / (1024*1024)
                    print(f"   âœ… æˆåŠŸ: {file_size:.1f}MB")
                    return True
                else:
                    error_msg = result.stderr[:100] if result.stderr else 'æœªçŸ¥é”™è¯¯'
                    print(f"   âŒ å°è¯•{attempt+1}å¤±è´¥: {error_msg}")
                    
                    # æ¸…ç†å¤±è´¥çš„æ–‡ä»¶
                    if os.path.exists(output_path):
                        os.remove(output_path)

            except subprocess.TimeoutExpired:
                print(f"   âŒ å°è¯•{attempt+1}è¶…æ—¶")
                if os.path.exists(output_path):
                    os.remove(output_path)
            except Exception as e:
                print(f"   âŒ å°è¯•{attempt+1}å¼‚å¸¸: {e}")
                if os.path.exists(output_path):
                    os.remove(output_path)

        print(f"   âŒ æ‰€æœ‰é‡è¯•å¤±è´¥")
        return False

    def create_clip_description(self, video_path: str, plot_point: Dict, episode_num: str):
        """åˆ›å»ºç‰‡æ®µæè¿°æ–‡ä»¶ï¼ˆå›ºå®šæ ¼å¼ï¼‰"""
        try:
            desc_path = video_path.replace('.mp4', '_ç‰‡æ®µè¯´æ˜.txt')

            content = f"""ğŸ“º ç”µè§†å‰§çŸ­è§†é¢‘ç‰‡æ®µè¯´æ˜æ–‡æ¡£
{"=" * 80}

ã€åŸºæœ¬ä¿¡æ¯ã€‘
é›†æ•°ç¼–å·ï¼šç¬¬{episode_num}é›†
å‰§æƒ…ç±»å‹ï¼š{plot_point.get('genre', 'æœªçŸ¥')}
ç‰‡æ®µç±»å‹ï¼š{plot_point['plot_type']}
ç‰‡æ®µæ ‡é¢˜ï¼š{plot_point['title']}

ã€æ—¶é—´ä¿¡æ¯ã€‘
å¼€å§‹æ—¶é—´ï¼š{plot_point['start_time']}
ç»“æŸæ—¶é—´ï¼š{plot_point['end_time']}
ç‰‡æ®µæ—¶é•¿ï¼š{plot_point['duration']:.1f} ç§’

ã€å‰§æƒ…åˆ†æã€‘
å‰§æƒ…æ„ä¹‰ï¼š{plot_point['plot_significance']}
å†…å®¹æ‘˜è¦ï¼š{plot_point['content_summary']}

ã€å†…å®¹äº®ç‚¹ã€‘
"""

            for highlight in plot_point['content_highlights']:
                content += f"â€¢ {highlight}\n"

            content += f"""
ã€å…³é”®å°è¯ã€‘
"""
            for dialogue in plot_point['key_dialogues']:
                content += f"{dialogue}\n"

            content += f"""
ã€ç¬¬ä¸‰äººç§°æ—ç™½å­—å¹•ã€‘
{plot_point['third_person_narration']}

ã€é”™åˆ«å­—ä¿®æ­£è¯´æ˜ã€‘
æœ¬ç‰‡æ®µå­—å¹•å·²è‡ªåŠ¨ä¿®æ­£å¸¸è§é”™åˆ«å­—ï¼š
â€¢ "é˜²è¡›" â†’ "é˜²å«"
â€¢ "æ­£ç•¶" â†’ "æ­£å½“"  
â€¢ "è¨¼æ“š" â†’ "è¯æ®"
â€¢ "æª¢å¯Ÿå®˜" â†’ "æ£€å¯Ÿå®˜"
ç­‰å¸¸è§é”™è¯¯å·²åœ¨æè¿°ä¸­ç»Ÿä¸€ä¿®æ­£ï¼Œæ–¹ä¾¿å‰ªè¾‘æ—¶å‚è€ƒã€‚

ã€å‰ªè¾‘æŠ€æœ¯è¯´æ˜ã€‘
â€¢ ç‰‡æ®µä¿è¯åœ¨å®Œæ•´å¥å­å¤„å¼€å§‹å’Œç»“æŸï¼Œç¡®ä¿å¯¹è¯å®Œæ•´æ€§
â€¢ æ—¶é—´è½´å·²ä¼˜åŒ–ï¼Œç¡®ä¿ä¸€å¥è¯è®²å®Œä¸ä¼šè¢«æˆªæ–­
â€¢ æ·»åŠ ç¬¬ä¸‰äººç§°æ—ç™½å­—å¹•å¯å¢å¼ºè§‚çœ‹ä½“éªŒ
â€¢ å»ºè®®åœ¨ç‰‡æ®µå¼€å¤´æ·»åŠ ç®€çŸ­å‰§æƒ…èƒŒæ™¯è¯´æ˜

ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

            with open(desc_path, 'w', encoding='utf-8') as f:
                f.write(content)

            print(f"   ğŸ“ è¯´æ˜æ–‡ä»¶: {os.path.basename(desc_path)}")

        except Exception as e:
            print(f"   âš ï¸ è¯´æ˜æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {e}")

    def process_episode_stable(self, srt_filename: str) -> Optional[Dict]:
        """å¤„ç†å•é›†ï¼ˆç¨³å®šç‰ˆæœ¬ï¼‰"""
        print(f"\nğŸ“º å¤„ç†é›†æ•°: {srt_filename}")

        # æ£€æŸ¥ç¼“å­˜çš„åˆ†æç»“æœ
        cached_analysis = self.load_analysis_cache(srt_filename)
        if cached_analysis:
            print("ğŸ’¾ ä½¿ç”¨ç¼“å­˜çš„åˆ†æç»“æœ")
            # éªŒè¯ç¼“å­˜æ•°æ®ç»“æ„
            if self._validate_analysis_result(cached_analysis):
                plot_points = cached_analysis.get('plot_points', [])
                episode_num = cached_analysis.get('episode_number', self.extract_episode_number(srt_filename))
                
                # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
                video_file = self.find_video_file(srt_filename)
                if not video_file:
                    print(f"âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
                    return None

                print(f"ğŸ“ è§†é¢‘æ–‡ä»¶: {os.path.basename(video_file)}")

                # åˆ›å»ºè§†é¢‘ç‰‡æ®µï¼ˆç¨³å®šç‰ˆæœ¬ï¼‰
                created_clips = self.create_video_clips_stable(plot_points, video_file, srt_filename)

                # ç”Ÿæˆä¸‹é›†è¡”æ¥è¯´æ˜
                next_episode_connection = self.generate_next_episode_connection(plot_points, episode_num)

                episode_summary = cached_analysis.copy()
                episode_summary.update({
                    'created_clips': len(created_clips),
                    'next_episode_connection': next_episode_connection,
                    'processing_timestamp': datetime.now().isoformat()
                })

                print(f"âœ… {srt_filename} å¤„ç†å®Œæˆ: {len(created_clips)} ä¸ªç‰‡æ®µ")
                return episode_summary

        # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œè¿›è¡Œå®Œæ•´åˆ†æ
        # è§£æå­—å¹•
        srt_path = os.path.join(self.srt_folder, srt_filename)
        subtitles = self.parse_srt_file(srt_path)

        if not subtitles:
            print(f"âŒ å­—å¹•è§£æå¤±è´¥")
            return None

        episode_num = self.extract_episode_number(srt_filename)

        # åˆ†æå‰§æƒ…ç‚¹
        plot_points = self.analyze_plot_points(subtitles, episode_num)

        if not plot_points:
            print(f"âŒ æœªæ‰¾åˆ°åˆé€‚çš„å‰§æƒ…ç‚¹")
            return None

        print(f"ğŸ¯ è¯†åˆ«åˆ° {len(plot_points)} ä¸ªå‰§æƒ…ç‚¹:")
        for i, point in enumerate(plot_points, 1):
            print(f"    {i}. {point['plot_type']} (è¯„åˆ†: {point['score']:.1f}, æ—¶é•¿: {point['duration']:.1f}ç§’)")

        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        video_file = self.find_video_file(srt_filename)
        if not video_file:
            print(f"âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return None

        print(f"ğŸ“ è§†é¢‘æ–‡ä»¶: {os.path.basename(video_file)}")

        # ç”Ÿæˆä¸‹é›†è¡”æ¥è¯´æ˜
        next_episode_connection = self.generate_next_episode_connection(plot_points, episode_num)

        episode_summary = {
            'episode_number': episode_num,
            'filename': srt_filename,
            'genre': self.detected_genre,
            'genre_confidence': self.genre_confidence,
            'plot_points': plot_points,
            'total_duration': sum(point['duration'] for point in plot_points),
            'next_episode_connection': next_episode_connection,
            'analysis_timestamp': datetime.now().isoformat()
        }

        # ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜
        self.save_analysis_cache(srt_filename, episode_summary)

        # åˆ›å»ºè§†é¢‘ç‰‡æ®µï¼ˆç¨³å®šç‰ˆæœ¬ï¼‰
        created_clips = self.create_video_clips_stable(plot_points, video_file, srt_filename)
        episode_summary['created_clips'] = len(created_clips)

        print(f"âœ… {srt_filename} å¤„ç†å®Œæˆ: {len(created_clips)} ä¸ªç‰‡æ®µ")

        return episode_summary

    def _validate_analysis_result(self, analysis: Dict) -> bool:
        """éªŒè¯åˆ†æç»“æœçš„å®Œæ•´æ€§"""
        required_keys = ['episode_number', 'plot_points', 'genre']
        
        if not all(key in analysis for key in required_keys):
            return False
            
        plot_points = analysis.get('plot_points', [])
        if not isinstance(plot_points, list) or not plot_points:
            return False
            
        # éªŒè¯æ¯ä¸ªå‰§æƒ…ç‚¹çš„ç»“æ„
        for point in plot_points:
            required_point_keys = ['plot_type', 'start_time', 'end_time', 'duration', 'title']
            if not all(key in point for key in required_point_keys):
                return False
                
        return True

    def process_all_episodes_stable(self):
        """å¤„ç†æ‰€æœ‰é›†æ•°ï¼ˆç¨³å®šç‰ˆæœ¬ - æ‰¹é‡å¤„ç†ï¼‰"""
        print("\nğŸš€ å¼€å§‹ç¨³å®šç‰ˆæ™ºèƒ½å‰§æƒ…å‰ªè¾‘å¤„ç†")
        print("=" * 50)

        # è·å–æ‰€æœ‰SRTæ–‡ä»¶
        srt_files = [f for f in os.listdir(self.srt_folder) 
                     if f.endswith(('.srt', '.txt')) and not f.startswith('.')]

        if not srt_files:
            print(f"âŒ {self.srt_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            return

        # æŒ‰æ–‡ä»¶åæ’åº
        srt_files.sort()

        print(f"ğŸ“ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶")

        # å¤„ç†æ¯ä¸€é›†
        all_episodes = []
        total_clips = 0
        
        for i, srt_file in enumerate(srt_files):
            try:
                print(f"\n{'='*60}")
                print(f"ğŸ“º å¤„ç†ç¬¬ {i+1}/{len(srt_files)} é›†: {srt_file}")
                print(f"{'='*60}")
                
                episode_summary = self.process_episode_stable(srt_file)
                if episode_summary:
                    all_episodes.append(episode_summary)
                    total_clips += episode_summary['created_clips']
                    
            except Exception as e:
                print(f"âŒ å¤„ç† {srt_file} å‡ºé”™: {e}")

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self.create_final_report_stable(all_episodes, total_clips)

        print(f"\nğŸ“Š å¤„ç†å®Œæˆ:")
        print(f"âœ… æˆåŠŸå¤„ç†: {len(all_episodes)}/{len(srt_files)} é›†")
        print(f"ğŸ¬ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.clips_folder}/")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {self.reports_folder}/ç¨³å®šç‰ˆå‰ªè¾‘æŠ¥å‘Š.txt")
        print(f"ğŸ’¾ ç¼“å­˜ç›®å½•: {self.cache_folder}/")

    def create_final_report_stable(self, episodes: List[Dict], total_clips: int):
        """åˆ›å»ºç¨³å®šç‰ˆæœ€ç»ˆæŠ¥å‘Š"""
        if not episodes:
            return

        report_path = os.path.join(self.reports_folder, "ç¨³å®šç‰ˆå‰ªè¾‘æŠ¥å‘Š.txt")

        content = f"""ğŸ“º ç¨³å®šç‰ˆæ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»ŸæŠ¥å‘Š
{"=" * 100}

ğŸ¯ ç³»ç»Ÿç¨³å®šæ€§ç‰¹ç‚¹ï¼š
â€¢ åˆ†æç»“æœç¼“å­˜æœºåˆ¶ - é¿å…é‡å¤APIè°ƒç”¨
â€¢ å‰ªè¾‘çŠ¶æ€è·Ÿè¸ª - æ”¯æŒæ–­ç‚¹ç»­ä¼ 
â€¢ å¤šæ¬¡æ‰§è¡Œç»“æœä¸€è‡´æ€§ä¿è¯
â€¢ å®Œæ•´å¥å­è¾¹ç•Œè¯†åˆ« - ç¡®ä¿å¯¹è¯å®Œæ•´
â€¢ è‡ªåŠ¨é‡è¯•æœºåˆ¶ - æé«˜å‰ªè¾‘æˆåŠŸç‡
â€¢ é”™è¯¯æ¢å¤å’ŒçŠ¶æ€ä¿å­˜

ğŸ“Š å¤„ç†ç»Ÿè®¡ï¼š
â€¢ æ€»é›†æ•°: {len(episodes)} é›†
â€¢ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª
â€¢ å¹³å‡æ¯é›†ç‰‡æ®µ: {total_clips/len(episodes):.1f} ä¸ª

ğŸ­ å‰§æƒ…ç±»å‹åˆ†å¸ƒï¼š
"""

        # ç»Ÿè®¡å‰§æƒ…ç±»å‹
        genre_stats = {}
        for episode in episodes:
            genre = episode.get('genre', 'æœªçŸ¥')
            genre_stats[genre] = genre_stats.get(genre, 0) + 1

        for genre, count in sorted(genre_stats.items(), key=lambda x: x[1], reverse=True):
            content += f"â€¢ {genre}: {count} é›†\n"

        content += f"""
ğŸ“ˆ å‰§æƒ…ç‚¹ç±»å‹ç»Ÿè®¡ï¼š
"""

        # ç»Ÿè®¡å‰§æƒ…ç‚¹ç±»å‹
        plot_type_stats = {}
        for episode in episodes:
            for plot_point in episode.get('plot_points', []):
                plot_type = plot_point['plot_type']
                plot_type_stats[plot_type] = plot_type_stats.get(plot_type, 0) + 1

        for plot_type, count in sorted(plot_type_stats.items(), key=lambda x: x[1], reverse=True):
            content += f"â€¢ {plot_type}: {count} ä¸ªç‰‡æ®µ\n"

        content += f"""

ğŸ’¾ ç¼“å­˜å’Œç¨³å®šæ€§ä¿¡æ¯ï¼š
â€¢ åˆ†æç»“æœç¼“å­˜æ–‡ä»¶: {len([f for f in os.listdir(self.cache_folder) if f.startswith('analysis_')])} ä¸ª
â€¢ å‰ªè¾‘çŠ¶æ€æ–‡ä»¶: {len([f for f in os.listdir(self.cache_folder) if f.startswith('clip_status_')])} ä¸ª
â€¢ å¤šæ¬¡æ‰§è¡Œä¸€è‡´æ€§: âœ… ä¿è¯
â€¢ æ–­ç‚¹ç»­ä¼ æ”¯æŒ: âœ… æ”¯æŒ
â€¢ å®Œæ•´å¥å­ä¿è¯: âœ… ä¿è¯

ğŸ“º åˆ†é›†è¯¦ç»†ä¿¡æ¯ï¼š
{"=" * 80}
"""

        for episode in episodes:
            content += f"""
ã€ç¬¬{episode['episode_number']}é›†ã€‘{episode['filename']}
å‰§æƒ…ç±»å‹ï¼š{episode['genre']} (ç½®ä¿¡åº¦: {episode['genre_confidence']:.2f})
ç”Ÿæˆç‰‡æ®µï¼š{episode['created_clips']} ä¸ª
æ€»æ—¶é•¿ï¼š{episode['total_duration']:.1f} ç§’
åˆ†ææ—¶é—´ï¼š{episode.get('analysis_timestamp', 'æœªçŸ¥')}

å‰§æƒ…ç‚¹è¯¦æƒ…ï¼š
"""
            for i, plot_point in enumerate(episode['plot_points'], 1):
                content += f"""  {i}. {plot_point['plot_type']} - {plot_point['title']}
     æ—¶é—´ï¼š{plot_point['start_time']} --> {plot_point['end_time']} ({plot_point['duration']:.1f}ç§’)
     æ„ä¹‰ï¼š{plot_point['plot_significance']}
     äº®ç‚¹ï¼š{', '.join(plot_point['content_highlights'])}
     å¥å­å®Œæ•´æ€§ï¼šâœ… ä¿è¯åœ¨å®Œæ•´å¥å­å¤„åˆ‡åˆ†
"""

            content += f"""
ğŸ”— ä¸ä¸‹ä¸€é›†è¡”æ¥ï¼š{episode['next_episode_connection']}

{"â”€" * 80}
"""

        content += f"""

ğŸ¯ ä½¿ç”¨è¯´æ˜ï¼š
1. æ‰€æœ‰è§†é¢‘ç‰‡æ®µä¿å­˜åœ¨ {self.clips_folder}/ ç›®å½•
2. æ¯ä¸ªç‰‡æ®µéƒ½æœ‰å¯¹åº”çš„è¯¦ç»†è¯´æ˜æ–‡ä»¶
3. åˆ†æç»“æœå·²ç¼“å­˜ï¼Œé‡å¤æ‰§è¡Œä¸ä¼šé‡å¤åˆ†æ
4. å‰ªè¾‘çŠ¶æ€å·²ä¿å­˜ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
5. ç‰‡æ®µä¿è¯åœ¨å®Œæ•´å¥å­å¤„åˆ‡åˆ†ï¼Œä¸ä¼šæˆªæ–­å¯¹è¯

ğŸ”§ ç¨³å®šæ€§æŠ€æœ¯ç‰¹ç‚¹ï¼š
â€¢ æ–‡ä»¶å†…å®¹å“ˆå¸Œç¼“å­˜ - ç¡®ä¿å†…å®¹å˜åŒ–æ—¶é‡æ–°åˆ†æ
â€¢ å¤šé‡éªŒè¯æœºåˆ¶ - ç¡®ä¿åˆ†æç»“æœå®Œæ•´æ€§
â€¢ è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯æ¢å¤
â€¢ å®Œæ•´å¥å­è¾¹ç•Œæ™ºèƒ½è¯†åˆ«
â€¢ çŠ¶æ€æŒä¹…åŒ–å­˜å‚¨

ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"ğŸ“„ ç¨³å®šç‰ˆæŠ¥å‘Šå·²ä¿å­˜")
        except Exception as e:
            print(f"âš ï¸ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ ç¨³å®šç‰ˆæ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ")
    print("=" * 60)
    print("ğŸ¯ ç¨³å®šæ€§ç‰¹ç‚¹ï¼š")
    print("â€¢ åˆ†æç»“æœç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤APIè°ƒç”¨")
    print("â€¢ å‰ªè¾‘çŠ¶æ€è·Ÿè¸ªï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ")
    print("â€¢ å¤šæ¬¡æ‰§è¡Œç»“æœä¸€è‡´æ€§ä¿è¯")
    print("â€¢ å®Œæ•´å¥å­è¾¹ç•Œè¯†åˆ«ï¼Œç¡®ä¿å¯¹è¯å®Œæ•´")
    print("â€¢ è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼Œæé«˜å‰ªè¾‘æˆåŠŸç‡")
    print("â€¢ æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£å’Œå›ºå®šè¾“å‡ºæ ¼å¼")
    print("=" * 60)

    clipper = StableTVClipper()

    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    if not os.path.exists(clipper.srt_folder):
        print(f"âŒ å­—å¹•ç›®å½•ä¸å­˜åœ¨: {clipper.srt_folder}")
        print("è¯·åˆ›å»ºsrtç›®å½•å¹¶æ”¾å…¥å­—å¹•æ–‡ä»¶")
        return

    if not os.path.exists(clipper.videos_folder):
        print(f"âŒ è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {clipper.videos_folder}")
        print("è¯·åˆ›å»ºvideosç›®å½•å¹¶æ”¾å…¥è§†é¢‘æ–‡ä»¶")
        return

    clipper.process_all_episodes_stable()

if __name__ == "__main__":
    main()
