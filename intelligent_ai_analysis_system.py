
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½AIç”µè§†å‰§åˆ†æç³»ç»Ÿ
å®Œå…¨åŸºäºAIçš„è‡ªé€‚åº”å‰§æƒ…åˆ†æï¼Œä¸ä¾èµ–å›ºå®šå…³é”®è¯
æ”¯æŒä»»ä½•ç±»å‹çš„ç”µè§†å‰§è‡ªåŠ¨åˆ†æå’Œå‰ªè¾‘
"""

import os
import re
import json
import hashlib
import subprocess
from typing import List, Dict, Optional
from datetime import datetime
import requests

class IntelligentAIAnalysisSystem:
    def __init__(self, srt_folder: str = "srt", video_folder: str = "videos", output_folder: str = "clips"):
        self.srt_folder = srt_folder
        self.video_folder = video_folder
        self.output_folder = output_folder
        self.cache_folder = "analysis_cache"
        
        # åˆ›å»ºç›®å½•
        for folder in [self.srt_folder, self.video_folder, self.output_folder, self.cache_folder]:
            os.makedirs(folder, exist_ok=True)
        
        # åŠ è½½AIé…ç½®
        self.ai_config = self.load_ai_config()
        
        # å‰§é›†ä¸Šä¸‹æ–‡ç¼“å­˜
        self.series_context = {
            'previous_episodes': [],
            'main_characters': set(),
            'story_threads': [],
            'ongoing_conflicts': []
        }
        
        print("ğŸ¤– æ™ºèƒ½AIç”µè§†å‰§åˆ†æç³»ç»Ÿå¯åŠ¨")
        print("=" * 60)
        print("âœ¨ ç‰¹æ€§ï¼š")
        print("â€¢ å®Œå…¨AIé©±åŠ¨ï¼Œè‡ªé€‚åº”ä»»ä½•å‰§æƒ…ç±»å‹")
        print("â€¢ æ™ºèƒ½è¯†åˆ«ç²¾å½©ç‰‡æ®µå’Œå‰§æƒ…è½¬æŠ˜")
        print("â€¢ ä¿è¯è·¨é›†è¿è´¯æ€§å’Œæ•…äº‹å®Œæ•´æ€§")
        print("â€¢ è‡ªåŠ¨é”™åˆ«å­—ä¿®æ­£")
        print("â€¢ æ¯é›†2-3åˆ†é’Ÿæ ¸å¿ƒå‰§æƒ…çŸ­è§†é¢‘")
        print("=" * 60)

    def load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            with open('.ai_config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('enabled', False) and config.get('api_key'):
                    print(f"âœ… AIé…ç½®å·²åŠ è½½: {config.get('model', 'æœªçŸ¥æ¨¡å‹')}")
                    return config
        except:
            pass
        
        print("âš ï¸ AIæœªé…ç½®ï¼Œå°†ä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")
        return {'enabled': False}

    def parse_subtitle_file(self, filepath: str) -> List[Dict]:
        """æ™ºèƒ½è§£æå­—å¹•æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œç¼–ç """
        print(f"ğŸ“– è§£æå­—å¹•æ–‡ä»¶: {os.path.basename(filepath)}")
        
        # å°è¯•å¤šç§ç¼–ç 
        content = None
        for encoding in ['utf-8', 'gbk', 'utf-16', 'gb2312', 'big5']:
            try:
                with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                    content = f.read()
                    break
            except:
                continue
        
        if not content:
            print("âŒ å­—å¹•æ–‡ä»¶è¯»å–å¤±è´¥")
            return []
        
        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£ - æ‰©å±•ç‰ˆ
        corrections = {
            # ç¹ä½“è½¬ç®€ä½“
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'å¯©åˆ¤': 'å®¡åˆ¤', 'è¾¯è­·': 'è¾©æŠ¤', 'èµ·è¨´': 'èµ·è¯‰', 'èª¿æŸ¥': 'è°ƒæŸ¥',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'é–‹å§‹': 'å¼€å§‹',
            'çµæŸ': 'ç»“æŸ', 'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'è½è­‰æœƒ': 'å¬è¯ä¼š',
            'ç„¡ç½ª': 'æ— ç½ª', 'å®Ÿç¾': 'å®ç°', 'å¯¾è©±': 'å¯¹è¯', 'é–¢ä¿‚': 'å…³ç³»',
            
            # å¸¸è§é”™åˆ«å­—
            'è¨¼æ®': 'è¯æ®', 'è¾©æˆ·': 'è¾©æŠ¤', 'æ£€æŸ¥å®˜': 'æ£€å¯Ÿå®˜', 'æ³•å®˜': 'æ³•å®˜',
            'ç”³è¿°': 'ç”³è¯‰', 'å¬æ”¿ä¼š': 'å¬è¯ä¼š', 'è¨¼äºº': 'è¯äºº', 'è¨¼è¨€': 'è¯è¨€'
        }
        
        for old, new in corrections.items():
            content = content.replace(old, new)
        
        # è§£æå­—å¹•æ¡ç›®
        subtitles = []
        
        # æ”¯æŒSRTå’ŒTXTæ ¼å¼
        if filepath.lower().endswith('.srt') or '-->' in content:
            # SRTæ ¼å¼
            blocks = re.split(r'\n\s*\n', content.strip())
            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    try:
                        index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1
                        time_match = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})', lines[1])
                        if time_match:
                            start_time = time_match.group(1).replace('.', ',')
                            end_time = time_match.group(2).replace('.', ',')
                            text = '\n'.join(lines[2:]).strip()
                            
                            if text:
                                subtitles.append({
                                    'index': index,
                                    'start': start_time,
                                    'end': end_time,
                                    'text': text,
                                    'start_seconds': self._time_to_seconds(start_time),
                                    'end_seconds': self._time_to_seconds(end_time)
                                })
                    except:
                        continue
        else:
            # TXTæ ¼å¼æˆ–å…¶ä»–æ ¼å¼ - æ™ºèƒ½è§£æ
            lines = content.split('\n')
            current_text = []
            current_time = None
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # æŸ¥æ‰¾æ—¶é—´æˆ³
                time_match = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})', line)
                if time_match and '-->' in line:
                    # ä¿å­˜ä¹‹å‰çš„å­—å¹•
                    if current_text and current_time:
                        subtitles.append({
                            'index': len(subtitles) + 1,
                            'start': current_time[0],
                            'end': current_time[1],
                            'text': ' '.join(current_text),
                            'start_seconds': self._time_to_seconds(current_time[0]),
                            'end_seconds': self._time_to_seconds(current_time[1])
                        })
                    
                    # è§£ææ–°çš„æ—¶é—´èŒƒå›´
                    time_parts = line.split('-->')
                    if len(time_parts) == 2:
                        start_time = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})', time_parts[0])
                        end_time = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})', time_parts[1])
                        if start_time and end_time:
                            current_time = (start_time.group(1).replace('.', ','), 
                                          end_time.group(1).replace('.', ','))
                            current_text = []
                else:
                    # æ·»åŠ åˆ°å½“å‰å­—å¹•æ–‡æœ¬
                    if line and not line.isdigit():
                        current_text.append(line)
            
            # ä¿å­˜æœ€åä¸€ä¸ªå­—å¹•
            if current_text and current_time:
                subtitles.append({
                    'index': len(subtitles) + 1,
                    'start': current_time[0],
                    'end': current_time[1],
                    'text': ' '.join(current_text),
                    'start_seconds': self._time_to_seconds(current_time[0]),
                    'end_seconds': self._time_to_seconds(current_time[1])
                })
        
        print(f"âœ… è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return subtitles

    def ai_analyze_episode(self, subtitles: List[Dict], episode_name: str) -> Optional[Dict]:
        """AIæ™ºèƒ½åˆ†æå•é›†å‰§æƒ…"""
        if not self.ai_config.get('enabled', False):
            print("âš ï¸ AIæœªå¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            return self.basic_analysis_fallback(subtitles, episode_name)
        
        # æ£€æŸ¥ç¼“å­˜
        cache_path = self._get_cache_path(episode_name, subtitles)
        cached_analysis = self._load_cache(cache_path)
        if cached_analysis:
            print(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜åˆ†æ: {episode_name}")
            return cached_analysis
        
        episode_num = self._extract_episode_number(episode_name)
        
        # æ„å»ºå®Œæ•´å‰§æƒ…æ–‡æœ¬
        full_script = []
        for sub in subtitles:
            timestamp = f"[{sub['start']}]"
            full_script.append(f"{timestamp} {sub['text']}")
        
        complete_content = '\n'.join(full_script)
        
        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = ""
        if self.series_context['previous_episodes']:
            context_info = f"\nä¹‹å‰å‰§é›†èƒŒæ™¯:\n"
            for prev_ep in self.series_context['previous_episodes'][-2:]:  # åªç”¨æœ€è¿‘2é›†
                context_info += f"- {prev_ep['episode']}: {prev_ep['summary']}\n"
        
        # AIåˆ†ææç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰§æƒ…åˆ†æå¸ˆã€‚è¯·å¯¹è¿™ä¸€é›†è¿›è¡Œæ·±åº¦æ™ºèƒ½åˆ†æï¼Œè¯†åˆ«æœ€ç²¾å½©çš„2-3åˆ†é’Ÿç‰‡æ®µç”¨äºçŸ­è§†é¢‘åˆ¶ä½œã€‚

ã€é›†æ•°ã€‘ç¬¬{episode_num}é›†
ã€å‰§é›†èƒŒæ™¯ã€‘{context_info}

ã€å®Œæ•´å‰§æƒ…å†…å®¹ã€‘
{complete_content}

è¯·è¿›è¡Œä¸“ä¸šåˆ†æå¹¶è¿”å›JSONæ ¼å¼ç»“æœï¼š

{{
    "episode_analysis": {{
        "episode_number": "{episode_num}",
        "drama_type": "è‡ªåŠ¨è¯†åˆ«çš„å‰§æƒ…ç±»å‹ï¼ˆå¦‚ï¼šæ³•å¾‹å‰§ã€å®¶åº­å‰§ã€æ‚¬ç–‘å‰§ã€çˆ±æƒ…å‰§ç­‰ï¼‰",
        "main_storyline": "ä¸»è¦æ•…äº‹çº¿æè¿°",
        "key_characters": ["å‡ºç°çš„ä¸»è¦è§’è‰²"],
        "emotional_arc": "æƒ…æ„Ÿå‘å±•è½¨è¿¹",
        "plot_progression": "å‰§æƒ…æ¨è¿›è¦ç‚¹",
        "dramatic_highlights": ["æˆå‰§æ€§é«˜æ½®ç‚¹1", "æˆå‰§æ€§é«˜æ½®ç‚¹2"],
        "story_themes": ["ä¸»è¦ä¸»é¢˜1", "ä¸»è¦ä¸»é¢˜2"]
    }},
    "core_segment": {{
        "title": "ç²¾å½©ç‰‡æ®µæ ‡é¢˜",
        "start_time": "å¼€å§‹æ—¶é—´ï¼ˆæ ¼å¼ï¼šHH:MM:SS,mmmï¼‰",
        "end_time": "ç»“æŸæ—¶é—´ï¼ˆæ ¼å¼ï¼šHH:MM:SS,mmmï¼‰",
        "duration_seconds": å®é™…ç§’æ•°,
        "plot_significance": "å‰§æƒ…é‡è¦æ€§è¯´æ˜",
        "dramatic_value": 8.5,
        "emotional_impact": 9.0,
        "story_coherence": "ä¸æ•´ä½“æ•…äº‹çš„è¿è´¯æ€§",
        "key_dialogues": [
            {{"timestamp": "HH:MM:SS,mmm", "speaker": "è§’è‰²å", "line": "å…³é”®å°è¯"}},
            {{"timestamp": "HH:MM:SS,mmm", "speaker": "è§’è‰²å", "line": "é‡è¦å¯¹è¯"}}
        ],
        "content_highlights": [
            "ç²¾å½©ç‚¹1ï¼šå…·ä½“æè¿°",
            "ç²¾å½©ç‚¹2ï¼šå…·ä½“æè¿°",
            "ç²¾å½©ç‚¹3ï¼šå…·ä½“æè¿°"
        ],
        "narrative_structure": {{
            "setup": "æƒ…èŠ‚é“ºå«",
            "conflict": "æ ¸å¿ƒå†²çª",
            "climax": "é«˜æ½®éƒ¨åˆ†",
            "resolution": "è§£å†³/è½¬æŠ˜"
        }}
    }},
    "series_continuity": {{
        "previous_connection": "ä¸å‰é›†çš„è”ç³»",
        "next_episode_setup": "ä¸ºä¸‹é›†çš„é“ºå«",
        "ongoing_storylines": ["æŒç»­çš„æ•…äº‹çº¿1", "æŒç»­çš„æ•…äº‹çº¿2"],
        "character_development": "è§’è‰²å‘å±•å˜åŒ–",
        "plot_threads": ["å‰§æƒ…çº¿ç´¢1", "å‰§æƒ…çº¿ç´¢2"]
    }},
    "technical_notes": {{
        "editing_suggestions": "å‰ªè¾‘å»ºè®®",
        "transition_points": "è½¬åœºç‚¹å»ºè®®",
        "subtitle_corrections": {{"é”™è¯¯è¯": "æ­£ç¡®è¯"}},
        "pacing_notes": "èŠ‚å¥æ§åˆ¶å»ºè®®"
    }}
}}

åˆ†æè¦æ±‚ï¼š
1. è‡ªåŠ¨è¯†åˆ«å‰§æƒ…ç±»å‹ï¼Œä¸è¦é¢„è®¾å›ºå®šç±»å‹
2. é€‰æ‹©çš„ç‰‡æ®µå¿…é¡»æ˜¯å®Œæ•´çš„æˆå‰§å•å…ƒï¼ˆæœ‰å¼€å§‹ã€å‘å±•ã€é«˜æ½®ï¼‰
3. æ—¶é—´æ®µå¿…é¡»åœ¨å­—å¹•èŒƒå›´å†…ï¼Œæ ¼å¼ä¸¥æ ¼ä¸ºHH:MM:SS,mmm
4. ç¡®ä¿ç‰‡æ®µæ—¶é•¿åœ¨120-180ç§’ä¹‹é—´
5. é‡ç‚¹å…³æ³¨å‰§æƒ…è½¬æŠ˜ã€æƒ…æ„Ÿçˆ†å‘ã€é‡è¦æ­éœ²ç­‰é«˜ä»·å€¼å†…å®¹
6. è€ƒè™‘ä¸å‰åé›†çš„è¿è´¯æ€§
7. æä¾›å…·ä½“çš„å‰ªè¾‘æŒ‡å¯¼å»ºè®®"""

        try:
            print(f"ğŸ¤– AIæ·±åº¦åˆ†æä¸­...")
            response = self._call_ai_api(prompt)
            
            if response:
                analysis = self._parse_ai_response(response)
                if analysis and self._validate_analysis(analysis, subtitles):
                    # ä¿å­˜ç¼“å­˜
                    self._save_cache(cache_path, analysis)
                    
                    # æ›´æ–°å‰§é›†ä¸Šä¸‹æ–‡
                    self._update_series_context(analysis, episode_name)
                    
                    return analysis
            
            print("âš ï¸ AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            return self.basic_analysis_fallback(subtitles, episode_name)
            
        except Exception as e:
            print(f"âŒ AIåˆ†æå‡ºé”™: {e}")
            return self.basic_analysis_fallback(subtitles, episode_name)

    def _call_ai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨AI API"""
        config = self.ai_config
        
        try:
            headers = {
                'Authorization': f'Bearer {config["api_key"]}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': config.get('model', 'gpt-3.5-turbo'),
                'messages': [
                    {
                        'role': 'system',
                        'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰§æƒ…åˆ†æå¸ˆï¼Œæ“…é•¿è¯†åˆ«ç²¾å½©ç‰‡æ®µå’Œä¿æŒæ•…äº‹è¿è´¯æ€§ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚'
                    },
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 4000,
                'temperature': 0.7
            }
            
            base_url = config.get('base_url', 'https://api.openai.com/v1')
            response = requests.post(
                f"{base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                return content
            else:
                print(f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def _parse_ai_response(self, response: str) -> Optional[Dict]:
        """è§£æAIå“åº”"""
        try:
            # æå–JSONå†…å®¹
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_str = response[start:end].strip()
            else:
                start = response.find("{")
                end = response.rfind("}") + 1
                if start >= 0 and end > start:
                    json_str = response[start:end]
                else:
                    json_str = response.strip()
            
            analysis = json.loads(json_str)
            return analysis
            
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            return None

    def _validate_analysis(self, analysis: Dict, subtitles: List[Dict]) -> bool:
        """éªŒè¯åˆ†æç»“æœ"""
        try:
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            if 'core_segment' not in analysis:
                return False
            
            segment = analysis['core_segment']
            if not all(key in segment for key in ['start_time', 'end_time', 'title']):
                return False
            
            # éªŒè¯æ—¶é—´æ ¼å¼å’ŒèŒƒå›´
            start_time = segment['start_time']
            end_time = segment['end_time']
            
            start_seconds = self._time_to_seconds(start_time)
            end_seconds = self._time_to_seconds(end_time)
            
            if start_seconds >= end_seconds:
                return False
            
            duration = end_seconds - start_seconds
            if duration < 60 or duration > 300:  # 1-5åˆ†é’ŸèŒƒå›´
                return False
            
            # æ£€æŸ¥æ—¶é—´æ˜¯å¦åœ¨å­—å¹•èŒƒå›´å†…
            subtitle_start = min(sub['start_seconds'] for sub in subtitles)
            subtitle_end = max(sub['end_seconds'] for sub in subtitles)
            
            if start_seconds < subtitle_start or end_seconds > subtitle_end:
                # å°è¯•ä¿®æ­£åˆ°æœ€æ¥è¿‘çš„å­—å¹•æ—¶é—´
                closest_start = min(subtitles, key=lambda s: abs(s['start_seconds'] - start_seconds))
                closest_end = min(subtitles, key=lambda s: abs(s['end_seconds'] - end_seconds))
                
                segment['start_time'] = closest_start['start']
                segment['end_time'] = closest_end['end']
                segment['duration_seconds'] = closest_end['end_seconds'] - closest_start['start_seconds']
            
            return True
            
        except Exception as e:
            print(f"éªŒè¯åˆ†æç»“æœå‡ºé”™: {e}")
            return False

    def basic_analysis_fallback(self, subtitles: List[Dict], episode_name: str) -> Dict:
        """åŸºç¡€åˆ†æå¤‡é€‰æ–¹æ¡ˆ"""
        episode_num = self._extract_episode_number(episode_name)
        
        # ç®€å•çš„å…³é”®è¯è¯„åˆ†
        keywords = {
            'æ³•å¾‹': ['æ³•å®˜', 'æ£€å¯Ÿå®˜', 'å¾‹å¸ˆ', 'æ³•åº­', 'å®¡åˆ¤', 'è¯æ®', 'æ¡ˆä»¶', 'èµ·è¯‰', 'è¾©æŠ¤'],
            'æƒ…æ„Ÿ': ['çˆ±', 'æ¨', 'æƒ…', 'å¿ƒ', 'æ„ŸåŠ¨', 'ç—›è‹¦', 'å¿«ä¹', 'æ‚²ä¼¤'],
            'æ‚¬ç–‘': ['çœŸç›¸', 'ç§˜å¯†', 'å‘ç°', 'çº¿ç´¢', 'è°ƒæŸ¥', 'æ­éœ²', 'ç¥ç§˜'],
            'å†²çª': ['äº‰è®º', 'åµæ¶', 'æ‰“æ–—', 'å¯¹æŠ—', 'å†²çª', 'çŸ›ç›¾', 'åå¯¹'],
            'è½¬æŠ˜': ['çªç„¶', 'æ²¡æƒ³åˆ°', 'åŸæ¥', 'ç«ç„¶', 'åè½¬', 'å˜åŒ–', 'æ”¹å˜']
        }
        
        # è¯„åˆ†æ¯ä¸ªå­—å¹•
        scored_subtitles = []
        for i, subtitle in enumerate(subtitles):
            score = 0
            text = subtitle['text']
            
            # å…³é”®è¯è¯„åˆ†
            for category, words in keywords.items():
                for word in words:
                    if word in text:
                        score += 2
            
            # æƒ…æ„Ÿå¼ºåº¦è¯„åˆ†
            score += text.count('ï¼') * 1.5
            score += text.count('ï¼Ÿ') * 1
            score += text.count('...') * 0.5
            
            # ä½ç½®åŠ æƒ
            position_ratio = i / len(subtitles)
            if position_ratio < 0.3 or position_ratio > 0.7:
                score *= 1.2
            
            if score > 3:
                scored_subtitles.append((i, score, subtitle))
        
        if not scored_subtitles:
            # é€‰æ‹©ä¸­é—´éƒ¨åˆ†
            mid_point = len(subtitles) // 2
            scored_subtitles = [(mid_point, 5, subtitles[mid_point])]
        
        # é€‰æ‹©æœ€é«˜åˆ†ç‰‡æ®µ
        scored_subtitles.sort(key=lambda x: x[1], reverse=True)
        center_idx, score, center_sub = scored_subtitles[0]
        
        # æ‰©å±•åˆ°2-3åˆ†é’Ÿ
        target_duration = 150  # 2.5åˆ†é’Ÿ
        start_idx = center_idx
        end_idx = center_idx
        
        # å‘å‰åæ‰©å±•
        while start_idx > 0:
            test_duration = subtitles[end_idx]['end_seconds'] - subtitles[start_idx-1]['start_seconds']
            if test_duration > target_duration:
                break
            start_idx -= 1
        
        while end_idx < len(subtitles) - 1:
            test_duration = subtitles[end_idx+1]['end_seconds'] - subtitles[start_idx]['start_seconds']
            if test_duration > target_duration * 1.2:
                break
            end_idx += 1
        
        # æ„å»ºåˆ†æç»“æœ
        start_time = subtitles[start_idx]['start']
        end_time = subtitles[end_idx]['end']
        duration = subtitles[end_idx]['end_seconds'] - subtitles[start_idx]['start_seconds']
        
        return {
            "episode_analysis": {
                "episode_number": episode_num,
                "drama_type": "é€šç”¨å‰§æƒ…",
                "main_storyline": f"ç¬¬{episode_num}é›†æ ¸å¿ƒå‰§æƒ…",
                "key_characters": ["ä¸»è¦è§’è‰²"],
                "emotional_arc": "æƒ…æ„Ÿå‘å±•",
                "plot_progression": "å‰§æƒ…æ¨è¿›"
            },
            "core_segment": {
                "title": f"ç¬¬{episode_num}é›†ç²¾å½©ç‰‡æ®µ",
                "start_time": start_time,
                "end_time": end_time,
                "duration_seconds": duration,
                "plot_significance": "é‡è¦å‰§æƒ…èŠ‚ç‚¹",
                "dramatic_value": 7.0,
                "emotional_impact": 7.0,
                "key_dialogues": [
                    {"timestamp": start_time, "speaker": "è§’è‰²", "line": subtitles[start_idx]['text'][:50]}
                ],
                "content_highlights": [
                    "æ ¸å¿ƒå‰§æƒ…å‘å±•",
                    "è§’è‰²å…³ç³»å˜åŒ–",
                    "æƒ…èŠ‚æ¨è¿›"
                ]
            },
            "series_continuity": {
                "previous_connection": "ä¸å‰é›†çš„è‡ªç„¶å»¶ç»­",
                "next_episode_setup": "ä¸ºä¸‹é›†å‰§æƒ…å‘å±•é“ºå«",
                "ongoing_storylines": ["ä¸»çº¿å‰§æƒ…"],
                "character_development": "è§’è‰²æˆé•¿"
            }
        }

    def create_video_clip(self, analysis: Dict, video_file: str, episode_name: str) -> bool:
        """åˆ›å»ºè§†é¢‘å‰ªè¾‘"""
        try:
            segment = analysis['core_segment']
            title = segment['title']
            start_time = segment['start_time']
            end_time = segment['end_time']
            
            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            safe_title = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', title)
            output_name = f"{safe_title}.mp4"
            output_path = os.path.join(self.output_folder, output_name)
            
            print(f"\nğŸ¬ åˆ›å»ºè§†é¢‘å‰ªè¾‘: {title}")
            print(f"ğŸ“ æºè§†é¢‘: {os.path.basename(video_file)}")
            print(f"â±ï¸ æ—¶é—´æ®µ: {start_time} --> {end_time}")
            print(f"ğŸ“ æ—¶é•¿: {segment['duration_seconds']:.1f}ç§’")
            
            # è½¬æ¢æ—¶é—´ä¸ºç§’
            start_seconds = self._time_to_seconds(start_time)
            end_seconds = self._time_to_seconds(end_time)
            duration = end_seconds - start_seconds
            
            # æ·»åŠ ç¼“å†²æ—¶é—´
            buffer_start = max(0, start_seconds - 1)
            buffer_duration = duration + 2
            
            # FFmpegå‰ªè¾‘å‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', str(buffer_start),
                '-t', str(buffer_duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                '-avoid_negative_ts', 'make_zero',
                output_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"  âœ… å‰ªè¾‘æˆåŠŸ: {output_name} ({file_size:.1f}MB)")
                
                # ç”Ÿæˆè¯¦ç»†è¯´æ˜æ–‡ä»¶
                self._create_description_file(output_path, analysis, episode_name)
                
                return True
            else:
                error_msg = result.stderr[:200] if result.stderr else "æœªçŸ¥é”™è¯¯"
                print(f"  âŒ å‰ªè¾‘å¤±è´¥: {error_msg}")
                return False
                
        except Exception as e:
            print(f"âŒ åˆ›å»ºè§†é¢‘å‰ªè¾‘å‡ºé”™: {e}")
            return False

    def _create_description_file(self, video_path: str, analysis: Dict, episode_name: str):
        """åˆ›å»ºè¯¦ç»†è¯´æ˜æ–‡ä»¶"""
        try:
            desc_path = video_path.replace('.mp4', '_åˆ†æ.txt')
            
            episode_analysis = analysis.get('episode_analysis', {})
            segment = analysis.get('core_segment', {})
            continuity = analysis.get('series_continuity', {})
            
            content = f"""ğŸ“º {segment.get('title', 'ç²¾å½©ç‰‡æ®µ')}
{"=" * 80}

â±ï¸ ç²¾ç¡®æ—¶é—´: {segment.get('start_time')} --> {segment.get('end_time')}
ğŸ“ ç‰‡æ®µæ—¶é•¿: {segment.get('duration_seconds', 0):.1f} ç§’
ğŸ­ å‰§æƒ…ç±»å‹: {episode_analysis.get('drama_type', 'æœªçŸ¥')}
ğŸ“Š æˆå‰§ä»·å€¼: {segment.get('dramatic_value', 0)}/10
ğŸ’¥ æƒ…æ„Ÿå†²å‡»: {segment.get('emotional_impact', 0)}/10

ğŸ’¡ å‰§æƒ…é‡è¦æ€§:
{segment.get('plot_significance', 'é‡è¦å‰§æƒ…èŠ‚ç‚¹')}

ğŸ¯ å†…å®¹äº®ç‚¹:
"""
            
            for highlight in segment.get('content_highlights', []):
                content += f"â€¢ {highlight}\n"
            
            content += f"""
ğŸ“ å…³é”®å¯¹è¯:
"""
            for dialogue in segment.get('key_dialogues', []):
                content += f"[{dialogue.get('timestamp', '')}] {dialogue.get('speaker', '')}: {dialogue.get('line', '')}\n"
            
            content += f"""
ğŸ”— å‰§é›†è¿è´¯æ€§:
â€¢ ä¸å‰é›†è”ç³»: {continuity.get('previous_connection', 'è‡ªç„¶å»¶ç»­')}
â€¢ ä¸‹é›†é“ºå«: {continuity.get('next_episode_setup', 'å‰§æƒ…å‘å±•')}
â€¢ æŒç»­æ•…äº‹çº¿: {', '.join(continuity.get('ongoing_storylines', []))}
â€¢ è§’è‰²å‘å±•: {continuity.get('character_development', 'è§’è‰²æˆé•¿')}

ğŸ“„ å‰ªè¾‘æŠ€æœ¯è¯´æ˜:
â€¢ åŸå§‹æ–‡ä»¶: {episode_name}
â€¢ æ—¶é—´ç²¾åº¦: æ¯«ç§’çº§å‡†ç¡®
â€¢ ç‰‡æ®µå®Œæ•´æ€§: åŒ…å«å®Œæ•´å¯¹è¯å’Œåœºæ™¯
â€¢ è¿è´¯æ€§ä¿è¯: è€ƒè™‘ä¸Šä¸‹æ–‡å‰§æƒ…è”ç³»

ğŸ¬ åæœŸåˆ¶ä½œå»ºè®®:
â€¢ å¯æ·»åŠ ç®€çŸ­çš„ä¸Šé›†å›é¡¾ï¼ˆ10-15ç§’ï¼‰
â€¢ å»ºè®®åœ¨ç»“å°¾æ·»åŠ ä¸‹é›†é¢„å‘Šï¼ˆ5-10ç§’ï¼‰
â€¢ ä¿æŒåŸéŸ³è½¨ï¼Œå¯æ·»åŠ èƒŒæ™¯éŸ³ä¹
â€¢ å­—å¹•å»ºè®®ä½¿ç”¨å¯¹è¯é«˜äº®æ˜¾ç¤º
"""

            # æ·»åŠ æŠ€æœ¯æ³¨é‡Š
            if 'technical_notes' in analysis:
                tech_notes = analysis['technical_notes']
                content += f"""
ğŸ”§ æŠ€æœ¯æ³¨é‡Š:
â€¢ å‰ªè¾‘å»ºè®®: {tech_notes.get('editing_suggestions', 'æ ‡å‡†å‰ªè¾‘')}
â€¢ è½¬åœºå»ºè®®: {tech_notes.get('transition_points', 'è‡ªç„¶è½¬åœº')}
â€¢ èŠ‚å¥æ§åˆ¶: {tech_notes.get('pacing_notes', 'ä¿æŒåŸå§‹èŠ‚å¥')}
"""
                
                if tech_notes.get('subtitle_corrections'):
                    content += "â€¢ å­—å¹•ä¿®æ­£:\n"
                    for wrong, correct in tech_notes['subtitle_corrections'].items():
                        content += f"  {wrong} â†’ {correct}\n"
            
            with open(desc_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"    ğŸ“„ ç”Ÿæˆåˆ†ææ–‡ä»¶: {os.path.basename(desc_path)}")
            
        except Exception as e:
            print(f"    âš ï¸ ç”Ÿæˆè¯´æ˜æ–‡ä»¶å¤±è´¥: {e}")

    def find_matching_video(self, episode_name: str) -> Optional[str]:
        """æ™ºèƒ½åŒ¹é…è§†é¢‘æ–‡ä»¶"""
        if not os.path.exists(self.video_folder):
            return None
        
        base_name = os.path.splitext(episode_name)[0]
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts']
        
        # ç²¾ç¡®åŒ¹é…
        for ext in video_extensions:
            video_path = os.path.join(self.video_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path
        
        # æ¨¡ç³ŠåŒ¹é… - æå–é›†æ•°
        episode_patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)', r'(\d+)']
        episode_num = None
        
        for pattern in episode_patterns:
            match = re.search(pattern, base_name, re.I)
            if match:
                episode_num = match.group(1)
                break
        
        if episode_num:
            for filename in os.listdir(self.video_folder):
                if any(filename.lower().endswith(ext) for ext in video_extensions):
                    for pattern in episode_patterns:
                        match = re.search(pattern, filename, re.I)
                        if match and match.group(1).zfill(2) == episode_num.zfill(2):
                            return os.path.join(self.video_folder, filename)
        
        return None

    def _get_cache_path(self, episode_name: str, subtitles: List[Dict]) -> str:
        """è·å–ç¼“å­˜è·¯å¾„"""
        content_hash = hashlib.md5(str(subtitles).encode()).hexdigest()[:16]
        safe_name = re.sub(r'[^\w\-_]', '_', episode_name)
        return os.path.join(self.cache_folder, f"{safe_name}_{content_hash}.json")

    def _load_cache(self, cache_path: str) -> Optional[Dict]:
        """åŠ è½½ç¼“å­˜"""
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return None

    def _save_cache(self, cache_path: str, analysis: Dict):
        """ä¿å­˜ç¼“å­˜"""
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def _update_series_context(self, analysis: Dict, episode_name: str):
        """æ›´æ–°å‰§é›†ä¸Šä¸‹æ–‡"""
        episode_summary = {
            'episode': episode_name,
            'drama_type': analysis.get('episode_analysis', {}).get('drama_type', ''),
            'summary': analysis.get('core_segment', {}).get('plot_significance', ''),
            'characters': analysis.get('episode_analysis', {}).get('key_characters', []),
            'storylines': analysis.get('series_continuity', {}).get('ongoing_storylines', [])
        }
        
        self.series_context['previous_episodes'].append(episode_summary)
        
        # åªä¿ç•™æœ€è¿‘5é›†çš„ä¸Šä¸‹æ–‡
        if len(self.series_context['previous_episodes']) > 5:
            self.series_context['previous_episodes'] = self.series_context['previous_episodes'][-5:]

    def _extract_episode_number(self, filename: str) -> str:
        """æå–é›†æ•°"""
        patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)', r'(\d+)']
        for pattern in patterns:
            match = re.search(pattern, filename, re.I)
            if match:
                return match.group(1).zfill(2)
        return "01"

    def _time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace(',', '.')
            parts = time_str.split(':')
            if len(parts) == 3:
                h, m, s = parts
                return int(h) * 3600 + int(m) * 60 + float(s)
            return 0.0
        except:
            return 0.0

    def process_all_episodes(self):
        """å¤„ç†æ‰€æœ‰é›†æ•°"""
        print("\nğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æå’Œå‰ªè¾‘")
        print("=" * 60)
        
        # è·å–å­—å¹•æ–‡ä»¶
        srt_files = []
        for filename in os.listdir(self.srt_folder):
            if filename.lower().endswith(('.srt', '.txt')) and not filename.startswith('.'):
                srt_files.append(filename)
        
        if not srt_files:
            print(f"âŒ {self.srt_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            return
        
        srt_files.sort()
        print(f"ğŸ“„ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶")
        
        success_count = 0
        all_analyses = []
        
        for srt_file in srt_files:
            try:
                print(f"\nğŸ“º å¤„ç†: {srt_file}")
                
                # è§£æå­—å¹•
                srt_path = os.path.join(self.srt_folder, srt_file)
                subtitles = self.parse_subtitle_file(srt_path)
                
                if not subtitles:
                    print(f"âŒ å­—å¹•è§£æå¤±è´¥")
                    continue
                
                # AIåˆ†æ
                analysis = self.ai_analyze_episode(subtitles, srt_file)
                
                if not analysis:
                    print(f"âŒ åˆ†æå¤±è´¥")
                    continue
                
                all_analyses.append({
                    'file': srt_file,
                    'analysis': analysis
                })
                
                # å¯»æ‰¾å¯¹åº”è§†é¢‘
                video_file = self.find_matching_video(srt_file)
                
                if not video_file:
                    print(f"âš ï¸ æœªæ‰¾åˆ°å¯¹åº”è§†é¢‘æ–‡ä»¶")
                    continue
                
                # åˆ›å»ºè§†é¢‘å‰ªè¾‘
                if self.create_video_clip(analysis, video_file, srt_file):
                    success_count += 1
                    print(f"âœ… {srt_file} å¤„ç†å®Œæˆ")
                else:
                    print(f"âŒ {srt_file} å‰ªè¾‘å¤±è´¥")
                    
            except Exception as e:
                print(f"âŒ å¤„ç† {srt_file} æ—¶å‡ºé”™: {e}")
        
        # ç”Ÿæˆæ•´ä½“æŠ¥å‘Š
        self._generate_series_report(all_analyses, success_count, len(srt_files))

    def _generate_series_report(self, analyses: List[Dict], success_count: int, total_count: int):
        """ç”Ÿæˆæ•´ä½“å‰§é›†æŠ¥å‘Š"""
        if not analyses:
            return
        
        report_path = os.path.join(self.output_folder, "æ™ºèƒ½åˆ†ææŠ¥å‘Š.txt")
        
        content = f"""ğŸ¤– æ™ºèƒ½AIç”µè§†å‰§åˆ†ææŠ¥å‘Š
{"=" * 80}

ğŸ“Š å¤„ç†ç»Ÿè®¡:
â€¢ æ€»é›†æ•°: {total_count} é›†
â€¢ æˆåŠŸå¤„ç†: {success_count} é›†
â€¢ æˆåŠŸç‡: {(success_count/total_count*100):.1f}%
â€¢ AIåˆ†æ: {'å¯ç”¨' if self.ai_config.get('enabled') else 'åŸºç¡€è§„åˆ™'}

ğŸ­ å‰§æƒ…ç±»å‹åˆ†å¸ƒ:
"""
        
        # ç»Ÿè®¡å‰§æƒ…ç±»å‹
        drama_types = {}
        total_duration = 0
        
        for item in analyses:
            analysis = item['analysis']
            drama_type = analysis.get('episode_analysis', {}).get('drama_type', 'æœªçŸ¥')
            drama_types[drama_type] = drama_types.get(drama_type, 0) + 1
            
            segment = analysis.get('core_segment', {})
            total_duration += segment.get('duration_seconds', 0)
        
        for drama_type, count in sorted(drama_types.items(), key=lambda x: x[1], reverse=True):
            content += f"â€¢ {drama_type}: {count} é›†\n"
        
        avg_duration = total_duration / len(analyses) if analyses else 0
        
        content += f"""
ğŸ“ æ—¶é•¿ç»Ÿè®¡:
â€¢ æ€»æ—¶é•¿: {total_duration:.1f} ç§’ ({total_duration/60:.1f} åˆ†é’Ÿ)
â€¢ å¹³å‡æ—¶é•¿: {avg_duration:.1f} ç§’ ({avg_duration/60:.1f} åˆ†é’Ÿ)

ğŸ“º è¯¦ç»†åˆ†æ:
"""
        
        # è¯¦ç»†åˆ†ææ¯ä¸€é›†
        for i, item in enumerate(analyses, 1):
            analysis = item['analysis']
            episode_analysis = analysis.get('episode_analysis', {})
            segment = analysis.get('core_segment', {})
            continuity = analysis.get('series_continuity', {})
            
            content += f"""
{i}. {segment.get('title', 'ç²¾å½©ç‰‡æ®µ')}
   æ–‡ä»¶: {item['file']}
   ç±»å‹: {episode_analysis.get('drama_type', 'æœªçŸ¥')}
   æ—¶é•¿: {segment.get('duration_seconds', 0):.1f}ç§’
   ä»·å€¼: {segment.get('dramatic_value', 0):.1f}/10
   è¿è´¯æ€§: {continuity.get('next_episode_setup', 'æœªçŸ¥')[:50]}...
"""
        
        content += f"""
ğŸ”— æ•´ä½“è¿è´¯æ€§åˆ†æ:
â€¢ æ•…äº‹ä¸»çº¿ä¿æŒè¿ç»­æ€§
â€¢ è§’è‰²å‘å±•å…·æœ‰é€»è¾‘æ€§
â€¢ å„é›†ä¹‹é—´æœ‰æ˜ç¡®çš„è¡”æ¥ç‚¹
â€¢ æ•´ä½“å™äº‹ç»“æ„å®Œæ•´

ğŸ’¡ ä½¿ç”¨å»ºè®®:
â€¢ æŒ‰é¡ºåºè§‚çœ‹çŸ­è§†é¢‘ä»¥ä¿æŒå‰§æƒ…è¿è´¯
â€¢ æ¯ä¸ªè§†é¢‘éƒ½æœ‰è¯¦ç»†çš„åˆ†ææ–‡ä»¶
â€¢ å¯æ ¹æ®å‰§æƒ…ç±»å‹åˆ†ç±»è§‚çœ‹
â€¢ å»ºè®®é…åˆåˆ†ææ–‡ä»¶ç†è§£å‰§æƒ…å‘å±•

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"\nğŸ“„ æ™ºèƒ½åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        except Exception as e:
            print(f"âš ï¸ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    system = IntelligentAIAnalysisSystem()
    
    print("\nè¯·é€‰æ‹©æ“ä½œæ¨¡å¼:")
    print("1. ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æå’Œå‰ªè¾‘")
    print("2. âš™ï¸ é…ç½®AIè®¾ç½®")
    print("3. ğŸ“ æ£€æŸ¥æ–‡ä»¶çŠ¶æ€")
    print("4. âŒ é€€å‡º")
    
    while True:
        try:
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
            
            if choice == '1':
                system.process_all_episodes()
                break
            elif choice == '2':
                configure_ai()
            elif choice == '3':
                check_file_status(system)
            elif choice == '4':
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
            break
        except Exception as e:
            print(f"âŒ æ“ä½œé”™è¯¯: {e}")

def configure_ai():
    """é…ç½®AIè®¾ç½®"""
    print("\nâš™ï¸ AIé…ç½®è®¾ç½®")
    print("=" * 40)
    
    config = {
        'enabled': True,
        'base_url': input("APIåœ°å€ (é»˜è®¤: https://api.openai.com/v1): ").strip() or "https://api.openai.com/v1",
        'api_key': input("APIå¯†é’¥: ").strip(),
        'model': input("æ¨¡å‹åç§° (é»˜è®¤: gpt-3.5-turbo): ").strip() or "gpt-3.5-turbo"
    }
    
    if config['api_key']:
        try:
            with open('.ai_config.json', 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            print("âœ… AIé…ç½®ä¿å­˜æˆåŠŸ")
        except Exception as e:
            print(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {e}")
    else:
        print("âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º")

def check_file_status(system):
    """æ£€æŸ¥æ–‡ä»¶çŠ¶æ€"""
    print("\nğŸ“ æ–‡ä»¶çŠ¶æ€æ£€æŸ¥")
    print("=" * 40)
    
    # æ£€æŸ¥å­—å¹•æ–‡ä»¶
    srt_count = 0
    if os.path.exists(system.srt_folder):
        srt_files = [f for f in os.listdir(system.srt_folder) 
                    if f.lower().endswith(('.srt', '.txt'))]
        srt_count = len(srt_files)
        print(f"ğŸ“„ å­—å¹•æ–‡ä»¶: {srt_count} ä¸ª")
        if srt_count > 0:
            for f in srt_files[:5]:
                print(f"  â€¢ {f}")
            if srt_count > 5:
                print(f"  ... ç­‰å…± {srt_count} ä¸ªæ–‡ä»¶")
    else:
        print(f"âŒ å­—å¹•ç›®å½•ä¸å­˜åœ¨: {system.srt_folder}/")
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶
    video_count = 0
    if os.path.exists(system.video_folder):
        video_files = [f for f in os.listdir(system.video_folder) 
                      if f.lower().endswith(('.mp4', '.mkv', '.avi', '.mov', '.wmv'))]
        video_count = len(video_files)
        print(f"ğŸ¬ è§†é¢‘æ–‡ä»¶: {video_count} ä¸ª")
        if video_count > 0:
            for f in video_files[:5]:
                print(f"  â€¢ {f}")
            if video_count > 5:
                print(f"  ... ç­‰å…± {video_count} ä¸ªæ–‡ä»¶")
    else:
        print(f"âŒ è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {system.video_folder}/")
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
    clip_count = 0
    if os.path.exists(system.output_folder):
        clip_files = [f for f in os.listdir(system.output_folder) 
                     if f.lower().endswith('.mp4')]
        clip_count = len(clip_files)
        print(f"âœ‚ï¸ å·²å‰ªè¾‘: {clip_count} ä¸ª")
    
    print(f"\nçŠ¶æ€æ€»ç»“:")
    print(f"â€¢ å‡†å¤‡å°±ç»ª: {'âœ…' if srt_count > 0 and video_count > 0 else 'âŒ'}")
    print(f"â€¢ AIé…ç½®: {'âœ…' if os.path.exists('.ai_config.json') else 'âŒ'}")

if __name__ == "__main__":
    main()
