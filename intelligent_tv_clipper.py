
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ - è‡ªé€‚åº”å„ç§å‰§æƒ…ç±»å‹
ç‰¹ç‚¹ï¼š
1. AIé©±åŠ¨çš„æ™ºèƒ½åˆ†æï¼Œä¸ä¾èµ–å›ºå®šå…³é”®è¯
2. è‡ªåŠ¨è¯†åˆ«å‰§æƒ…ç±»å‹ï¼ˆæ³•å¾‹ã€çˆ±æƒ…ã€æ‚¬ç–‘ã€å¤è£…ç­‰ï¼‰
3. åŠ¨æ€è°ƒæ•´è¯„åˆ†æƒé‡å’Œç‰‡æ®µé€‰æ‹©ç­–ç•¥
4. æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£å’Œæ–‡ä»¶æ ¼å¼è‡ªé€‚åº”
5. æ¯é›†ç”Ÿæˆ2-3åˆ†é’Ÿæ ¸å¿ƒå‰§æƒ…çŸ­è§†é¢‘
"""

import os
import re
import json
import subprocess
import requests
from typing import List, Dict, Optional, Tuple
from datetime import datetime

class IntelligentTVClipper:
    def __init__(self, video_folder: str = "videos", output_folder: str = "intelligent_clips"):
        self.video_folder = video_folder
        self.output_folder = output_folder
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        for folder in [self.video_folder, self.output_folder]:
            if not os.path.exists(folder):
                os.makedirs(folder)
                print(f"âœ“ åˆ›å»ºç›®å½•: {folder}/")
        
        # æ™ºèƒ½å‰§æƒ…ç±»å‹è¯†åˆ«è¯åº“
        self.genre_patterns = {
            'legal': {
                'keywords': ['æ³•å®˜', 'æ£€å¯Ÿå®˜', 'å¾‹å¸ˆ', 'æ³•åº­', 'å®¡åˆ¤', 'è¯æ®', 'æ¡ˆä»¶', 'èµ·è¯‰', 'è¾©æŠ¤', 'åˆ¤å†³', 'ç”³è¯‰', 'å¬è¯ä¼š', 'æ³•å¾‹', 'æ­£å½“é˜²å«'],
                'emotional_markers': ['æ„¤æ€’', 'æ— å¥ˆ', 'åšæŒ', 'æ­£ä¹‰', 'çœŸç›¸', 'å†¤æ‰'],
                'plot_indicators': ['å¼€åº­', 'ä¸¾è¯', 'è´¨è¯', 'åˆ¤å†³', 'ä¸Šè¯‰', 'ç¿»æ¡ˆ']
            },
            'romance': {
                'keywords': ['çˆ±æƒ…', 'å–œæ¬¢', 'å¿ƒåŠ¨', 'è¡¨ç™½', 'çº¦ä¼š', 'åˆ†æ‰‹', 'å¤åˆ', 'ç»“å©š', 'æƒ…ä¾£', 'æ‹äºº', 'æš—æ‹', 'åˆæ‹', 'æµªæ¼«'],
                'emotional_markers': ['ç”œèœœ', 'å¿ƒç–¼', 'æƒ³å¿µ', 'æ¸©æŸ”', 'æ„ŸåŠ¨', 'å¹¸ç¦', 'å¿ƒç¢', 'åæ‚”'],
                'plot_indicators': ['ç›¸é‡', 'è¯¯ä¼š', 'å‘Šç™½', 'åˆ†ç¦»', 'é‡é€¢', 'ç»“å±€']
            },
            'crime': {
                'keywords': ['è­¦å¯Ÿ', 'çŠ¯ç½ª', 'å«Œç–‘äºº', 'è°ƒæŸ¥', 'ç ´æ¡ˆ', 'çº¿ç´¢', 'å‡¶æ‰‹', 'æ¡ˆå‘', 'ä¾¦æ¢', 'åˆ‘ä¾¦', 'è¿½è¸ª', 'é€®æ•', 'çœŸå‡¶'],
                'emotional_markers': ['ç´§å¼ ', 'ææƒ§', 'éœ‡æƒŠ', 'æ„¤æ€’', 'ç»æœ›', 'å¸Œæœ›'],
                'plot_indicators': ['æ¡ˆå‘', 'è°ƒæŸ¥', 'è¿½è¸ª', 'å‘ç°', 'æŠ“æ•', 'çœŸç›¸']
            },
            'family': {
                'keywords': ['å®¶åº­', 'çˆ¶æ¯', 'å­©å­', 'å…„å¼Ÿ', 'å§å¦¹', 'äº²æƒ…', 'å®¶äºº', 'å›¢èš', 'ç¦»åˆ«', 'æˆé•¿', 'æ•™è‚²', 'ä»£æ²Ÿ', 'è´£ä»»'],
                'emotional_markers': ['æ¸©æš–', 'æ„ŸåŠ¨', 'å¿ƒç–¼', 'æ„§ç–š', 'ç†è§£', 'åŒ…å®¹'],
                'plot_indicators': ['æˆé•¿', 'å†²çª', 'å’Œè§£', 'ç¦»åˆ«', 'å›¢èš', 'ä¼ æ‰¿']
            },
            'historical': {
                'keywords': ['çš‡å¸', 'å¤§è‡£', 'æœå»·', 'æˆ˜äº‰', 'å°†å†›', 'å£«å…µ', 'ç‹æœ', 'å®«å»·', 'æ”¿æ²»', 'æƒåŠ›', 'å›ä¹±', 'èµ·ä¹‰', 'æ±Ÿå±±'],
                'emotional_markers': ['å¿ è¯š', 'èƒŒå›', 'é‡å¿ƒ', 'ç‰ºç‰²', 'è£è€€', 'è€»è¾±'],
                'plot_indicators': ['ç™»åŸº', 'æ”¿å˜', 'æˆ˜å½¹', 'è”ç›Ÿ', 'èƒŒå›', 'è¦†ç­']
            },
            'modern': {
                'keywords': ['å…¬å¸', 'èŒåœº', 'è€æ¿', 'å‘˜å·¥', 'ç«äº‰', 'åˆ›ä¸š', 'å•†ä¸š', 'é¡¹ç›®', 'åˆä½œ', 'æŠ•èµ„', 'æˆåŠŸ', 'å¤±è´¥'],
                'emotional_markers': ['å‹åŠ›', 'å…´å¥‹', 'æŒ«æŠ˜', 'æˆå°±', 'ç„¦è™‘', 'è‡ªä¿¡'],
                'plot_indicators': ['æœºä¼š', 'æŒ‘æˆ˜', 'åˆä½œ', 'ç«äº‰', 'æˆåŠŸ', 'è½¬æœº']
            }
        }
        
        # é€šç”¨æˆå‰§å¼ åŠ›æ ‡è¯†è¯
        self.universal_dramatic_words = [
            'çªç„¶', 'å¿½ç„¶', 'æ²¡æƒ³åˆ°', 'åŸæ¥', 'å±…ç„¶', 'ç«Ÿç„¶', 'éœ‡æƒŠ', 'æƒŠè®¶', 'æ„å¤–',
            'å‘ç°', 'çœŸç›¸', 'ç§˜å¯†', 'éšç’', 'æ­éœ²', 'æš´éœ²', 'çˆ†å‘', 'å†²çª', 'å¯¹æŠ—',
            'å±é™©', 'ç´§æ€¥', 'æ•‘å‘½', 'å…³é”®', 'é‡è¦', 'å†³å®š', 'é€‰æ‹©', 'æ”¹å˜', 'è½¬æŠ˜'
        ]
        
        # æƒ…æ„Ÿå¼ºåº¦æ ‡è¯†è¯
        self.emotional_intensity_words = [
            'å“­', 'ç¬‘', 'å–Š', 'å«', 'æ€’', 'æ°”', 'æ¿€åŠ¨', 'å…´å¥‹', 'ç´§å¼ ', 'å®³æ€•',
            'å¼€å¿ƒ', 'æ‚²ä¼¤', 'ç—›è‹¦', 'ç»æœ›', 'å¸Œæœ›', 'æ„ŸåŠ¨', 'æ„¤æ€’', 'å´©æºƒ', 'é¢¤æŠ–'
        ]
        
        # AIé…ç½®
        self.ai_config = self.load_ai_config()
        
        # æ£€æµ‹åˆ°çš„å‰§æƒ…ç±»å‹
        self.detected_genre = None
        self.genre_confidence = 0.0

    def load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            with open('.ai_config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('enabled', False) and config.get('api_key'):
                    return config
        except:
            pass
        
        # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        import os
        api_key = os.environ.get('AI_API_KEY') or os.environ.get('OPENAI_API_KEY')
        if api_key:
            return {
                'enabled': True,
                'api_key': api_key,
                'base_url': 'https://api.openai.com/v1',
                'model': 'gpt-3.5-turbo'
            }
        
        return {'enabled': False}

    def parse_subtitle_file(self, filepath: str) -> List[Dict]:
        """æ™ºèƒ½è§£æå­—å¹•æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œç¼–ç """
        subtitles = []
        
        # å°è¯•ä¸åŒç¼–ç 
        encodings = ['utf-8', 'gbk', 'utf-16', 'gb2312']
        content = None
        
        for encoding in encodings:
            try:
                with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                    content = f.read()
                    break
            except:
                continue
        
        if not content:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {filepath}")
            return []
        
        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£ï¼ˆæ›´å…¨é¢ï¼‰
        corrections = {
            # ç¹ä½“å­—ä¿®æ­£
            'è­‰æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜', 'å¯©åˆ¤': 'å®¡åˆ¤', 'è¾¯è­·': 'è¾©æŠ¤',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'é–‹å§‹': 'å¼€å§‹',
            'çµæŸ': 'ç»“æŸ', 'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'è½è­‰æœƒ': 'å¬è¯ä¼š',
            # å¸¸è§é”™å­—ä¿®æ­£
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'èª¿æŸ¥': 'è°ƒæŸ¥', 'èµ·è¨´': 'èµ·è¯‰',
            'è¨¼æ˜': 'è¯æ˜', 'å®Ÿç¾': 'å®ç°', 'å¯¾è©±': 'å¯¹è¯', 'é–¢ä¿‚': 'å…³ç³»'
        }
        
        for old, new in corrections.items():
            content = content.replace(old, new)
        
        # æ™ºèƒ½åˆ†å‰²å­—å¹•å—ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        # SRTæ ¼å¼
        if '-->' in content:
            blocks = re.split(r'\n\s*\n', content.strip())
            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    try:
                        # å°è¯•è§£æåºå·
                        index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1
                        
                        # è§£ææ—¶é—´
                        time_match = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})', lines[1])
                        if time_match:
                            start_time = time_match.group(1).replace('.', ',')
                            end_time = time_match.group(2).replace('.', ',')
                            text = '\n'.join(lines[2:]).strip()
                            
                            if text:  # ç¡®ä¿æœ‰å†…å®¹
                                subtitles.append({
                                    'index': index,
                                    'start': start_time,
                                    'end': end_time,
                                    'text': text,
                                    'episode': os.path.basename(filepath)
                                })
                    except (ValueError, IndexError):
                        continue
        
        # å¦‚æœæ²¡æœ‰è§£æåˆ°å­—å¹•ï¼Œå°è¯•æŒ‰è¡Œè§£æï¼ˆç®€å•æ–‡æœ¬æ ¼å¼ï¼‰
        if not subtitles:
            lines = content.split('\n')
            for i, line in enumerate(lines):
                line = line.strip()
                if line and not line.isdigit():
                    # ç”Ÿæˆè™šæ‹Ÿæ—¶é—´æˆ³
                    start_seconds = i * 3
                    end_seconds = start_seconds + 3
                    start_time = f"00:{start_seconds//60:02d}:{start_seconds%60:02d},000"
                    end_time = f"00:{end_seconds//60:02d}:{end_seconds%60:02d},000"
                    
                    subtitles.append({
                        'index': i + 1,
                        'start': start_time,
                        'end': end_time,
                        'text': line,
                        'episode': os.path.basename(filepath)
                    })
        
        print(f"âœ“ è§£æå­—å¹•: {len(subtitles)} æ¡")
        return subtitles

    def detect_genre(self, subtitles: List[Dict]) -> str:
        """æ™ºèƒ½è¯†åˆ«å‰§æƒ…ç±»å‹"""
        # åˆå¹¶å‰200æ¡å­—å¹•è¿›è¡Œåˆ†æ
        sample_text = ' '.join([sub['text'] for sub in subtitles[:200]])
        
        genre_scores = {}
        for genre, patterns in self.genre_patterns.items():
            score = 0
            
            # å…³é”®è¯è¯„åˆ†
            for keyword in patterns['keywords']:
                score += sample_text.count(keyword) * 2
            
            # æƒ…æ„Ÿæ ‡è®°è¯„åˆ†
            for marker in patterns['emotional_markers']:
                score += sample_text.count(marker) * 1.5
            
            # å‰§æƒ…æŒ‡ç¤ºè¯è¯„åˆ†
            for indicator in patterns['plot_indicators']:
                score += sample_text.count(indicator) * 3
            
            genre_scores[genre] = score
        
        # æ‰¾å‡ºæœ€åŒ¹é…çš„ç±»å‹
        if genre_scores:
            best_genre = max(genre_scores, key=genre_scores.get)
            max_score = genre_scores[best_genre]
            total_score = sum(genre_scores.values())
            
            if max_score > 10 and total_score > 0:  # è¶³å¤Ÿçš„åŒ¹é…åº¦
                self.detected_genre = best_genre
                self.genre_confidence = min(max_score / total_score, 1.0)
                print(f"ğŸ­ æ£€æµ‹å‰§æƒ…ç±»å‹: {best_genre} (ç½®ä¿¡åº¦: {self.genre_confidence:.2f})")
                return best_genre
        
        self.detected_genre = 'general'
        self.genre_confidence = 0.5
        print(f"ğŸ­ ä½¿ç”¨é€šç”¨åˆ†ææ¨¡å¼")
        return 'general'

    def calculate_segment_importance(self, text: str, position: float, context: Dict = None) -> float:
        """æ™ºèƒ½è®¡ç®—ç‰‡æ®µé‡è¦æ€§è¯„åˆ†"""
        score = 0.0
        
        # 1. å‰§æƒ…ç±»å‹åŒ¹é…è¯„åˆ†
        if self.detected_genre and self.detected_genre in self.genre_patterns:
            patterns = self.genre_patterns[self.detected_genre]
            
            # å…³é”®è¯åŒ¹é…
            for keyword in patterns['keywords']:
                if keyword in text:
                    score += 3.0 * self.genre_confidence
            
            # æƒ…æ„Ÿæ ‡è®°åŒ¹é…
            for marker in patterns['emotional_markers']:
                if marker in text:
                    score += 2.0 * self.genre_confidence
            
            # å‰§æƒ…æŒ‡ç¤ºè¯åŒ¹é…
            for indicator in patterns['plot_indicators']:
                if indicator in text:
                    score += 4.0 * self.genre_confidence
        
        # 2. é€šç”¨æˆå‰§å¼ åŠ›è¯„åˆ†
        for word in self.universal_dramatic_words:
            if word in text:
                score += 2.0
        
        # 3. æƒ…æ„Ÿå¼ºåº¦è¯„åˆ†
        for word in self.emotional_intensity_words:
            if word in text:
                score += 1.5
        
        # 4. å¯¹è¯è´¨é‡è¯„åˆ†
        punctuation_score = text.count('ï¼') * 0.5 + text.count('ï¼Ÿ') * 0.5 + text.count('...') * 0.3
        score += min(punctuation_score, 3.0)  # æœ€å¤š3åˆ†
        
        # 5. ä½ç½®æƒé‡ï¼ˆå¼€å¤´ç»“å°¾æ›´é‡è¦ï¼‰
        if position < 0.15 or position > 0.85:
            score *= 1.3
        elif 0.4 <= position <= 0.6:  # ä¸­é—´éƒ¨åˆ†
            score *= 1.1
        
        # 6. æ–‡æœ¬é•¿åº¦è´¨é‡è¯„åˆ†
        text_len = len(text)
        if 15 <= text_len <= 150:
            score += 1.0
        elif text_len > 200:
            score *= 0.8  # è¿‡é•¿çš„æ–‡æœ¬å‡åˆ†
        
        # 7. AIå¢å¼ºè¯„åˆ†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.ai_config.get('enabled', False):
            ai_score = self.get_ai_importance_score(text)
            if ai_score > 0:
                score = score * 0.7 + ai_score * 0.3  # èåˆAIè¯„åˆ†
        
        return score

    def get_ai_importance_score(self, text: str) -> float:
        """ä½¿ç”¨AIè¯„ä¼°ç‰‡æ®µé‡è¦æ€§"""
        try:
            if len(text) < 10 or len(text) > 300:
                return 0.0
            
            genre_desc = f"è¿™æ˜¯ä¸€éƒ¨{self.detected_genre}ç±»å‹çš„ç”µè§†å‰§" if self.detected_genre != 'general' else "è¿™æ˜¯ä¸€éƒ¨ç”µè§†å‰§"
            
            prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆã€‚{genre_desc}ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹å¯¹è¯ç‰‡æ®µçš„ç²¾å½©ç¨‹åº¦ï¼š

"{text}"

è¯„ä¼°æ ‡å‡†ï¼ˆæ¯é¡¹0-2åˆ†ï¼‰ï¼š
1. å‰§æƒ…é‡è¦æ€§ï¼šæ˜¯å¦æ¨è¿›ä¸»è¦æ•…äº‹çº¿
2. æˆå‰§å¼ åŠ›ï¼šæ˜¯å¦åŒ…å«å†²çªã€è½¬æŠ˜ã€æ„å¤–
3. æƒ…æ„Ÿå…±é¸£ï¼šæ˜¯å¦å¼•å‘è§‚ä¼—æƒ…æ„Ÿååº”
4. è§’è‰²å‘å±•ï¼šæ˜¯å¦å±•ç°è§’è‰²æˆé•¿æˆ–å…³ç³»å˜åŒ–
5. è§‚ä¼—å¸å¼•åŠ›ï¼šæ˜¯å¦åˆ¶é€ æ‚¬å¿µæˆ–é«˜æ½®

è¯·ç»™å‡º0-10åˆ†çš„ç»¼åˆè¯„åˆ†ï¼Œåªéœ€è¦è¾“å‡ºæ•°å­—ã€‚"""

            response = self.call_ai_api(prompt)
            if response:
                # æå–è¯„åˆ†
                score_match = re.search(r'(\d+\.?\d*)', response.strip())
                if score_match:
                    score = float(score_match.group(1))
                    return min(max(score, 0), 10)  # é™åˆ¶åœ¨0-10ä¹‹é—´
            
            return 0.0
            
        except Exception as e:
            return 0.0

    def call_ai_api(self, prompt: str) -> str:
        """è°ƒç”¨AI API"""
        try:
            config = self.ai_config
            if not config.get('enabled', False):
                return ""
            
            headers = {
                'Authorization': f'Bearer {config["api_key"]}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': config.get('model', 'gpt-3.5-turbo'),
                'messages': [
                    {'role': 'system', 'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œä¸“æ³¨äºè¯†åˆ«ç²¾å½©ç‰‡æ®µã€‚è¯·ç»™å‡ºç®€æ´å‡†ç¡®çš„è¯„åˆ†ã€‚'},
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 20,
                'temperature': 0.2
            }
            
            response = requests.post(
                f"{config.get('base_url', 'https://api.openai.com/v1')}/chat/completions",
                headers=headers,
                json=data,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result.get('choices', [{}])[0].get('message', {}).get('content', '').strip()
                return content
            
            return ""
            
        except Exception as e:
            return ""

    def find_episode_highlights(self, subtitles: List[Dict], episode_num: str) -> Optional[Dict]:
        """æ‰¾åˆ°å•é›†ç²¾å½©ç‰‡æ®µ"""
        if not subtitles:
            return None
        
        # ä½¿ç”¨æ»‘åŠ¨çª—å£åˆ†æ
        window_size = 30  # çº¦2-3åˆ†é’Ÿçš„çª—å£
        step_size = 15    # 50%é‡å 
        
        best_segment = None
        best_score = 0
        
        for i in range(0, len(subtitles) - window_size, step_size):
            segment_subs = subtitles[i:i + window_size]
            combined_text = ' '.join([sub['text'] for sub in segment_subs])
            
            position = i / len(subtitles)
            context = {
                'position': position,
                'window_index': i // step_size,
                'total_windows': (len(subtitles) - window_size) // step_size + 1
            }
            
            score = self.calculate_segment_importance(combined_text, position, context)
            
            if score > best_score:
                best_score = score
                best_segment = {
                    'start_index': i,
                    'end_index': i + window_size - 1,
                    'score': score,
                    'text': combined_text,
                    'subtitles': segment_subs
                }
        
        if not best_segment or best_score < 3.0:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é«˜åˆ†ç‰‡æ®µï¼Œé€‰æ‹©ä¸­é—´éƒ¨åˆ†
            mid_start = len(subtitles) // 3
            mid_end = min(mid_start + window_size, len(subtitles) - 1)
            best_segment = {
                'start_index': mid_start,
                'end_index': mid_end,
                'score': 3.0,
                'text': ' '.join([subtitles[j]['text'] for j in range(mid_start, mid_end + 1)]),
                'subtitles': subtitles[mid_start:mid_end + 1]
            }
        
        # ä¼˜åŒ–ç‰‡æ®µè¾¹ç•Œ
        best_segment = self.optimize_segment_boundaries(subtitles, best_segment)
        
        # ç”Ÿæˆç‰‡æ®µä¿¡æ¯
        start_time = best_segment['subtitles'][0]['start']
        end_time = best_segment['subtitles'][-1]['end']
        duration = self.time_to_seconds(end_time) - self.time_to_seconds(start_time)
        
        # ç¡®ä¿æ—¶é•¿åœ¨åˆç†èŒƒå›´å†…ï¼ˆ90-200ç§’ï¼‰
        if duration < 90:
            best_segment = self.extend_segment(subtitles, best_segment, target_duration=120)
        elif duration > 200:
            best_segment = self.trim_segment(best_segment, target_duration=180)
        
        # é‡æ–°è®¡ç®—æ—¶é—´
        start_time = best_segment['subtitles'][0]['start']
        end_time = best_segment['subtitles'][-1]['end']
        duration = self.time_to_seconds(end_time) - self.time_to_seconds(start_time)
        
        return {
            'episode_number': episode_num,
            'theme': self.generate_episode_theme(best_segment, episode_num),
            'start_time': start_time,
            'end_time': end_time,
            'duration': duration,
            'score': best_segment['score'],
            'content_preview': best_segment['text'][:100] + "..." if len(best_segment['text']) > 100 else best_segment['text'],
            'key_dialogues': self.extract_key_dialogues(best_segment['subtitles']),
            'significance': self.analyze_significance(best_segment['text']),
            'next_episode_hint': self.generate_next_episode_hint(best_segment['text'], episode_num)
        }

    def optimize_segment_boundaries(self, all_subtitles: List[Dict], segment: Dict) -> Dict:
        """ä¼˜åŒ–ç‰‡æ®µè¾¹ç•Œï¼Œå¯»æ‰¾è‡ªç„¶åˆ‡å…¥ç‚¹"""
        start_idx = segment['start_index']
        end_idx = segment['end_index']
        
        # å¯»æ‰¾æ›´å¥½çš„å¼€å§‹ç‚¹
        scene_starters = ['çªç„¶', 'è¿™æ—¶', 'å¿½ç„¶', 'åˆšæ‰', 'ç°åœ¨', 'é‚£å¤©', 'å½“æ—¶', 'ç„¶å', 'æ¥ç€', 'åæ¥']
        for i in range(max(0, start_idx - 10), start_idx + 5):
            if i < len(all_subtitles):
                text = all_subtitles[i]['text']
                if any(starter in text for starter in scene_starters):
                    start_idx = i
                    break
        
        # å¯»æ‰¾æ›´å¥½çš„ç»“æŸç‚¹
        scene_enders = ['èµ°äº†', 'ç¦»å¼€', 'ç»“æŸ', 'ç®—äº†', 'å¥½å§', 'å†è§', 'å®Œäº†', 'è¡Œäº†', 'å°±è¿™æ ·']
        for i in range(end_idx, min(len(all_subtitles), end_idx + 10)):
            text = all_subtitles[i]['text']
            if any(ender in text for ender in scene_enders):
                end_idx = i
                break
            if 'ã€‚' in text and len(text) < 20:  # çŸ­å¥ç»“æŸ
                end_idx = i
                break
        
        segment['start_index'] = start_idx
        segment['end_index'] = end_idx
        segment['subtitles'] = all_subtitles[start_idx:end_idx + 1]
        segment['text'] = ' '.join([sub['text'] for sub in segment['subtitles']])
        
        return segment

    def extend_segment(self, all_subtitles: List[Dict], segment: Dict, target_duration: int) -> Dict:
        """æ‰©å±•ç‰‡æ®µåˆ°ç›®æ ‡æ—¶é•¿"""
        current_duration = self.time_to_seconds(segment['subtitles'][-1]['end']) - self.time_to_seconds(segment['subtitles'][0]['start'])
        
        while current_duration < target_duration:
            # å‘å‰æ‰©å±•
            if segment['start_index'] > 0:
                segment['start_index'] -= 1
                segment['subtitles'].insert(0, all_subtitles[segment['start_index']])
            
            # å‘åæ‰©å±•
            if segment['end_index'] < len(all_subtitles) - 1:
                segment['end_index'] += 1
                segment['subtitles'].append(all_subtitles[segment['end_index']])
            
            if segment['start_index'] == 0 and segment['end_index'] == len(all_subtitles) - 1:
                break
            
            current_duration = self.time_to_seconds(segment['subtitles'][-1]['end']) - self.time_to_seconds(segment['subtitles'][0]['start'])
        
        segment['text'] = ' '.join([sub['text'] for sub in segment['subtitles']])
        return segment

    def trim_segment(self, segment: Dict, target_duration: int) -> Dict:
        """ä¿®å‰ªç‰‡æ®µåˆ°ç›®æ ‡æ—¶é•¿"""
        while len(segment['subtitles']) > 10:
            current_duration = self.time_to_seconds(segment['subtitles'][-1]['end']) - self.time_to_seconds(segment['subtitles'][0]['start'])
            
            if current_duration <= target_duration:
                break
            
            # ä»ä¸¤ç«¯ä¿®å‰ª
            if len(segment['subtitles']) % 2 == 0:
                segment['subtitles'].pop(0)
                segment['start_index'] += 1
            else:
                segment['subtitles'].pop()
                segment['end_index'] -= 1
        
        segment['text'] = ' '.join([sub['text'] for sub in segment['subtitles']])
        return segment

    def generate_episode_theme(self, segment: Dict, episode_num: str) -> str:
        """ç”Ÿæˆé›†æ•°ä¸»é¢˜"""
        text = segment['text']
        
        # æ ¹æ®æ£€æµ‹åˆ°çš„å‰§æƒ…ç±»å‹ç”Ÿæˆä¸»é¢˜
        if self.detected_genre == 'legal':
            if any(word in text for word in ['ç”³è¯‰', 'é‡å®¡', 'ç¿»æ¡ˆ']):
                return f"E{episode_num}ï¼šæ¡ˆä»¶ç”³è¯‰å¯åŠ¨ï¼Œæ³•å¾‹è¾ƒé‡å‡çº§"
            elif any(word in text for word in ['å¬è¯ä¼š', 'æ³•åº­', 'å®¡åˆ¤']):
                return f"E{episode_num}ï¼šæ³•åº­æ¿€è¾©ï¼Œæ­£ä¹‰ä¸æ³•ç†äº¤é”‹"
            elif any(word in text for word in ['è¯æ®', 'çœŸç›¸', 'å‘ç°']):
                return f"E{episode_num}ï¼šå…³é”®è¯æ®æµ®ç°ï¼ŒçœŸç›¸æ¸éœ²ç«¯å€ª"
            else:
                return f"E{episode_num}ï¼šæ³•å¾‹å‰§æƒ…æ¨è¿›ï¼Œæ¡ˆä»¶ç°è½¬æœº"
        
        elif self.detected_genre == 'romance':
            if any(word in text for word in ['è¡¨ç™½', 'å‘Šç™½', 'å–œæ¬¢']):
                return f"E{episode_num}ï¼šæƒ…æ„Ÿå‘Šç™½æ—¶åˆ»ï¼Œçˆ±æƒ…ç”œèœœå‡æ¸©"
            elif any(word in text for word in ['åˆ†æ‰‹', 'ç¦»åˆ«', 'è¯¯ä¼š']):
                return f"E{episode_num}ï¼šçˆ±æƒ…é­é‡æ³¢æŠ˜ï¼Œæƒ…ä¾£é¢ä¸´è€ƒéªŒ"
            elif any(word in text for word in ['ç»“å©š', 'æ±‚å©š', 'å¹¸ç¦']):
                return f"E{episode_num}ï¼šçˆ±æƒ…ä¿®æˆæ­£æœï¼Œå¹¸ç¦æ—¶åˆ»æ¥ä¸´"
            else:
                return f"E{episode_num}ï¼šæƒ…æ„Ÿå‰§æƒ…å‘å±•ï¼Œçˆ±æƒ…æ•…äº‹æ¨è¿›"
        
        elif self.detected_genre == 'crime':
            if any(word in text for word in ['ç ´æ¡ˆ', 'çœŸå‡¶', 'æŠ“æ•']):
                return f"E{episode_num}ï¼šæ¡ˆä»¶ä¾¦ç ´å…³é”®ï¼ŒçœŸå‡¶å³å°†è½ç½‘"
            elif any(word in text for word in ['çº¿ç´¢', 'å‘ç°', 'è°ƒæŸ¥']):
                return f"E{episode_num}ï¼šé‡è¦çº¿ç´¢æµ®ç°ï¼Œæ¡ˆä»¶è°ƒæŸ¥æ¨è¿›"
            elif any(word in text for word in ['å±é™©', 'è¿½é€', 'ç´§æ€¥']):
                return f"E{episode_num}ï¼šå±æœºå››ä¼æ—¶åˆ»ï¼Œç´§å¼ è¿½å‡»ä¸Šæ¼”"
            else:
                return f"E{episode_num}ï¼šåˆ‘ä¾¦å‰§æƒ…æ¨è¿›ï¼Œæ¡ˆä»¶ç°è¿›å±•"
        
        elif self.detected_genre == 'family':
            if any(word in text for word in ['å›¢èš', 'å’Œè§£', 'ç†è§£']):
                return f"E{episode_num}ï¼šå®¶åº­æ¸©æƒ…æ—¶åˆ»ï¼Œäº²æƒ…å’Œè§£æ„Ÿäºº"
            elif any(word in text for word in ['å†²çª', 'çŸ›ç›¾', 'äº‰åµ']):
                return f"E{episode_num}ï¼šå®¶åº­çŸ›ç›¾çˆ†å‘ï¼Œäº²æƒ…é¢ä¸´è€ƒéªŒ"
            elif any(word in text for word in ['æˆé•¿', 'æ•™è‚²', 'ä¼ æ‰¿']):
                return f"E{episode_num}ï¼šå®¶åº­æ•™è‚²ä¼ æ‰¿ï¼Œæˆé•¿æ„Ÿæ‚Ÿæ·±åˆ»"
            else:
                return f"E{episode_num}ï¼šå®¶åº­å‰§æƒ…å‘å±•ï¼Œäº²æƒ…æ•…äº‹æ¨è¿›"
        
        else:
            # é€šç”¨ä¸»é¢˜ç”Ÿæˆ
            if any(word in text for word in ['çœŸç›¸', 'å‘ç°', 'æ­éœ²']):
                return f"E{episode_num}ï¼šçœŸç›¸å¤§ç™½æ—¶åˆ»ï¼Œå‰§æƒ…è¿æ¥è½¬æŠ˜"
            elif any(word in text for word in ['å†²çª', 'å¯¹æŠ—', 'äº‰è®º']):
                return f"E{episode_num}ï¼šçŸ›ç›¾å†²çªçˆ†å‘ï¼Œå‰§æƒ…æ¨å‘é«˜æ½®"
            elif any(word in text for word in ['å†³å®š', 'é€‰æ‹©', 'æ”¹å˜']):
                return f"E{episode_num}ï¼šå…³é”®æŠ‰æ‹©æ—¶åˆ»ï¼Œå‘½è¿è½¬æŠ˜ç‚¹æ¥ä¸´"
            else:
                return f"E{episode_num}ï¼šç²¾å½©å‰§æƒ…æ¨è¿›ï¼Œæ•…äº‹å‘å±•è¿é«˜æ½®"

    def extract_key_dialogues(self, subtitles: List[Dict]) -> List[str]:
        """æå–å…³é”®å¯¹è¯"""
        key_dialogues = []
        
        for sub in subtitles:
            text = sub['text'].strip()
            
            # è¯„ä¼°å¯¹è¯é‡è¦æ€§
            importance = 0
            
            # å‰§æƒ…ç±»å‹ç›¸å…³å…³é”®è¯
            if self.detected_genre in self.genre_patterns:
                patterns = self.genre_patterns[self.detected_genre]
                for keyword in patterns['keywords']:
                    if keyword in text:
                        importance += 2
                for marker in patterns['emotional_markers']:
                    if marker in text:
                        importance += 1.5
            
            # é€šç”¨é‡è¦æ ‡è¯†
            for word in self.universal_dramatic_words:
                if word in text:
                    importance += 1
            
            # æƒ…æ„Ÿå¼ºåº¦
            importance += text.count('ï¼') * 0.5 + text.count('ï¼Ÿ') * 0.5
            
            if importance >= 2.0 and len(text) >= 8:
                time_code = f"{sub['start']} --> {sub['end']}"
                key_dialogues.append(f"[{time_code}] {text}")
        
        return key_dialogues[:6]  # æœ€å¤š6æ¡å…³é”®å¯¹è¯

    def analyze_significance(self, text: str) -> str:
        """åˆ†æå‰§æƒ…æ„ä¹‰"""
        significance_points = []
        
        # æ ¹æ®å‰§æƒ…ç±»å‹åˆ†æ
        if self.detected_genre in self.genre_patterns:
            patterns = self.genre_patterns[self.detected_genre]
            
            for indicator in patterns['plot_indicators']:
                if indicator in text:
                    if self.detected_genre == 'legal':
                        significance_points.append("æ³•å¾‹ç¨‹åºå…³é”®è¿›å±•")
                    elif self.detected_genre == 'romance':
                        significance_points.append("æƒ…æ„Ÿå…³ç³»é‡è¦å‘å±•")
                    elif self.detected_genre == 'crime':
                        significance_points.append("æ¡ˆä»¶è°ƒæŸ¥é‡å¤§çªç ´")
                    elif self.detected_genre == 'family':
                        significance_points.append("å®¶åº­å…³ç³»è½¬æŠ˜ç‚¹")
                    elif self.detected_genre == 'historical':
                        significance_points.append("å†å²äº‹ä»¶å…³é”®èŠ‚ç‚¹")
                    else:
                        significance_points.append("å‰§æƒ…é‡è¦è½¬æŠ˜")
                    break
        
        # é€šç”¨æ„ä¹‰åˆ†æ
        if any(word in text for word in ['çœŸç›¸', 'å‘ç°', 'æ­éœ²']):
            significance_points.append("é‡è¦ä¿¡æ¯æ­éœ²")
        if any(word in text for word in ['å†³å®š', 'é€‰æ‹©', 'æ”¹å˜']):
            significance_points.append("è§’è‰²é‡å¤§æŠ‰æ‹©")
        if any(word in text for word in ['å†²çª', 'å¯¹æŠ—', 'äº‰è®º']):
            significance_points.append("æˆå‰§å†²çªé«˜æ½®")
        if any(word in text for word in ['æ„ŸåŠ¨', 'éœ‡æ’¼', 'éœ‡æƒŠ']):
            significance_points.append("æƒ…æ„Ÿå…±é¸£å¼ºçƒˆ")
        
        return "ã€".join(significance_points) if significance_points else "ç²¾å½©å‰§æƒ…ç‰‡æ®µ"

    def generate_next_episode_hint(self, text: str, episode_num: str) -> str:
        """ç”Ÿæˆä¸‹é›†è¡”æ¥æç¤º"""
        if 'ç»§ç»­' in text or 'ä¸‹é›†' in text or 'ä¸‹æ¬¡' in text:
            return "å‰§æƒ…å¾…ç»­ï¼Œä¸‹é›†å°†æœ‰é‡å¤§å‘å±•"
        
        if self.detected_genre == 'legal':
            if any(word in text for word in ['ç”³è¯‰', 'å‡†å¤‡']):
                return "ç”³è¯‰ç¨‹åºå¯åŠ¨ï¼Œä¸‹é›†æ³•åº­è¾©è®ºå³å°†å¼€å§‹"
            elif any(word in text for word in ['è¯æ®', 'çº¿ç´¢']):
                return "æ–°è¯æ®æµ®ç°ï¼Œä¸‹é›†æ¡ˆä»¶å°†è¿æ¥è½¬æœº"
        elif self.detected_genre == 'romance':
            if any(word in text for word in ['è¯¯ä¼š', 'åˆ†ç¦»']):
                return "æƒ…æ„Ÿé­é‡æŒ«æŠ˜ï¼Œä¸‹é›†çˆ±æƒ…èƒ½å¦é‡ç‡ƒ"
            elif any(word in text for word in ['è¡¨ç™½', 'å‘Šç™½']):
                return "çˆ±æƒ…è¡¨ç™½å®Œæˆï¼Œä¸‹é›†æ„Ÿæƒ…å°†å¦‚ä½•å‘å±•"
        elif self.detected_genre == 'crime':
            if any(word in text for word in ['çº¿ç´¢', 'è°ƒæŸ¥']):
                return "è°ƒæŸ¥æ·±å…¥è¿›è¡Œï¼Œä¸‹é›†çœŸç›¸å³å°†æµ®ç°"
            elif any(word in text for word in ['å±é™©', 'ç´§æ€¥']):
                return "å±æœºå°šæœªè§£é™¤ï¼Œä¸‹é›†æƒŠé™©ç»§ç»­å‡çº§"
        
        return f"ç²¾å½©å‰§æƒ…æŒç»­å‘å±•ï¼Œä¸‹é›†æ›´å¤šäº®ç‚¹ç­‰å¾…æ­æ™“"

    def time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            # å¤„ç†ä¸åŒæ ¼å¼çš„æ—¶é—´
            time_str = time_str.replace('.', ',')  # ç»Ÿä¸€ä¸ºé€—å·æ ¼å¼
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0

    def find_video_file(self, subtitle_filename: str) -> Optional[str]:
        """æ™ºèƒ½åŒ¹é…è§†é¢‘æ–‡ä»¶"""
        if not os.path.exists(self.video_folder):
            return None
        
        # æå–å­—å¹•æ–‡ä»¶çš„åŸºç¡€å
        base_name = os.path.splitext(subtitle_filename)[0]
        
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts']
        
        # 1. ç²¾ç¡®åŒ¹é…
        for ext in video_extensions:
            video_path = os.path.join(self.video_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path
        
        # 2. æ¨¡ç³ŠåŒ¹é… - æå–é›†æ•°ä¿¡æ¯
        episode_patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)']
        subtitle_episode = None
        
        for pattern in episode_patterns:
            match = re.search(pattern, base_name, re.I)
            if match:
                subtitle_episode = match.group(1)
                break
        
        if subtitle_episode:
            for filename in os.listdir(self.video_folder):
                if any(filename.lower().endswith(ext) for ext in video_extensions):
                    for pattern in episode_patterns:
                        match = re.search(pattern, filename, re.I)
                        if match and match.group(1) == subtitle_episode:
                            return os.path.join(self.video_folder, filename)
        
        # 3. éƒ¨åˆ†åŒ¹é…
        for filename in os.listdir(self.video_folder):
            if any(filename.lower().endswith(ext) for ext in video_extensions):
                file_base = os.path.splitext(filename)[0]
                # æ£€æŸ¥æ˜¯å¦æœ‰å…±åŒçš„å…³é”®è¯
                if any(part in file_base.lower() for part in base_name.lower().split('_') if len(part) > 2):
                    return os.path.join(self.video_folder, filename)
        
        return None

    def create_clip(self, segment_plan: Dict, video_file: str) -> bool:
        """åˆ›å»ºè§†é¢‘ç‰‡æ®µ"""
        try:
            theme = segment_plan['theme']
            start_time = segment_plan['start_time']
            end_time = segment_plan['end_time']
            
            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            safe_theme = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', theme)
            output_name = f"{safe_theme}.mp4"
            output_path = os.path.join(self.output_folder, output_name)
            
            print(f"\nğŸ¬ åˆ›å»ºç²¾å½©ç‰‡æ®µ: {theme}")
            print(f"ğŸ“ æºè§†é¢‘: {os.path.basename(video_file)}")
            print(f"â±ï¸ æ—¶é—´æ®µ: {start_time} --> {end_time}")
            print(f"ğŸ“ æ—¶é•¿: {segment_plan['duration']:.1f}ç§’")
            print(f"ğŸ“Š é‡è¦æ€§è¯„åˆ†: {segment_plan['score']:.1f}/10")
            
            # è®¡ç®—æ—¶é—´
            start_seconds = self.time_to_seconds(start_time)
            end_seconds = self.time_to_seconds(end_time)
            duration = end_seconds - start_seconds
            
            # æ·»åŠ ç¼“å†²æ—¶é—´
            buffer_start = max(0, start_seconds - 1)
            buffer_duration = duration + 2
            
            # FFmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', str(buffer_start),
                '-t', str(buffer_duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                '-avoid_negative_ts', 'make_zero',
                output_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"  âœ… æˆåŠŸåˆ›å»º: {output_name} ({file_size:.1f}MB)")
                
                # åˆ›å»ºè¯´æ˜æ–‡ä»¶
                self.create_description_file(output_path, segment_plan)
                
                return True
            else:
                error_msg = result.stderr[:200] if result.stderr else "æœªçŸ¥é”™è¯¯"
                print(f"  âŒ å‰ªè¾‘å¤±è´¥: {error_msg}")
                return False
                
        except Exception as e:
            print(f"  âŒ åˆ›å»ºç‰‡æ®µæ—¶å‡ºé”™: {e}")
            return False

    def create_description_file(self, video_path: str, segment_plan: Dict):
        """åˆ›å»ºè¯¦ç»†è¯´æ˜æ–‡ä»¶"""
        try:
            desc_path = video_path.replace('.mp4', '_è¯´æ˜.txt')
            
            content = f"""ğŸ“º {segment_plan['theme']}
{"=" * 60}

ğŸ­ å‰§æƒ…ç±»å‹: {self.detected_genre}
ğŸ“Š AIåˆ†æ: {'æ˜¯' if self.ai_config.get('enabled') else 'å¦'}
ğŸ”¥ ç²¾å½©åº¦è¯„åˆ†: {segment_plan['score']:.1f}/10

â±ï¸ æ—¶é—´ç‰‡æ®µ: {segment_plan['start_time']} --> {segment_plan['end_time']}
ğŸ“ ç‰‡æ®µæ—¶é•¿: {segment_plan['duration']:.1f} ç§’ ({segment_plan['duration']/60:.1f} åˆ†é’Ÿ)
ğŸ’¡ å‰§æƒ…æ„ä¹‰: {segment_plan['significance']}

ğŸ“ å…³é”®å°è¯:
"""
            for dialogue in segment_plan['key_dialogues']:
                content += f"{dialogue}\n"
            
            content += f"""
ğŸ¯ å†…å®¹é¢„è§ˆ:
{segment_plan['content_preview']}

ğŸ”— ä¸‹é›†è¡”æ¥: {segment_plan['next_episode_hint']}

ğŸ“„ å‰ªè¾‘è¯´æ˜:
â€¢ æœ¬ç‰‡æ®µç»è¿‡AIæ™ºèƒ½åˆ†æè¯„ä¼°
â€¢ å‰§æƒ…ç±»å‹è¯†åˆ«: {self.detected_genre} (ç½®ä¿¡åº¦: {self.genre_confidence:.2f})
â€¢ æ—¶é•¿æ§åˆ¶åœ¨2-3åˆ†é’Ÿï¼Œçªå‡ºæ ¸å¿ƒå‰§æƒ…
â€¢ è‡ªåŠ¨ä¿®æ­£å­—å¹•é”™åˆ«å­—ï¼Œä¼˜åŒ–ç‰‡æ®µè¾¹ç•Œ
â€¢ é€‚åˆçŸ­è§†é¢‘å¹³å°ä¼ æ’­å’Œå‰§æƒ…ä»‹ç»
"""
            
            with open(desc_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"    ğŸ“„ ç”Ÿæˆè¯´æ˜æ–‡ä»¶: {os.path.basename(desc_path)}")
            
        except Exception as e:
            print(f"    âš  ç”Ÿæˆè¯´æ˜æ–‡ä»¶å¤±è´¥: {e}")

def main():
    """ä¸»ç¨‹åº"""
    print("ğŸš€ æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿå¯åŠ¨")
    print("=" * 60)
    print("ğŸ¤– ç³»ç»Ÿç‰¹æ€§:")
    print("â€¢ AIé©±åŠ¨æ™ºèƒ½åˆ†æï¼Œè‡ªé€‚åº”å„ç§å‰§æƒ…ç±»å‹")
    print("â€¢ è‡ªåŠ¨è¯†åˆ«å‰§æƒ…ç±»å‹å¹¶åŠ¨æ€è°ƒæ•´è¯„åˆ†ç­–ç•¥")
    print("â€¢ æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£å’Œå¤šæ ¼å¼å­—å¹•æ”¯æŒ")
    print("â€¢ æ¯é›†ç”Ÿæˆ2-3åˆ†é’Ÿæ ¸å¿ƒå‰§æƒ…çŸ­è§†é¢‘")
    print("â€¢ ä¸“ä¸šå‰ªè¾‘è¾¹ç•Œä¼˜åŒ–å’Œæ—¶é•¿æ§åˆ¶")
    print("=" * 60)
    
    clipper = IntelligentTVClipper()
    
    # è·å–æ‰€æœ‰å­—å¹•æ–‡ä»¶
    subtitle_files = []
    for file in os.listdir('.'):
        if file.endswith(('.txt', '.srt')) and not file.startswith('.') and not file.endswith('è¯´æ˜.txt'):
            # å°è¯•è¯†åˆ«æ˜¯å¦æ˜¯å­—å¹•æ–‡ä»¶
            if any(pattern in file.lower() for pattern in ['e', 's0', 'ç¬¬', 'é›†', 'ep']):
                subtitle_files.append(file)
    
    subtitle_files.sort()
    
    if not subtitle_files:
        print("âŒ æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
        print("è¯·å°†å­—å¹•æ–‡ä»¶æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼Œæ–‡ä»¶ååº”åŒ…å«é›†æ•°ä¿¡æ¯")
        print("æ”¯æŒæ ¼å¼: .txt, .srt")
        print("ç¤ºä¾‹æ–‡ä»¶å: S01E01.txt, ç¬¬1é›†.srt, EP01.txt")
        return
    
    print(f"ğŸ“„ æ‰¾åˆ° {len(subtitle_files)} ä¸ªå­—å¹•æ–‡ä»¶: {', '.join(subtitle_files[:5])}")
    if len(subtitle_files) > 5:
        print(f"   ... ç­‰ {len(subtitle_files)} ä¸ªæ–‡ä»¶")
    
    # æ£€æŸ¥è§†é¢‘ç›®å½•
    if not os.path.exists(clipper.video_folder):
        print(f"âŒ è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {clipper.video_folder}")
        print("è¯·åˆ›å»ºvideosç›®å½•å¹¶æ”¾å…¥å¯¹åº”çš„è§†é¢‘æ–‡ä»¶")
        return
    
    video_files = [f for f in os.listdir(clipper.video_folder) 
                   if f.lower().endswith(('.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts'))]
    
    if not video_files:
        print(f"âŒ è§†é¢‘ç›®å½•ä¸­æ²¡æœ‰è§†é¢‘æ–‡ä»¶")
        return
    
    print(f"ğŸ¬ æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    
    # åˆ†æç¬¬ä¸€ä¸ªå­—å¹•æ–‡ä»¶æ¥æ£€æµ‹å‰§æƒ…ç±»å‹
    first_subtitles = clipper.parse_subtitle_file(subtitle_files[0])
    detected_genre = clipper.detect_genre(first_subtitles)
    
    created_clips = []
    all_plans = []
    
    for i, subtitle_file in enumerate(subtitle_files, 1):
        print(f"\nğŸ“º å¤„ç†ç¬¬ {i} é›†: {subtitle_file}")
        
        # è§£æå­—å¹•
        subtitles = clipper.parse_subtitle_file(subtitle_file)
        if not subtitles:
            print(f"  âŒ å­—å¹•è§£æå¤±è´¥")
            continue
        
        # æå–é›†æ•°
        episode_patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)']
        episode_num = None
        
        for pattern in episode_patterns:
            match = re.search(pattern, subtitle_file, re.I)
            if match:
                episode_num = match.group(1).zfill(2)
                break
        
        if not episode_num:
            episode_num = str(i).zfill(2)
        
        # æ‰¾åˆ°ç²¾å½©ç‰‡æ®µ
        segment_plan = clipper.find_episode_highlights(subtitles, episode_num)
        if not segment_plan:
            print(f"  âŒ æœªæ‰¾åˆ°åˆé€‚çš„ç²¾å½©ç‰‡æ®µ")
            continue
        
        all_plans.append(segment_plan)
        
        print(f"  ğŸ¯ ä¸»é¢˜: {segment_plan['theme']}")
        print(f"  â±ï¸ ç‰‡æ®µ: {segment_plan['start_time']} --> {segment_plan['end_time']} ({segment_plan['duration']:.1f}ç§’)")
        print(f"  ğŸ“Š è¯„åˆ†: {segment_plan['score']:.1f}/10")
        print(f"  ğŸ’¡ æ„ä¹‰: {segment_plan['significance']}")
        
        # æ‰¾åˆ°å¯¹åº”è§†é¢‘æ–‡ä»¶
        video_file = clipper.find_video_file(subtitle_file)
        if not video_file:
            print(f"  âš  æœªæ‰¾åˆ°å¯¹åº”è§†é¢‘æ–‡ä»¶")
            continue
        
        # åˆ›å»ºçŸ­è§†é¢‘
        if clipper.create_clip(segment_plan, video_file):
            output_name = f"{re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', segment_plan['theme'])}.mp4"
            created_clips.append(os.path.join(clipper.output_folder, output_name))
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    generate_summary_report(all_plans, clipper, created_clips)
    
    print(f"\nğŸ“Š åˆ¶ä½œå®Œæˆç»Ÿè®¡:")
    print(f"âœ… åˆ†æé›†æ•°: {len(all_plans)} é›†")
    print(f"âœ… æˆåŠŸåˆ¶ä½œ: {len(created_clips)} ä¸ªçŸ­è§†é¢‘")
    print(f"ğŸ­ å‰§æƒ…ç±»å‹: {clipper.detected_genre}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {clipper.output_folder}/")
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: intelligent_tv_analysis_report.txt")

def generate_summary_report(plans: List[Dict], clipper, created_clips: List[str]):
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    if not plans:
        return
    
    content = "ğŸ“º æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘åˆ†ææŠ¥å‘Š\n"
    content += "=" * 80 + "\n\n"
    
    content += "ğŸ¤– æ™ºèƒ½ç³»ç»Ÿä¿¡æ¯ï¼š\n"
    content += f"â€¢ æ£€æµ‹å‰§æƒ…ç±»å‹: {clipper.detected_genre}\n"
    content += f"â€¢ ç±»å‹è¯†åˆ«ç½®ä¿¡åº¦: {clipper.genre_confidence:.2f}\n"
    content += f"â€¢ AIå¢å¼ºåˆ†æ: {'å¯ç”¨' if clipper.ai_config.get('enabled') else 'æœªå¯ç”¨'}\n"
    content += f"â€¢ åˆ†æé›†æ•°: {len(plans)} é›†\n"
    content += f"â€¢ æˆåŠŸåˆ¶ä½œ: {len(created_clips)} ä¸ªçŸ­è§†é¢‘\n\n"
    
    total_duration = 0
    total_score = 0
    
    for i, plan in enumerate(plans, 1):
        content += f"ğŸ“º {plan['theme']}\n"
        content += "-" * 60 + "\n"
        content += f"å‰§æƒ…ç±»å‹: {clipper.detected_genre}\n"
        content += f"æ—¶é—´ç‰‡æ®µ: {plan['start_time']} --> {plan['end_time']}\n"
        content += f"ç‰‡æ®µæ—¶é•¿: {plan['duration']:.1f} ç§’ ({plan['duration']/60:.1f} åˆ†é’Ÿ)\n"
        content += f"ç²¾å½©åº¦è¯„åˆ†: {plan['score']:.1f}/10\n"
        content += f"å‰§æƒ…æ„ä¹‰: {plan['significance']}\n\n"
        
        content += "å…³é”®å°è¯:\n"
        for dialogue in plan['key_dialogues']:
            content += f"  {dialogue}\n"
        content += "\n"
        
        content += f"å†…å®¹é¢„è§ˆ: {plan['content_preview']}\n"
        content += f"ä¸‹é›†è¡”æ¥: {plan['next_episode_hint']}\n"
        content += "=" * 80 + "\n\n"
        
        total_duration += plan['duration']
        total_score += plan['score']
    
    # æ€»ç»“ç»Ÿè®¡
    avg_duration = total_duration / len(plans) if plans else 0
    avg_score = total_score / len(plans) if plans else 0
    
    content += f"ğŸ“Š æ™ºèƒ½åˆ†ææ€»ç»“ï¼š\n"
    content += f"â€¢ å‰§æƒ…ç±»å‹: {clipper.detected_genre} (æ™ºèƒ½è¯†åˆ«)\n"
    content += f"â€¢ æ€»åˆ¶ä½œæ—¶é•¿: {total_duration:.1f} ç§’ ({total_duration/60:.1f} åˆ†é’Ÿ)\n"
    content += f"â€¢ å¹³å‡æ¯é›†æ—¶é•¿: {avg_duration:.1f} ç§’\n"
    content += f"â€¢ å¹³å‡ç²¾å½©åº¦è¯„åˆ†: {avg_score:.1f}/10\n"
    content += f"â€¢ AIè¾…åŠ©åˆ†æ: {'æ˜¯' if clipper.ai_config.get('enabled') else 'å¦'}\n"
    content += f"â€¢ åˆ¶ä½œæˆåŠŸç‡: {len(created_clips)/len(plans)*100:.1f}%\n"
    content += f"â€¢ é€‚ç”¨åœºæ™¯: çŸ­è§†é¢‘åˆ¶ä½œã€ç²¾å½©ç‰‡æ®µæå–ã€å‰§æƒ…ä»‹ç»\n"
    
    try:
        with open('intelligent_tv_analysis_report.txt', 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ“„ æ™ºèƒ½åˆ†ææŠ¥å‘Šå·²ä¿å­˜")
    except Exception as e:
        print(f"âš  ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

if __name__ == "__main__":
    main()
