#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œæ•´æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ
è§£å†³æ‰€æœ‰æ ¸å¿ƒé—®é¢˜ï¼š
1. å®é™…å‰ªè¾‘ç”ŸæˆçŸ­è§†é¢‘å’Œæ—ç™½
2. å…¨æ–‡åˆ†æå‡å°‘APIè°ƒç”¨
3. ä¿è¯å‰§æƒ…è¿è´¯æ€§å’Œåè½¬å¤„ç†
4. ç”Ÿæˆä¸“ä¸šå‰§æƒ…åˆ†ææ—ç™½
5. ç¡®ä¿å¯¹è¯å®Œæ•´æ€§
"""

import os
import re
import json
import hashlib
import subprocess
from typing import List, Dict, Optional
from datetime import datetime
from unified_config import unified_config
from unified_ai_client import ai_client

class IntelligentTVClipper:
    def __init__(self):
        # ç›®å½•ç»“æ„
        self.srt_folder = "srt"
        self.video_folder = "videos"
        self.output_folder = "clips"
        self.cache_folder = "analysis_cache"
        self.narration_folder = "narrations"

        # åˆ›å»ºå¿…è¦ç›®å½•
        for folder in [self.srt_folder, self.video_folder, self.output_folder, 
                      self.cache_folder, self.narration_folder]:
            os.makedirs(folder, exist_ok=True)

        print("ğŸ¬ å®Œæ•´æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ")
        print("=" * 60)
        print(f"ğŸ“ å­—å¹•ç›®å½•: {self.srt_folder}/")
        print(f"ğŸ¥ è§†é¢‘ç›®å½•: {self.video_folder}/")
        print(f"âœ‚ï¸ è¾“å‡ºç›®å½•: {self.output_folder}/")
        print(f"ğŸ™ï¸ æ—ç™½ç›®å½•: {self.narration_folder}/")
        print(f"ğŸ’¾ ç¼“å­˜ç›®å½•: {self.cache_folder}/")

    def parse_subtitle_file(self, filepath: str) -> List[Dict]:
        """è§£æå­—å¹•æ–‡ä»¶ï¼Œæ™ºèƒ½ä¿®æ­£é”™è¯¯"""
        print(f"ğŸ“– è§£æå­—å¹•: {os.path.basename(filepath)}")

        # å°è¯•å¤šç§ç¼–ç è¯»å–
        content = None
        for encoding in ['utf-8', 'gbk', 'utf-16', 'gb2312']:
            try:
                with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                    content = f.read()
                    break
            except:
                continue

        if not content:
            print("âŒ å­—å¹•æ–‡ä»¶è¯»å–å¤±è´¥")
            return []

        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£
        corrections = {
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'é–‹å§‹': 'å¼€å§‹',
            'çµæŸ': 'ç»“æŸ', 'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'è½è­‰æœƒ': 'å¬è¯ä¼š',
            'å“¡': 'å‘˜', 'æ•¸': 'æ•°', 'å‹™': 'åŠ¡', 'éšª': 'é™©', 'ç¨®': 'ç§'
        }

        for old, new in corrections.items():
            content = content.replace(old, new)

        # è§£æå­—å¹•æ¡ç›®
        subtitles = []
        blocks = re.split(r'\n\s*\n', content.strip())

        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                try:
                    index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1

                    time_pattern = r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})'
                    time_match = re.search(time_pattern, lines[1])

                    if time_match:
                        start_time = time_match.group(1).replace('.', ',')
                        end_time = time_match.group(2).replace('.', ',')
                        text = '\n'.join(lines[2:]).strip()

                        if text:
                            subtitles.append({
                                'index': index,
                                'start': start_time,
                                'end': end_time,
                                'text': text,
                                'start_seconds': self._time_to_seconds(start_time),
                                'end_seconds': self._time_to_seconds(end_time)
                            })
                except:
                    continue

        print(f"âœ… è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return subtitles

    def get_analysis_cache_path(self, srt_file: str) -> str:
        """è·å–åˆ†æç¼“å­˜è·¯å¾„"""
        file_hash = self._get_file_hash(srt_file)
        base_name = os.path.splitext(os.path.basename(srt_file))[0]
        return os.path.join(self.cache_folder, f"{base_name}_{file_hash}_analysis.json")

    def _get_file_hash(self, filepath: str) -> str:
        """è·å–æ–‡ä»¶å†…å®¹å“ˆå¸Œå€¼"""
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            return hashlib.md5(content.encode()).hexdigest()[:16]
        except:
            return "unknown"

    def load_cached_analysis(self, srt_file: str) -> Optional[Dict]:
        """åŠ è½½ç¼“å­˜çš„åˆ†æç»“æœ"""
        cache_path = self.get_analysis_cache_path(srt_file)
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    analysis = json.load(f)
                print(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜åˆ†æ: {os.path.basename(srt_file)}")
                return analysis
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        return None

    def save_analysis_cache(self, srt_file: str, analysis: Dict):
        """ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜"""
        cache_path = self.get_analysis_cache_path(srt_file)
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ä¿å­˜åˆ†æç¼“å­˜: {os.path.basename(srt_file)}")
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

    def ai_analyze_full_episode(self, subtitles: List[Dict], episode_name: str) -> Optional[Dict]:
        """AIåˆ†ææ•´é›†å†…å®¹ - å…¨æ–‡åˆ†æå‡å°‘APIè°ƒç”¨"""
        if not unified_config.is_enabled():
            print("âŒ AIæœªå¯ç”¨ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return None

        episode_num = self._extract_episode_number(episode_name)

        # æ„å»ºå®Œæ•´å‰§æƒ…æ–‡æœ¬ - å…¨æ–‡è¾“å…¥ä¿è¯è¿è´¯æ€§
        full_context = []
        for sub in subtitles:
            timestamp = f"[{sub['start']}]"
            full_context.append(f"{timestamp} {sub['text']}")

        complete_script = '\n'.join(full_context)

        # ä¸“ä¸šå‰§æƒ…åˆ†ææç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆå’Œå‰§æƒ…åˆ†æä¸“å®¶ã€‚è¯·å¯¹è¿™ä¸€é›†è¿›è¡Œæ·±åº¦åˆ†æï¼Œè¯†åˆ«å‡º3-4ä¸ªæœ€ç²¾å½©ä¸”è¿è´¯çš„ç‰‡æ®µç”¨äºçŸ­è§†é¢‘åˆ¶ä½œã€‚

ã€é›†æ•°ã€‘{episode_num}
ã€å®Œæ•´å‰§æƒ…å†…å®¹ã€‘
{complete_script}

è¯·è¿›è¡Œä¸“ä¸šåˆ†æå¹¶è¿”å›JSONæ ¼å¼ç»“æœï¼š

{{
    "episode_analysis": {{
        "episode_number": "{episode_num}",
        "main_storyline": "ä¸»è¦æ•…äº‹çº¿æè¿°",
        "key_characters": ["ä¸»è¦è§’è‰²1", "ä¸»è¦è§’è‰²2"],
        "plot_progression": ["æƒ…èŠ‚å‘å±•1", "æƒ…èŠ‚å‘å±•2"],
        "dramatic_arc": "æ•´ä½“æˆå‰§å¼§çº¿",
        "emotional_journey": "æƒ…æ„Ÿå†ç¨‹",
        "plot_twists": ["åè½¬ç‚¹1", "åè½¬ç‚¹2"],
        "continuity_points": ["ä¸å‰é›†è”ç³»", "ä¸ºåé›†é“ºå«"]
    }},
    "highlight_segments": [
        {{
            "segment_id": 1,
            "title": "ç‰‡æ®µæ ‡é¢˜",
            "start_time": "00:05:30,000",
            "end_time": "00:08:45,000",
            "plot_significance": "å‰§æƒ…é‡è¦æ€§è¯´æ˜",
            "dramatic_tension": 8.5,
            "emotional_impact": 9.0,
            "dialogue_quality": 8.0,
            "story_progression": "æ¨è¿›ä¸»çº¿å‰§æƒ…",
            "character_development": "è§’è‰²å‘å±•æè¿°",
            "visual_elements": ["è§†è§‰äº®ç‚¹1", "è§†è§‰äº®ç‚¹2"],
            "key_dialogues": [
                {{"speaker": "è§’è‰²å", "line": "å…³é”®å°è¯", "timestamp": "00:06:15,000"}},
                {{"speaker": "è§’è‰²å", "line": "é‡è¦å¯¹è¯", "timestamp": "00:07:20,000"}}
            ],
            "narrative_analysis": {{
                "setup": "æƒ…èŠ‚é“ºå«",
                "conflict": "æ ¸å¿ƒå†²çª",
                "climax": "é«˜æ½®éƒ¨åˆ†",
                "resolution": "è§£å†³æ–¹æ¡ˆ",
                "hook": "æ‚¬å¿µè®¾ç½®"
            }},
            "connection_to_series": {{
                "previous_reference": "ä¸å‰é¢å‰§æƒ…çš„è”ç³»",
                "future_setup": "ä¸ºåç»­æƒ…èŠ‚çš„é“ºå«",
                "series_importance": "åœ¨æ•´éƒ¨å‰§ä¸­çš„é‡è¦æ€§"
            }}
        }}
    ],
    "series_continuity": {{
        "previous_episode_connections": ["ä¸å‰é›†çš„è”ç³»1", "ä¸å‰é›†çš„è”ç³»2"],
        "next_episode_setup": ["ä¸ºä¸‹é›†çš„é“ºå«1", "ä¸ºä¸‹é›†çš„é“ºå«2"],
        "overarching_themes": ["æ€»ä½“ä¸»é¢˜1", "æ€»ä½“ä¸»é¢˜2"],
        "character_arcs": {{"è§’è‰²å": "è§’è‰²å‘å±•è½¨è¿¹"}}
    }},
    "narrative_coherence": {{
        "story_flow": "æ•…äº‹æµç•…æ€§è¯„ä¼°",
        "logical_consistency": "é€»è¾‘ä¸€è‡´æ€§",
        "emotional_consistency": "æƒ…æ„Ÿä¸€è‡´æ€§",
        "pacing_analysis": "èŠ‚å¥åˆ†æ"
    }}
}}

åˆ†æè¦æ±‚ï¼š
1. ç¡®ä¿ç‰‡æ®µæ—¶é—´åœ¨å­—å¹•èŒƒå›´å†…ä¸”æ ¼å¼ä¸ºHH:MM:SS,mmm
2. æ¯ä¸ªç‰‡æ®µ2-3åˆ†é’Ÿï¼ŒåŒ…å«å®Œæ•´çš„æˆå‰§ç»“æ„
3. ç‰‡æ®µä¹‹é—´è¦æœ‰é€»è¾‘è”ç³»ï¼Œèƒ½å®Œæ•´å™è¿°å‰§æƒ…
4. ç‰¹åˆ«å…³æ³¨åè½¬æƒ…èŠ‚ä¸å‰é¢å‰§æƒ…çš„è”ç³»
5. ç¡®ä¿å¯¹è¯å®Œæ•´æ€§ï¼Œä¸æˆªæ–­å¥å­
6. åˆ†æè¦æ·±åº¦ä¸“ä¸šï¼Œé€‚åˆåˆ¶ä½œæ—ç™½è§£è¯´"""

        try:
            print(f"ğŸ¤– AIåˆ†ææ•´é›†å†…å®¹...")
            response = ai_client.call_ai(prompt, "ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆå’Œå‰§æƒ…åˆ†æä¸“å®¶ã€‚")

            if not response:
                print("âŒ AIåˆ†æå¤±è´¥")
                return None

            # è§£æAIå“åº”
            analysis = self._parse_ai_response(response)
            if not analysis:
                print("âŒ AIå“åº”è§£æå¤±è´¥")
                return None

            # éªŒè¯å’Œä¿®æ­£æ—¶é—´æ®µ
            validated_segments = []
            for segment in analysis.get('highlight_segments', []):
                if self._validate_and_fix_segment(segment, subtitles):
                    validated_segments.append(segment)

            if not validated_segments:
                print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ç‰‡æ®µ")
                return None

            analysis['highlight_segments'] = validated_segments
            return analysis

        except Exception as e:
            print(f"âŒ AIåˆ†æå‡ºé”™: {e}")
            return None

    def _parse_ai_response(self, response: str) -> Optional[Dict]:
        """è§£æAIå“åº”"""
        try:
            # æå–JSONå†…å®¹
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_str = response[start:end].strip()
            else:
                json_str = response.strip()

            return json.loads(json_str)
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æé”™è¯¯: {e}")
            print(f"åŸå§‹å“åº”: {response}")
            return None
        except Exception as e:
            print(f"âŒ è§£æAIå“åº”å‡ºé”™: {e}")
            return None

    def _validate_and_fix_segment(self, segment: Dict, subtitles: List[Dict]) -> bool:
        """éªŒè¯å¹¶ä¿®æ­£æ—¶é—´æ®µ"""
        start_time = segment['start_time']
        end_time = segment['end_time']

        # è½¬æ¢ä¸ºç§’æ•°
        start_seconds = self._time_to_seconds(start_time)
        end_seconds = self._time_to_seconds(end_time)

        # æŸ¥æ‰¾æœ€æ¥è¿‘çš„å­—å¹•æ¡ç›®
        closest_start = None
        closest_end = None

        for sub in subtitles:
            if abs(sub['start_seconds'] - start_seconds) <= 10:
                closest_start = sub
            if abs(sub['end_seconds'] - end_seconds) <= 10:
                closest_end = sub

        # å¦‚æœæ‰¾åˆ°ï¼Œåˆ™æ›´æ–°æ—¶é—´
        if closest_start:
            segment['start_time'] = closest_start['start']
            start_seconds = closest_start['start_seconds']
        if closest_end:
            segment['end_time'] = closest_end['end']
            end_seconds = closest_end['end_seconds']

        # éªŒè¯æ—¶é—´é¡ºåº
        if start_seconds >= end_seconds:
            print(f"âš ï¸ æ—¶é—´æ®µæ— æ•ˆ: {start_time} --> {end_time}")
            return False

        return True

    def _time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´å­—ç¬¦ä¸²è½¬ç§’æ•°"""
        try:
            time_obj = datetime.strptime(time_str, '%H:%M:%S,%f')
            return time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second + time_obj.microsecond / 1000000.0
        except ValueError:
            time_obj = datetime.strptime(time_str, '%H:%M:%S,%f')
            return time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second + time_obj.microsecond / 1000000.0

    def _safe_filename(self, title: str) -> str:
        """åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å"""
        safe_title = re.sub(r'[^\w\s]', '', title)
        safe_title = safe_title.replace(' ', '_')
        return safe_title[:60]  # é™åˆ¶é•¿åº¦

    def _find_video_file(self, episode_name: str) -> Optional[str]:
        """æŸ¥æ‰¾å¯¹åº”çš„è§†é¢‘æ–‡ä»¶"""
        for filename in os.listdir(self.video_folder):
            if episode_name in filename and filename.lower().endswith(('.mp4', '.avi', '.mkv')):
                return os.path.join(self.video_folder, filename)
        return None

    def _extract_episode_number(self, episode_name: str) -> str:
        """æå–å‰§é›†å·ç """
        match = re.search(r'ç¬¬(\d+)é›†', episode_name)
        if match:
            return match.group(1)
        return "æœªçŸ¥é›†æ•°"

    def _clip_video_segment(self, video_file: str, segment: Dict, output_path: str) -> bool:
        """å‰ªè¾‘è§†é¢‘ç‰‡æ®µ"""
        start_time = segment['start_time'].replace(',', '.')
        end_time = segment['end_time'].replace(',', '.')

        try:
            # è®¡ç®—æŒç»­æ—¶é—´
            start_seconds = self._time_to_seconds(start_time.replace('.', ','))
            end_seconds = self._time_to_seconds(end_time.replace('.', ','))
            duration = end_seconds - start_seconds

            # æ„å»ºffmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', start_time,
                '-t', str(duration),
                '-c', 'copy',  # ä½¿ç”¨copyé¿å…é‡æ–°ç¼–ç 
                output_path
            ]

            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            print(f"   âœ… å‰ªè¾‘å‘½ä»¤: {' '.join(cmd)}")
            print(f"   âœ… å‰ªè¾‘è¾“å‡º: {result.stderr}")  # ffmpegè¾“å‡ºåˆ°stderr

            return True
        except subprocess.CalledProcessError as e:
            print(f"   âŒ å‰ªè¾‘å¤±è´¥: {e.stderr}")
            return False
        except Exception as e:
            print(f"   âŒ å‰ªè¾‘å‡ºé”™: {e}")
            return False

    def create_clip_with_narration(self, analysis: Dict, srt_file: str) -> bool:
        """åˆ›å»ºå‰ªè¾‘ç‰‡æ®µå¹¶ç”Ÿæˆæ—ç™½ - ä¸€ä½“åŒ–æµç¨‹"""
        print(f"\nğŸ¬ å¼€å§‹å‰ªè¾‘å¹¶ç”Ÿæˆæ—ç™½...")

        episode_name = os.path.splitext(os.path.basename(srt_file))[0]
        video_file = self._find_video_file(episode_name)

        if not video_file:
            print(f"âŒ æ‰¾ä¸åˆ°å¯¹åº”è§†é¢‘: {episode_name}")
            return False

        print(f"ğŸ¥ æºè§†é¢‘: {os.path.basename(video_file)}")

        success_count = 0

        for i, segment in enumerate(analysis['highlight_segments']):
            print(f"\nğŸ“¹ å‰ªè¾‘ç‰‡æ®µ {i+1}: {segment['title']}")

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            safe_title = self._safe_filename(segment['title'])
            clip_filename = f"{episode_name}_{safe_title}.mp4"
            clip_path = os.path.join(self.output_folder, clip_filename)

            # æ—ç™½æ–‡ä»¶è·¯å¾„
            narration_filename = f"{episode_name}_{safe_title}_æ—ç™½.txt"
            narration_path = os.path.join(self.narration_folder, narration_filename)

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å®Œæ•´çš„å‰ªè¾‘å’Œæ—ç™½
            if os.path.exists(clip_path) and os.path.exists(narration_path):
                print(f"âœ… ç‰‡æ®µå’Œæ—ç™½å·²å­˜åœ¨: {clip_filename}")
                success_count += 1
                continue

            # å‰ªè¾‘è§†é¢‘
            print(f"   â±ï¸ æ—¶é—´: {segment['start_time']} --> {segment['end_time']}")
            if self._clip_video_segment(video_file, segment, clip_path):
                print(f"   âœ… è§†é¢‘å‰ªè¾‘å®Œæˆ")

                # ç«‹å³ç”Ÿæˆå¯¹åº”çš„æ—ç™½
                print(f"   ğŸ™ï¸ ç”Ÿæˆæ—ç™½ä¸­...")
                narration = self._generate_segment_narration(segment, analysis)

                # ä¿å­˜æ—ç™½æ–‡ä»¶
                self._save_narration_file(narration_path, segment, narration)

                print(f"   âœ… æ—ç™½ç”Ÿæˆå®Œæˆ: {narration_filename}")
                success_count += 1
            else:
                print(f"   âŒ å‰ªè¾‘å¤±è´¥: {segment['title']}")

        print(f"\nğŸ“Š å‰ªè¾‘å®Œæˆ: {success_count}/{len(analysis['highlight_segments'])} ä¸ªç‰‡æ®µæˆåŠŸ")
        return success_count > 0

    def _save_narration_file(self, narration_path: str, segment: Dict, narration: Dict):
        """ä¿å­˜æ—ç™½æ–‡ä»¶"""
        with open(narration_path, 'w', encoding='utf-8') as f:
            f.write(f"ç‰‡æ®µæ ‡é¢˜: {segment['title']}\n")
            f.write(f"æ—¶é—´æ®µ: {segment['start_time']} --> {segment['end_time']}\n")
            f.write(f"å‰§æƒ…é‡è¦æ€§: {segment['plot_significance']}\n")
            f.write(f"æˆå‰§å¼ åŠ›: {segment.get('dramatic_tension', 'N/A')}\n")
            f.write(f"æƒ…æ„Ÿå†²å‡»: {segment.get('emotional_impact', 'N/A')}\n\n")

            f.write("=== æ—ç™½å†…å®¹ ===\n")
            f.write(f"å¼€åœºç™½: {narration['opening']}\n")
            f.write(f"è¿‡ç¨‹è§£è¯´: {narration['process']}\n")
            f.write(f"äº®ç‚¹å¼ºè°ƒ: {narration['highlight']}\n")
            f.write(f"ç»“å°¾: {narration['ending']}\n\n")

            f.write("=== å®Œæ•´æ—ç™½ ===\n")
            f.write(f"{narration['full_narration']}\n\n")

            if 'timing' in narration:
                f.write("=== æ—¶é—´å®‰æ’ ===\n")
                for section, timing in narration['timing'].items():
                    f.write(f"{section}: {timing[0]}-{timing[1]}ç§’\n")

            if 'key_dialogues' in segment:
                f.write("\n=== å…³é”®å°è¯ ===\n")
                for dialogue in segment['key_dialogues']:
                    f.write(f"[{dialogue['timestamp']}] {dialogue['speaker']}: {dialogue['line']}\n")

    def _generate_segment_narration(self, segment: Dict, analysis: Dict) -> Dict:
        """ä¸ºç‰‡æ®µç”Ÿæˆä¸“ä¸šæ—ç™½"""
        if not unified_config.is_enabled():
            # ä½¿ç”¨æ¨¡æ¿ç”ŸæˆåŸºç¡€æ—ç™½
            return self._generate_template_narration(segment)

        # ä½¿ç”¨AIç”Ÿæˆä¸“ä¸šæ—ç™½
        context = analysis.get('episode_analysis', {})
        episode_theme = context.get('main_storyline', '')

        # æå–å…³é”®å¯¹è¯ä½œä¸ºå‚è€ƒ
        key_dialogues = segment.get('key_dialogues', [])
        dialogue_context = ""
        if key_dialogues:
            dialogue_context = "\nå…³é”®å¯¹è¯ï¼š\n"
            for d in key_dialogues[:3]:  # åªå–å‰3ä¸ª
                dialogue_context += f"- {d['speaker']}: {d['line']}\n"

        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§çŸ­è§†é¢‘æ—ç™½è§£è¯´å‘˜ã€‚è¯·ä¸ºè¿™ä¸ªç²¾å½©ç‰‡æ®µç”Ÿæˆä¸“ä¸šçš„è§£è¯´æ—ç™½ã€‚

ç‰‡æ®µä¿¡æ¯ï¼š
æ ‡é¢˜ï¼š{segment['title']}
æ—¶é—´ï¼š{segment['start_time']} --> {segment['end_time']}
å‰§æƒ…é‡è¦æ€§ï¼š{segment['plot_significance']}
æ•…äº‹å‘å±•ï¼š{segment.get('story_progression', '')}
è§’è‰²å‘å±•ï¼š{segment.get('character_development', '')}
å‰§é›†ä¸»é¢˜ï¼š{episode_theme}{dialogue_context}

è¯·ç”Ÿæˆä¸“ä¸šçš„4æ®µå¼æ—ç™½ï¼š
1. å¼€åœºç™½ï¼ˆ2-3ç§’ï¼‰ï¼šæŠ“ä½è§‚ä¼—æ³¨æ„åŠ›çš„å¼€åœº
2. è¿‡ç¨‹è§£è¯´ï¼ˆ3-5ç§’ï¼‰ï¼šè§£é‡Šæ ¸å¿ƒæƒ…èŠ‚å’Œäººç‰©åŠ¨æœº
3. äº®ç‚¹å¼ºè°ƒï¼ˆ2-3ç§’ï¼‰ï¼šçªå‡ºæœ€ç²¾å½©çš„æˆå‰§å†²çª
4. ç»“å°¾ï¼ˆ1-2ç§’ï¼‰ï¼šåˆ¶é€ æ‚¬å¿µæˆ–æƒ…æ„Ÿå…±é¸£

æ—ç™½è¦æ±‚ï¼š
- è¯­è¨€ç®€æ´æœ‰åŠ›ï¼ŒèŠ‚å¥æ„Ÿå¼º
- çªå‡ºæˆå‰§å¼ åŠ›å’Œæƒ…æ„Ÿå†²çª
- é€‚åˆçŸ­è§†é¢‘å¿«èŠ‚å¥è§‚çœ‹
- é¿å…è¿‡åº¦å‰§é€ï¼Œä¿æŒæ‚¬å¿µ
- æ€»æ—¶é•¿8-12ç§’

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "opening": "å¼€åœºç™½æ–‡æœ¬",
    "process": "è¿‡ç¨‹è§£è¯´æ–‡æœ¬",
    "highlight": "äº®ç‚¹å¼ºè°ƒæ–‡æœ¬", 
    "ending": "ç»“å°¾æ–‡æœ¬",
    "full_narration": "å®Œæ•´è¿è´¯çš„æ—ç™½æ–‡æœ¬",
    "timing": {{
        "opening": [0, 3],
        "process": [3, 8], 
        "highlight": [8, 11],
        "ending": [11, 12]
    }}
}}"""

        try:
            response = ai_client.call_ai(prompt, "ä½ æ˜¯ä¸“ä¸šçš„çŸ­è§†é¢‘æ—ç™½è§£è¯´å‘˜ã€‚")
            if response:
                parsed = self._parse_narration_response(response)
                if parsed:
                    return parsed
        except Exception as e:
            print(f"   âš ï¸ AIæ—ç™½ç”Ÿæˆå¤±è´¥: {e}")

        # é™çº§åˆ°æ¨¡æ¿ç”Ÿæˆ
        return self._generate_template_narration(segment)

    def _generate_template_narration(self, segment: Dict) -> Dict:
        """ä½¿ç”¨æ¨¡æ¿ç”ŸæˆåŸºç¡€æ—ç™½"""
        title = segment['title']
        significance = segment.get('plot_significance', '')

        # æ ¹æ®æ ‡é¢˜å†…å®¹æ™ºèƒ½ç”Ÿæˆæ—ç™½
        if "æ¡ˆä»¶" in title or "æ³•åº­" in title:
            opening = f"æ³•å¾‹å‰§æƒ…çš„å…³é”®æ—¶åˆ»ï¼Œ{title}å³å°†æ­æ™“ã€‚"
            process = f"æˆ‘ä»¬çœ‹åˆ°{significance}ï¼Œæ­£ä¹‰ä¸æ³•å¾‹çš„è¾ƒé‡æ­£åœ¨å±•å¼€ã€‚"
            highlight = "æœ€ç´§å¼ çš„æ˜¯æ³•åº­ä¸Šçš„æ¿€çƒˆè¾©è®ºï¼ŒçœŸç›¸å³å°†å¤§ç™½ã€‚"
            ending = "è¿™ä¸ªæ¡ˆä»¶çš„èµ°å‘å°†å¦‚ä½•å‘å±•ï¼Ÿ"
        elif "æƒ…æ„Ÿ" in title or "å…³ç³»" in title:
            opening = f"æ„Ÿäººçš„æƒ…æ„Ÿç‰‡æ®µï¼Œ{title}ç‰µåŠ¨äººå¿ƒã€‚"
            process = f"æˆ‘ä»¬çœ‹åˆ°{significance}ï¼Œäººç‰©å…³ç³»å‘ç”Ÿé‡è¦å˜åŒ–ã€‚"
            highlight = "æœ€åŠ¨äººçš„æ˜¯è§’è‰²ä¹‹é—´çš„çœŸæƒ…æµéœ²ï¼Œä»¤äººåŠ¨å®¹ã€‚"
            ending = "è¿™æ®µæƒ…æ„Ÿå°†å¦‚ä½•å½±å“ä»–ä»¬çš„æœªæ¥ï¼Ÿ"
        else:
            opening = f"ç²¾å½©çš„å‰§æƒ…ç‰‡æ®µï¼Œ{title}æ­£åœ¨ä¸Šæ¼”ã€‚"
            process = f"æˆ‘ä»¬çœ‹åˆ°{significance}ï¼Œæ•…äº‹è¿æ¥é‡è¦è½¬æŠ˜ã€‚"
            highlight = "æœ€ç²¾å½©çš„æ˜¯å‰§æƒ…çš„æ„å¤–å‘å±•ï¼Œè®©äººç›®ä¸è½¬ç›ã€‚"
            ending = "åç»­å‰§æƒ…å°†å¦‚ä½•å±•å¼€ï¼Ÿè®©æˆ‘ä»¬ç»§ç»­å…³æ³¨ã€‚"

        full_narration = f"{opening} {process} {highlight} {ending}"

        return {
            "opening": opening,
            "process": process,
            "highlight": highlight,
            "ending": ending,
            "full_narration": full_narration,
            "timing": {
                "opening": [0, 3],
                "process": [3, 8],
                "highlight": [8, 11],
                "ending": [11, 12]
            }
        }