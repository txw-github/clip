# Updated AI call method to use OpenAI client and fallback to requests.
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œå…¨æ™ºèƒ½åŒ–å‰§æƒ…åˆ†æå™¨ - è§£å†³æ‰€æœ‰é™åˆ¶é—®é¢˜
ç‰¹ç‚¹ï¼š
1. å®Œå…¨åŠ¨æ€ï¼Œæ— ç¡¬ç¼–ç é™åˆ¶
2. æä¾›å®Œæ•´ä¸Šä¸‹æ–‡ç‰‡æ®µç»™AI
3. æ¯é›†ç”Ÿæˆå¤šä¸ªç²¾å½©çŸ­è§†é¢‘
4. AIåˆ¤æ–­æœ€ä½³å‰ªè¾‘å†…å®¹å’Œæ—¶é•¿
5. æ”¯æŒsrtç›®å½•ç»“æ„
"""

import os
import re
import json
import requests
from typing import List, Dict, Tuple, Optional
from api_config_helper import config_helper

class SmartAnalyzer:
    def __init__(self):
        self.config = config_helper.load_config()
        self.enabled = self.config.get('enabled', False)

        if self.enabled:
            print(f"ğŸ¤– å¯ç”¨AIæ™ºèƒ½åˆ†æ: {self.config.get('provider')}/{self.config.get('model')}")
        else:
            print("ğŸ“ AIæœªé…ç½®ï¼Œä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")

    def get_subtitle_files(self) -> List[str]:
        """è·å–å­—å¹•æ–‡ä»¶ - æ”¯æŒsrtç›®å½•ç»“æ„"""
        files = []

        # ä¼˜å…ˆæ£€æŸ¥srtç›®å½•
        srt_dir = 'srt'
        if os.path.exists(srt_dir):
            for f in os.listdir(srt_dir):
                if f.endswith(('.txt', '.srt')):
                    files.append(os.path.join(srt_dir, f))

        # å¦‚æœsrtç›®å½•ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œæ£€æŸ¥æ ¹ç›®å½•
        if not files:
            print("âš  srtç›®å½•ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œæ£€æŸ¥æ ¹ç›®å½•...")
            for f in os.listdir('.'):
                if f.endswith(('.txt', '.srt')) and any(pattern in f.lower() for pattern in ['s01e', 'ep', 'e0', 'e1']):
                    files.append(f)

        # ç¡®ä¿srtç›®å½•å­˜åœ¨
        if not os.path.exists(srt_dir):
            os.makedirs(srt_dir)
            print(f"âœ“ åˆ›å»ºå­—å¹•ç›®å½•: {srt_dir}/")
            if not files:
                print("âš  è¯·å°†å­—å¹•æ–‡ä»¶æ”¾å…¥srtç›®å½•")

        return sorted(files)

    def parse_subtitle_file(self, filepath: str) -> List[Dict]:
        """è§£æå­—å¹•æ–‡ä»¶"""
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
        except Exception as e:
            print(f"âŒ è¯»å–å­—å¹•æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
            return []

        blocks = re.split(r'\n\s*\n', content.strip())
        subtitles = []

        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                try:
                    index = int(lines[0])
                    time_match = re.match(r'(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})', lines[1])
                    if time_match:
                        start_time = time_match.group(1)
                        end_time = time_match.group(2)
                        text = '\n'.join(lines[2:])

                        subtitles.append({
                            'index': index,
                            'start': start_time,
                            'end': end_time,
                            'text': text,
                            'episode': os.path.basename(filepath)
                        })
                except (ValueError, IndexError):
                    continue

        return subtitles

    def create_context_segments(self, subtitles: List[Dict], window_size: int = 25) -> List[Dict]:
        """åˆ›å»ºåŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡çš„ç‰‡æ®µç»„"""
        context_segments = []

        # ä½¿ç”¨æ»‘åŠ¨çª—å£åˆ›å»ºé‡å çš„ä¸Šä¸‹æ–‡ç‰‡æ®µ
        step_size = window_size // 2  # 50% é‡å ç¡®ä¿è¿ç»­æ€§

        for i in range(0, len(subtitles), step_size):
            end_idx = min(i + window_size, len(subtitles))

            if end_idx - i < 10:  # å¤ªçŸ­çš„ç‰‡æ®µè·³è¿‡
                continue

            segment_subtitles = subtitles[i:end_idx]

            # åˆå¹¶æ–‡æœ¬
            full_text = "\n".join([sub['text'] for sub in segment_subtitles])

            # æ—¶é—´èŒƒå›´
            start_time = segment_subtitles[0]['start']
            end_time = segment_subtitles[-1]['end']
            duration = self.time_to_seconds(end_time) - self.time_to_seconds(start_time)

            # ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_before = subtitles[max(0, i-15):i] if i > 0 else []
            context_after = subtitles[end_idx:min(len(subtitles), end_idx+15)] if end_idx < len(subtitles) else []

            context_segments.append({
                'start_index': i,
                'end_index': end_idx - 1,
                'start_time': start_time,
                'end_time': end_time,
                'duration': duration,
                'full_text': full_text,
                'subtitles': segment_subtitles,
                'context_before': context_before,
                'context_after': context_after,
                'episode_position': i / len(subtitles)  # åœ¨å‰§é›†ä¸­çš„ä½ç½®
            })

        return context_segments

    def ai_analyze_segment(self, segment: Dict, episode_context: str = "") -> Dict:
        """ä½¿ç”¨AIåˆ†æç‰‡æ®µ - å®Œå…¨æ™ºèƒ½åŒ–"""
        if not self.enabled:
            return self._fallback_analysis(segment)

        # æ„å»ºä¸°å¯Œçš„ä¸Šä¸‹æ–‡
        context_before = "\n".join([sub['text'] for sub in segment['context_before'][-8:]])
        context_after = "\n".join([sub['text'] for sub in segment['context_after'][:8]])

        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œéœ€è¦åˆ†æè¿™ä¸ªç‰‡æ®µæ˜¯å¦é€‚åˆåˆ¶ä½œæˆç²¾å½©çŸ­è§†é¢‘ã€‚

ã€å‰æƒ…æè¦ã€‘
{context_before}

ã€å½“å‰ç‰‡æ®µå†…å®¹ã€‘ï¼ˆæ—¶é•¿ï¼š{segment['duration']:.1f}ç§’ï¼‰
{segment['full_text']}

ã€åç»­å‘å±•ã€‘
{context_after}

ã€å‰§é›†èƒŒæ™¯ã€‘{episode_context}

ã€ç‰‡æ®µä½ç½®ã€‘åœ¨å‰§é›†çš„{segment['episode_position']*100:.1f}%ä½ç½®

è¯·å®Œæˆä¸“ä¸šåˆ†æï¼š

1. **ç»¼åˆè¯„åˆ†** (0-10åˆ†)ï¼šè¿™ä¸ªç‰‡æ®µåˆ¶ä½œçŸ­è§†é¢‘çš„ä»·å€¼
2. **å‰§æƒ…å®Œæ•´æ€§** (0-10åˆ†)ï¼šç‰‡æ®µæ˜¯å¦æœ‰å®Œæ•´çš„èµ·æ‰¿è½¬åˆ
3. **æƒ…æ„Ÿå¼ºåº¦** (0-10åˆ†)ï¼šæ˜¯å¦æœ‰å¼ºçƒˆçš„æƒ…æ„Ÿå†²å‡»
4. **è§‚ä¼—å¸å¼•åŠ›** (0-10åˆ†)ï¼šæ˜¯å¦èƒ½å¸å¼•è§‚ä¼—è§‚çœ‹
5. **ä¸Šä¸‹æ–‡ç‹¬ç«‹æ€§** (0-10åˆ†)ï¼šè„±ç¦»ä¸Šä¸‹æ–‡æ˜¯å¦ä»ç„¶ç²¾å½©

6. **ç‰‡æ®µç±»å‹è¯†åˆ«**ï¼šè‡ªåŠ¨è¯†åˆ«è¿™æ˜¯ä»€ä¹ˆç±»å‹çš„ç‰‡æ®µï¼ˆä¸å—é™åˆ¶ï¼‰
7. **æœ€ä½³å‰ªè¾‘æ—¶é•¿**ï¼šå»ºè®®çš„å‰ªè¾‘æ—¶é•¿ï¼ˆç§’ï¼‰
8. **å‰ªè¾‘è°ƒæ•´å»ºè®®**ï¼š
   - æ˜¯å¦éœ€è¦æ‰©å±•æˆ–ç¼©çŸ­
   - æœ€ä½³å¼€å§‹å’Œç»“æŸç‚¹
   - è°ƒæ•´åŸå› 
9. **ç²¾å½©äº®ç‚¹**ï¼šè¯†åˆ«ç‰‡æ®µä¸­æœ€ç²¾å½©çš„éƒ¨åˆ†
10. **çŸ­è§†é¢‘æ ‡é¢˜**ï¼šä¸ºè¿™ä¸ªç‰‡æ®µç”Ÿæˆå¸å¼•äººçš„æ ‡é¢˜

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "overall_score": ç»¼åˆè¯„åˆ†,
    "plot_completeness": å‰§æƒ…å®Œæ•´æ€§è¯„åˆ†,
    "emotional_intensity": æƒ…æ„Ÿå¼ºåº¦è¯„åˆ†,
    "audience_appeal": è§‚ä¼—å¸å¼•åŠ›è¯„åˆ†,
    "context_independence": ä¸Šä¸‹æ–‡ç‹¬ç«‹æ€§è¯„åˆ†,
    "segment_type": "è‡ªåŠ¨è¯†åˆ«çš„ç‰‡æ®µç±»å‹",
    "optimal_duration": å»ºè®®å‰ªè¾‘æ—¶é•¿,
    "clip_adjustment": {{
        "action": "extend/shrink/keep",
        "reason": "è°ƒæ•´åŸå› ",
        "new_start_offset": å¼€å§‹æ—¶é—´åç§»ç§’æ•°,
        "new_end_offset": ç»“æŸæ—¶é—´åç§»ç§’æ•°,
        "best_start_dialogue": "æœ€ä½³å¼€å§‹å¯¹è¯",
        "best_end_dialogue": "æœ€ä½³ç»“æŸå¯¹è¯"
    }},
    "highlights": ["äº®ç‚¹1", "äº®ç‚¹2", "äº®ç‚¹3"],
    "video_title": "å¸å¼•äººçš„çŸ­è§†é¢‘æ ‡é¢˜",
    "hook_reason": "å¸å¼•è§‚ä¼—çš„æ ¸å¿ƒåŸå› ",
    "recommended": true/false,
    "confidence": ç½®ä¿¡åº¦0-1
}}"""

        try:
            response = self._call_ai_api(prompt)
            if response:
                result = self._parse_ai_response(response)
                result['original_segment'] = segment
                return result
        except Exception as e:
            print(f"AIåˆ†æå‡ºé”™: {e}")

        return self._fallback_analysis(segment)

    def _call_ai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨AI API - ä½¿ç”¨é€šç”¨APIåŠ©æ‰‹"""
        try:
            return config_helper.call_ai_api(prompt, self.config)
        except Exception as e:
            print(f"  âš  AIåˆ†æå¼‚å¸¸: {e}")
            return None

    def _call_gemini_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨Gemini API"""
        try:
            url = f"https://generativelanguage.googleapis.com/v1/models/{self.config['model']}:generateContent?key={self.config['api_key']}"

            data = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "maxOutputTokens": 2000,
                    "temperature": 0.7
                }
            }

            response = requests.post(url, json=data, timeout=30)

            if response.status_code == 200:
                result = response.json()
                return result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '')
            else:
                print(f"Gemini APIé”™è¯¯: {response.status_code} - {response.text}")
                return None
        except Exception as e:
            print(f"Gemini APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _call_qwen_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨é€šä¹‰åƒé—®API"""
        try:
            headers = {
                'Authorization': f'Bearer {self.config["api_key"]}',
                'Content-Type': 'application/json'
            }

            data = {
                'model': self.config['model'],
                'input': {'prompt': prompt},
                'parameters': {
                    'max_tokens': 2000,
                    'temperature': 0.7
                }
            }

            response = requests.post(self.config['url'], headers=headers, json=data, timeout=30)

            if response.status_code == 200:
                result = response.json()
                return result.get('output', {}).get('text', '')
            else:
                print(f"é€šä¹‰åƒé—®APIé”™è¯¯: {response.status_code} - {response.text}")
                return None
        except Exception as e:
            print(f"é€šä¹‰åƒé—®APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _call_doubao_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨è±†åŒ…API"""
        try:
            headers = {
                'Authorization': f'Bearer {self.config["api_key"]}',
                'Content-Type': 'application/json'
            }

            data = {
                'model': self.config['model'],
                'messages': [
                    {'role': 'system', 'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œä¸“æ³¨äºè¯†åˆ«ç²¾å½©ç‰‡æ®µå¹¶åˆ¶å®šæœ€ä½³å‰ªè¾‘æ–¹æ¡ˆã€‚'},
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 2000,
                'temperature': 0.7
            }

            response = requests.post(self.config['url'], headers=headers, json=data, timeout=30)

            if response.status_code == 200:
                result = response.json()
                return result.get('choices', [{}])[0].get('message', {}).get('content', '')
            else:
                print(f"è±†åŒ…APIé”™è¯¯: {response.status_code} - {response.text}")
                return None
        except Exception as e:
            print(f"è±†åŒ…APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _call_standard_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨æ ‡å‡†APIï¼ˆæ”¯æŒOpenRouterç­‰æ–°æœåŠ¡å•†ï¼‰"""
        try:
            headers = {
                'Authorization': f'Bearer {self.config["api_key"]}',
                'Content-Type': 'application/json'
            }

            # ä¸ºOpenRouteræ·»åŠ ç‰¹æ®Šå¤´éƒ¨
            if self.config.get('provider') == 'openrouter':
                headers.update({
                    'HTTP-Referer': 'https://replit.com',
                    'X-Title': 'TV-Clipper-AI'
                })

            data = {
                'model': self.config['model'],
                'messages': [
                    {'role': 'system', 'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œä¸“æ³¨äºè¯†åˆ«ç²¾å½©ç‰‡æ®µå¹¶åˆ¶å®šæœ€ä½³å‰ªè¾‘æ–¹æ¡ˆã€‚ä½ çš„åˆ†æä¸å—ä»»ä½•é¢„è®¾é™åˆ¶ï¼Œå®Œå…¨åŸºäºå‰§æƒ…å†…å®¹è¿›è¡Œæ™ºèƒ½åˆ¤æ–­ã€‚'},
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 2000,
                'temperature': 0.7
            }

            response = requests.post(self.config['url'], headers=headers, json=data, timeout=30)

            if response.status_code == 200:
                result = response.json()
                return result.get('choices', [{}])[0].get('message', {}).get('content', '')
            else:
                print(f"APIé”™è¯¯: {response.status_code} - {response.text}")
                return None
        except Exception as e:
            print(f"APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _parse_ai_response(self, response_text: str) -> Dict:
        """è§£æAIå“åº”"""
        try:
            # æå–JSON
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                json_text = response_text[json_start:json_end].strip()
            else:
                start = response_text.find("{")
                end = response_text.rfind("}") + 1
                if start != -1 and end > start:
                    json_text = response_text[start:end]
                else:
                    json_text = response_text

            result = json.loads(json_text)

            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
            defaults = {
                "overall_score": 5.0,
                "recommended": False,
                "video_title": "ç²¾å½©ç‰‡æ®µ",
                "optimal_duration": 120,
                "confidence": 0.5
            }

            for key, default_value in defaults.items():
                if key not in result:
                    result[key] = default_value

            return result

        except json.JSONDecodeError:
            # åŸºç¡€è§£æ
            score_match = re.search(r'(\d+\.?\d*)', response_text)
            score = float(score_match.group(1)) if score_match else 5.0

            return {
                "overall_score": score,
                "recommended": score >= 6.0,
                "video_title": "AIåˆ†æç‰‡æ®µ",
                "reasoning": response_text[:200],
                "confidence": 0.5
            }
        except Exception as e:
            print(f"å“åº”è§£æå¼‚å¸¸: {e}")
            return {
                "overall_score": 5.0,
                "recommended": False,
                "video_title": "è§£æé”™è¯¯",
                "reasoning": "è§£æå¤±è´¥",
                "confidence": 0.1
            }

    def _fallback_analysis(self, segment: Dict) -> Dict:
        """AIä¸å¯ç”¨æ—¶çš„å¤‡ç”¨åˆ†æ"""
        text = segment['full_text']

        # ç®€å•å…³é”®è¯åˆ†æ
        exciting_keywords = ['çªç„¶', 'å‘ç°', 'çœŸç›¸', 'ç§˜å¯†', 'å±é™©', 'ä¸è¦', 'ä¸ºä»€ä¹ˆ', 'æ•‘å‘½', 'å®Œäº†']
        emotional_words = ['æ„¤æ€’', 'å“­', 'å–Š', 'æ¿€åŠ¨', 'éœ‡æƒŠ', 'å®³æ€•', 'å¼€å¿ƒ', 'éš¾è¿‡']

        score = 0
        for keyword in exciting_keywords:
            score += text.count(keyword) * 2
        for emotion in emotional_words:
            score += text.count(emotion) * 1.5

        # å¯¹è¯å¼ºåº¦
        score += text.count('ï¼') * 0.5 + text.count('ï¼Ÿ') * 0.3

        return {
            "overall_score": min(score, 10),
            "recommended": score >= 4,
            "video_title": "ç²¾å½©ç‰‡æ®µ",
            "optimal_duration": segment['duration'],
            "reasoning": "åŸºç¡€åˆ†ææ¨¡å¼",
            "confidence": 0.6,
            "original_segment": segment
        }

    def analyze_episode_smartly(self, episode_file: str) -> Dict:
        """æ™ºèƒ½åˆ†æå•é›†ï¼Œè¿”å›å¤šä¸ªæ¨èçš„çŸ­è§†é¢‘ç‰‡æ®µ"""
        print(f"\nğŸ§  æ™ºèƒ½åˆ†æ {os.path.basename(episode_file)}...")

        subtitles = self.parse_subtitle_file(episode_file)
        if not subtitles:
            return {"error": "æ— æ³•è§£æå­—å¹•æ–‡ä»¶"}

        # åˆ›å»ºä¸Šä¸‹æ–‡ç‰‡æ®µ
        context_segments = self.create_context_segments(subtitles)
        print(f"ğŸ“Š åˆ›å»ºäº† {len(context_segments)} ä¸ªä¸Šä¸‹æ–‡ç‰‡æ®µ")

        # è·å–å‰§é›†èƒŒæ™¯
        episode_context = self._get_episode_context(subtitles[:50], subtitles[-30:])

        # AIåˆ†ææ¯ä¸ªç‰‡æ®µ
        analyzed_segments = []
        for i, segment in enumerate(context_segments):
            print(f"  ğŸ” åˆ†æç‰‡æ®µ {i+1}/{len(context_segments)}")

            analysis = self.ai_analyze_segment(segment, episode_context)

            # åªä¿ç•™é«˜è´¨é‡ç‰‡æ®µ
            if analysis.get('recommended', False) and analysis.get('overall_score', 0) >= 6.0:
                analyzed_segments.append(analysis)

        # æŒ‰åˆ†æ•°æ’åº
        analyzed_segments.sort(key=lambda x: x.get('overall_score', 0), reverse=True)

        # é€‰æ‹©æœ€ä½³ç‰‡æ®µï¼ˆé¿å…é‡å ï¼‰
        final_clips = self._select_best_clips(analyzed_segments)

        # ç”Ÿæˆå‰§é›†æ€»ç»“
        episode_num = self._extract_episode_number(episode_file)

        return {
            'episode': episode_file,
            'episode_number': episode_num,
            'total_clips': len(final_clips),
            'clips': final_clips,
            'total_duration': sum(clip.get('optimal_duration', 120) for clip in final_clips),
            'ai_analysis': self.enabled,
            'episode_context': episode_context[:100]
        }

    def _get_episode_context(self, beginning: List[Dict], ending: List[Dict]) -> str:
        """è·å–å‰§é›†èƒŒæ™¯"""
        if not self.enabled:
            return "æœ¬é›†ç²¾å½©å†…å®¹"

        beginning_text = "\n".join([sub['text'] for sub in beginning])
        ending_text = "\n".join([sub['text'] for sub in ending])

        prompt = f"""è¯·ç”¨30å­—ä»¥å†…ç®€è¦æ€»ç»“è¿™ä¸€é›†çš„æ ¸å¿ƒå‰§æƒ…ï¼š

å¼€å¤´ï¼š{beginning_text}
ç»“å°¾ï¼š{ending_text}

åªè¿”å›å‰§æƒ…æ¦‚è¦ï¼Œä¸éœ€è¦å…¶ä»–å†…å®¹ã€‚"""

        try:
            response = self._call_ai_api(prompt)
            return response[:50] if response else "æœ¬é›†ç²¾å½©å†…å®¹"
        except:
            return "æœ¬é›†ç²¾å½©å†…å®¹"

    def _select_best_clips(self, clips: List[Dict], max_clips: int = 4) -> List[Dict]:
        """é€‰æ‹©æœ€ä½³ç‰‡æ®µï¼Œé¿å…é‡å """
        if not clips:
            return []

        selected = []
        used_time_ranges = []

        for clip in clips:
            if len(selected) >= max_clips:
                break

            segment = clip['original_segment']
            start_time = self.time_to_seconds(segment['start_time'])
            end_time = self.time_to_seconds(segment['end_time'])

            # æ£€æŸ¥æ˜¯å¦ä¸å·²é€‰ç‰‡æ®µé‡å 
            overlapping = False
            for used_start, used_end in used_time_ranges:
                if not (end_time < used_start or start_time > used_end):
                    overlapping = True
                    break

            if not overlapping:
                selected.append(clip)
                used_time_ranges.append((start_time, end_time))

        return selected

    def _extract_episode_number(self, filename: str) -> str:
        """æå–å‰§é›†ç¼–å·"""
        episode_match = re.search(r'[SE](\d+)[EX](\d+)', filename, re.IGNORECASE)
        if episode_match:
            return f"{episode_match.group(1)}{episode_match.group(2)}"

        episode_match = re.search(r'(\d+)', filename)
        return episode_match.group(1) if episode_match else "00"

    def time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢"""
        try:
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0

def analyze_all_episodes_smartly():
    """æ™ºèƒ½åˆ†ææ‰€æœ‰å‰§é›†"""
    analyzer = SmartAnalyzer()

    # è·å–æ‰€æœ‰å­—å¹•æ–‡ä»¶
    subtitle_files = analyzer.get_subtitle_files()

    if not subtitle_files:
        print("âŒ æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
        return []

    print(f"ğŸš€ å¯åŠ¨å®Œå…¨æ™ºèƒ½åŒ–åˆ†æç³»ç»Ÿ - å‘ç° {len(subtitle_files)} ä¸ªå­—å¹•æ–‡ä»¶")
    print("ğŸ¤– æ–°ç‰¹æ€§ï¼š")
    print("â€¢ å®Œå…¨AIé©±åŠ¨ï¼Œæ— ä»»ä½•ç¡¬ç¼–ç é™åˆ¶")
    print("â€¢ æä¾›å®Œæ•´ä¸Šä¸‹æ–‡ç»™AIåˆ†æ")
    print("â€¢ æ¯é›†ç”Ÿæˆå¤šä¸ªç²¾å½©çŸ­è§†é¢‘")
    print("â€¢ AIåˆ¤æ–­æœ€ä½³å‰ªè¾‘å†…å®¹å’Œæ—¶é•¿")
    print("â€¢ æ”¯æŒsrtç›®å½•ç»“æ„")
    print("=" * 60)

    all_episodes_plans = []

    for filename in subtitle_files:
        try:
            episode_plan = analyzer.analyze_episode_smartly(filename)

            if 'error' not in episode_plan:
                all_episodes_plans.append(episode_plan)

                print(f"âœ… {os.path.basename(filename)}")
                print(f"  ğŸ¬ æ¨èçŸ­è§†é¢‘: {episode_plan['total_clips']} ä¸ª")
                print(f"  â±ï¸ æ€»æ—¶é•¿: {episode_plan['total_duration']:.1f}ç§’")
                print(f"  ğŸ¤– AIåˆ†æ: {'æ˜¯' if episode_plan['ai_analysis'] else 'å¦'}")

                # æ˜¾ç¤ºæ¨èç‰‡æ®µ
                for i, clip in enumerate(episode_plan['clips'][:3]):
                    title = clip.get('video_title', 'æœªçŸ¥')
                    score = clip.get('overall_score', 0)
                    print(f"    ç‰‡æ®µ{i+1}: {title} (è¯„åˆ†: {score:.1f})")
                print()
            else:
                print(f"âŒ é”™è¯¯å¤„ç† {filename}: {episode_plan['error']}")

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥ {filename}: {e}")

    # ç”ŸæˆæŠ¥å‘Š
    generate_smart_report(all_episodes_plans)
    return all_episodes_plans

def generate_smart_report(episodes_plans: List[Dict]):
    """ç”Ÿæˆæ™ºèƒ½åˆ†ææŠ¥å‘Š"""
    if not episodes_plans:
        return

    total_clips = sum(ep['total_clips'] for ep in episodes_plans)
    total_duration = sum(ep['total_duration'] for ep in episodes_plans)
    ai_analyzed = sum(1 for ep in episodes_plans if ep['ai_analysis'])

    content = f"""ğŸ¤– å®Œå…¨æ™ºèƒ½åŒ–å‰§æƒ…åˆ†ææŠ¥å‘Š
{'='*60}

ğŸ“Š åˆ†æç»Ÿè®¡ï¼š
â€¢ æ€»é›†æ•°ï¼š{len(episodes_plans)} é›†
â€¢ æ¨èçŸ­è§†é¢‘ï¼š{total_clips} ä¸ª
â€¢ æ€»æ—¶é•¿ï¼š{total_duration/60:.1f} åˆ†é’Ÿ
â€¢ AIæ™ºèƒ½åˆ†æï¼š{ai_analyzed}/{len(episodes_plans)} é›†
â€¢ å¹³å‡æ¯é›†ï¼š{total_clips/len(episodes_plans):.1f} ä¸ªçŸ­è§†é¢‘

ğŸ¬ è¯¦ç»†å‰§é›†æ–¹æ¡ˆï¼š
"""

    for ep in episodes_plans:
        content += f"\nğŸ“º ç¬¬{ep['episode_number']}é›†\n"
        content += f"æ¨èçŸ­è§†é¢‘ï¼š{ep['total_clips']} ä¸ª\n"
        content += f"æ€»æ—¶é•¿ï¼š{ep['total_duration']/60:.1f} åˆ†é’Ÿ\n"
        content += f"èƒŒæ™¯ï¼š{ep.get('episode_context', 'N/A')}\n"

        for i, clip in enumerate(ep['clips']):
            segment = clip['original_segment']
            title = clip.get('video_title', 'ç²¾å½©ç‰‡æ®µ')
            score = clip.get('overall_score', 0)
            duration = clip.get('optimal_duration', 120)

            content += f"\n  ğŸ¯ çŸ­è§†é¢‘ {i+1}ï¼š{title}\n"
            content += f"     æ—¶é—´ï¼š{segment['start_time']} --> {segment['end_time']}\n"
            content += f"     å»ºè®®æ—¶é•¿ï¼š{duration}ç§’\n"
            content += f"     è¯„åˆ†ï¼š{score:.1f}/10\n"

            if 'highlights' in clip:
                content += f"     äº®ç‚¹ï¼š{', '.join(clip['highlights'][:3])}\n"

        content += "\n" + "-"*40 + "\n"

    with open('smart_analysis_report.txt', 'w', encoding='utf-8') as f:
        f.write(content)

    print(f"âœ… å®Œå…¨æ™ºèƒ½åŒ–åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° smart_analysis_report.txt")
    print(f"ğŸ“Š å…±ç”Ÿæˆ {total_clips} ä¸ªæ¨èçŸ­è§†é¢‘ç‰‡æ®µ")

if __name__ == "__main__":
    analyze_all_episodes_smartly()
